<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Quantitative Methods for Linguistic Data</title>
  <meta name="description" content="Quantitative Methods for Linguistic Data">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Quantitative Methods for Linguistic Data" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Quantitative Methods for Linguistic Data" />
  
  
  

<meta name="author" content="Morgan Sonderegger, Michael Wagner, Francisco Torreira">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="mixed-effects-logistic-regression.html">
<link rel="next" href="datasets-appendix.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods for Linguistic Data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html"><i class="fa fa-check"></i><b>1</b> Inferential statistics: Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#loads-transitions.txt-from-osf-project-for-roberts-torreira-levinson-2015-data"><i class="fa fa-check"></i><b>1.1</b> loads transitions.txt from OSF project for Roberts, Torreira, &amp; Levinson (2015) data</a></li>
<li class="chapter" data-level="1.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-population"><i class="fa fa-check"></i><b>1.2</b> Population vs.Â sample</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-to-population-high-level"><i class="fa fa-check"></i><b>1.2.1</b> Sample <span class="math inline">\(\to\)</span> population: High level</a></li>
<li class="chapter" data-level="1.2.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sdsm"><i class="fa fa-check"></i><b>1.2.2</b> Sampling distribution of the sample mean</a></li>
<li class="chapter" data-level="1.2.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sampling-from-a-non-normal-distribution"><i class="fa fa-check"></i><b>1.2.3</b> Sampling from a non-normal distribution</a></li>
<li class="chapter" data-level="" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#the-transitions-dataset-was-loaded-at-the-beginning-of-this-page"><i class="fa fa-check"></i><b>1.3</b> the transitions dataset was loaded at the beginning of this page</a></li>
<li class="chapter" data-level="1.4" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#meandur-n-sd-se"><i class="fa fa-check"></i><b>1.4</b> meanDur n sd se</a></li>
<li class="chapter" data-level="1.5" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section"><i class="fa fa-check"></i><b>1.5</b> 1 185.7611 21090 473.3708 3.259591</a></li>
<li class="chapter" data-level="1.6" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#confidence-intervals"><i class="fa fa-check"></i><b>1.6</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.7" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-distribution"><i class="fa fa-check"></i><b>1.7</b> <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="1.7.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-based-confidence-intervals"><i class="fa fa-check"></i><b>1.7.1</b> <span class="math inline">\(t\)</span>-based confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-1"><i class="fa fa-check"></i><b>1.8</b> [1] 0.975</a></li>
<li class="chapter" data-level="1.9" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#n"><i class="fa fa-check"></i><b>1.9</b> n</a></li>
<li class="chapter" data-level="1.10" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-2"><i class="fa fa-check"></i><b>1.10</b> [1,] 5 2.570582</a></li>
<li class="chapter" data-level="1.11" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-3"><i class="fa fa-check"></i><b>1.11</b> [2,] 15 2.131450</a></li>
<li class="chapter" data-level="1.12" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-4"><i class="fa fa-check"></i><b>1.12</b> [3,] 25 2.059539</a></li>
<li class="chapter" data-level="1.13" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-5"><i class="fa fa-check"></i><b>1.13</b> [4,] 50 2.008559</a></li>
<li class="chapter" data-level="1.14" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-6"><i class="fa fa-check"></i><b>1.14</b> [5,] 100 1.983972</a></li>
<li class="chapter" data-level="1.15" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-7"><i class="fa fa-check"></i><b>1.15</b> [6,] 500 1.964720</a></li>
<li class="chapter" data-level="1.16" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-8"><i class="fa fa-check"></i><b>1.16</b> </a></li>
<li class="chapter" data-level="1.17" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#f-m"><i class="fa fa-check"></i><b>1.17</b> F M</a></li>
<li class="chapter" data-level="1.18" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-9"><i class="fa fa-check"></i><b>1.18</b> 9550 11540</a></li>
<li class="chapter" data-level="1.19" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#other-reading"><i class="fa fa-check"></i><b>1.19</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>2</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#loads-transitions.txt-from-osf-project-for-roberts-torreira-levinson-2015-data-1"><i class="fa fa-check"></i><b>2.1</b> loads transitions.txt from OSF project for Roberts, Torreira, &amp; Levinson (2015) data</a></li>
<li class="chapter" data-level="2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-high-level"><i class="fa fa-check"></i><b>2.2</b> Hypothesis testing: High-level</a></li>
<li class="chapter" data-level="2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#z-scores"><i class="fa fa-check"></i><b>2.3</b> <span class="math inline">\(z\)</span>-scores</a></li>
<li class="chapter" data-level="2.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-tests"><i class="fa fa-check"></i><b>2.4</b> <span class="math inline">\(t\)</span>-tests</a><ul>
<li class="chapter" data-level="2.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#single-sample-t-test-setup"><i class="fa fa-check"></i><b>2.4.1</b> Single-sample <span class="math inline">\(t\)</span>-test: Setup</a></li>
<li class="chapter" data-level="2.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-in-general"><i class="fa fa-check"></i><b>2.4.2</b> Hypothesis testing in general</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-10"><i class="fa fa-check"></i><b>2.5</b> [1] 6.494323</a></li>
<li class="chapter" data-level="2.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-11"><i class="fa fa-check"></i><b>2.6</b> </a></li>
<li class="chapter" data-level="2.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-sample-t-test"><i class="fa fa-check"></i><b>2.7</b> One Sample t-test</a></li>
<li class="chapter" data-level="2.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-12"><i class="fa fa-check"></i><b>2.8</b> </a></li>
<li class="chapter" data-level="2.9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-dwrittenfrequency-t-2.1317-df-19-p-value-0.04631-alternative-hypothesis-true-mean-is-not-equal-to-6.494-95-percent-confidence-interval-6.516539-8.958954-sample-estimates-mean-of-x-7.737747-one-sample-t-test-data-dwrittenfrequency"><i class="fa fa-check"></i><b>2.9</b> data: d<span class="math inline">\(WrittenFrequency ## t = 2.1317, df = 19, p-value = 0.04631 ## alternative hypothesis: true mean is not equal to 6.494 ## 95 percent confidence interval: ## 6.516539 8.958954 ## sample estimates: ## mean of x ## 7.737747 ## ## One Sample t-test ## ## data: d\)</span>WrittenFrequency</a></li>
<li class="chapter" data-level="2.10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-2.1505-df-102-p-value-0.03388"><i class="fa fa-check"></i><b>2.10</b> t = 2.1505, df = 102, p-value = 0.03388</a></li>
<li class="chapter" data-level="2.11" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-mean-is-not-equal-to-6.494"><i class="fa fa-check"></i><b>2.11</b> alternative hypothesis: true mean is not equal to 6.494</a></li>
<li class="chapter" data-level="2.12" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval"><i class="fa fa-check"></i><b>2.12</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.13" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-13"><i class="fa fa-check"></i><b>2.13</b> 6.522260 7.193689</a></li>
<li class="chapter" data-level="2.14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates"><i class="fa fa-check"></i><b>2.14</b> sample estimates:</a></li>
<li class="chapter" data-level="2.15" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-of-x"><i class="fa fa-check"></i><b>2.15</b> mean of x</a></li>
<li class="chapter" data-level="2.16" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-14"><i class="fa fa-check"></i><b>2.16</b> 6.857975</a><ul>
<li class="chapter" data-level="2.16.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.16.1</b> Two-sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="2.17" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-15"><i class="fa fa-check"></i><b>2.17</b> </a></li>
<li class="chapter" data-level="2.18" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.18</b> Two Sample t-test</a></li>
<li class="chapter" data-level="2.19" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-16"><i class="fa fa-check"></i><b>2.19</b> </a></li>
<li class="chapter" data-level="2.20" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-regularitywrittenfrequency-by-regularitytype"><i class="fa fa-check"></i><b>2.20</b> data: regularity<span class="math inline">\(WrittenFrequency by regularity\)</span>type</a></li>
<li class="chapter" data-level="2.21" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t--2.6406-df-698-p-value-0.008462"><i class="fa fa-check"></i><b>2.21</b> t = -2.6406, df = 698, p-value = 0.008462</a></li>
<li class="chapter" data-level="2.22" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0"><i class="fa fa-check"></i><b>2.22</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.23" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-1"><i class="fa fa-check"></i><b>2.23</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.24" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-17"><i class="fa fa-check"></i><b>2.24</b> -0.8834591 -0.1299488</a></li>
<li class="chapter" data-level="2.25" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-1"><i class="fa fa-check"></i><b>2.25</b> sample estimates:</a></li>
<li class="chapter" data-level="2.26" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-in-group-hebben-mean-in-group-nonheb"><i class="fa fa-check"></i><b>2.26</b> mean in group hebben mean in group nonheb</a></li>
<li class="chapter" data-level="2.27" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-18"><i class="fa fa-check"></i><b>2.27</b> 6.494323 7.001027</a><ul>
<li class="chapter" data-level="2.27.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-example"><i class="fa fa-check"></i><b>2.27.1</b> Unequal variances: Welch <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="2.28" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-19"><i class="fa fa-check"></i><b>2.28</b> </a></li>
<li class="chapter" data-level="2.29" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-two-sample-t-test"><i class="fa fa-check"></i><b>2.29</b> Welch Two Sample t-test</a></li>
<li class="chapter" data-level="2.30" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-20"><i class="fa fa-check"></i><b>2.30</b> </a></li>
<li class="chapter" data-level="2.31" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-regularitywrittenfrequency-by-regularitytype-1"><i class="fa fa-check"></i><b>2.31</b> data: regularity<span class="math inline">\(WrittenFrequency by regularity\)</span>type</a></li>
<li class="chapter" data-level="2.32" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t--2.6688-df-179.82-p-value-0.008309"><i class="fa fa-check"></i><b>2.32</b> t = -2.6688, df = 179.82, p-value = 0.008309</a></li>
<li class="chapter" data-level="2.33" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-1"><i class="fa fa-check"></i><b>2.33</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.34" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-2"><i class="fa fa-check"></i><b>2.34</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.35" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-21"><i class="fa fa-check"></i><b>2.35</b> -0.8813494 -0.1320584</a></li>
<li class="chapter" data-level="2.36" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-2"><i class="fa fa-check"></i><b>2.36</b> sample estimates:</a></li>
<li class="chapter" data-level="2.37" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-in-group-hebben-mean-in-group-nonheb-1"><i class="fa fa-check"></i><b>2.37</b> mean in group hebben mean in group nonheb</a></li>
<li class="chapter" data-level="2.38" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-22"><i class="fa fa-check"></i><b>2.38</b> 6.494323 7.001027</a><ul>
<li class="chapter" data-level="2.38.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-test-assumptions"><i class="fa fa-check"></i><b>2.38.1</b> Assumptions behind <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.38.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>2.38.2</b> Paired <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="2.39" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#a-tibble-349-x-3"><i class="fa fa-check"></i><b>2.39</b> # A tibble: 349 x 3</a></li>
<li class="chapter" data-level="2.40" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#file-meandurfirst-meandurafter"><i class="fa fa-check"></i><b>2.40</b> file meanDurFirst meanDurAfter</a></li>
<li class="chapter" data-level="2.41" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-23"><i class="fa fa-check"></i><b>2.41</b> <fct> <dbl> <dbl></a></li>
<li class="chapter" data-level="2.42" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3154.eaf-231.-245."><i class="fa fa-check"></i><b>2.42</b> 1 sw3154.eaf 231. 245.</a></li>
<li class="chapter" data-level="2.43" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3155.eaf-19-153."><i class="fa fa-check"></i><b>2.43</b> 2 sw3155.eaf 19 153.</a></li>
<li class="chapter" data-level="2.44" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3156.eaf-131--9.11"><i class="fa fa-check"></i><b>2.44</b> 3 sw3156.eaf 131 -9.11</a></li>
<li class="chapter" data-level="2.45" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3159.eaf-166.--28.3"><i class="fa fa-check"></i><b>2.45</b> 4 sw3159.eaf 166. -28.3</a></li>
<li class="chapter" data-level="2.46" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3161.eaf--352.-34.3"><i class="fa fa-check"></i><b>2.46</b> 5 sw3161.eaf -352. 34.3</a></li>
<li class="chapter" data-level="2.47" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3168.eaf-31.7-120."><i class="fa fa-check"></i><b>2.47</b> 6 sw3168.eaf 31.7 120.</a></li>
<li class="chapter" data-level="2.48" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3169.eaf-nan-202."><i class="fa fa-check"></i><b>2.48</b> 7 sw3169.eaf NaN 202.</a></li>
<li class="chapter" data-level="2.49" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3171.eaf--76.8--120."><i class="fa fa-check"></i><b>2.49</b> 8 sw3171.eaf -76.8 -120.</a></li>
<li class="chapter" data-level="2.50" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3174.eaf-378.-75.7"><i class="fa fa-check"></i><b>2.50</b> 9 sw3174.eaf 378. 75.7</a></li>
<li class="chapter" data-level="2.51" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3182.eaf-330.-139."><i class="fa fa-check"></i><b>2.51</b> 10 sw3182.eaf 330. 139.</a></li>
<li class="chapter" data-level="2.52" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#with-339-more-rows"><i class="fa fa-check"></i><b>2.52</b> # â¦ with 339 more rows</a></li>
<li class="chapter" data-level="2.53" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-24"><i class="fa fa-check"></i><b>2.53</b> </a></li>
<li class="chapter" data-level="2.54" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>2.54</b> Paired t-test</a></li>
<li class="chapter" data-level="2.55" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-25"><i class="fa fa-check"></i><b>2.55</b> </a></li>
<li class="chapter" data-level="2.56" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-dmeandurfirst-and-dmeandurafter"><i class="fa fa-check"></i><b>2.56</b> data: d<span class="math inline">\(meanDurFirst and d\)</span>meanDurAfter</a></li>
<li class="chapter" data-level="2.57" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-5.9893-df-346-p-value-5.283e-09"><i class="fa fa-check"></i><b>2.57</b> t = 5.9893, df = 346, p-value = 5.283e-09</a></li>
<li class="chapter" data-level="2.58" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-2"><i class="fa fa-check"></i><b>2.58</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.59" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-3"><i class="fa fa-check"></i><b>2.59</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.60" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-26"><i class="fa fa-check"></i><b>2.60</b> 42.10084 83.27295</a></li>
<li class="chapter" data-level="2.61" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-3"><i class="fa fa-check"></i><b>2.61</b> sample estimates:</a></li>
<li class="chapter" data-level="2.62" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-of-the-differences"><i class="fa fa-check"></i><b>2.62</b> mean of the differences</a></li>
<li class="chapter" data-level="2.63" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-27"><i class="fa fa-check"></i><b>2.63</b> 62.6869</a><ul>
<li class="chapter" data-level="2.63.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#reporting-a-hypothesis-test"><i class="fa fa-check"></i><b>2.63.1</b> Reporting a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.64" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#checking-normality"><i class="fa fa-check"></i><b>2.64</b> Checking normality</a><ul>
<li class="chapter" data-level="2.64.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#visual-methods"><i class="fa fa-check"></i><b>2.64.1</b> Visual methods</a></li>
</ul></li>
<li class="chapter" data-level="2.65" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#stat_bin-using-bins-30.-pick-better-value-with-binwidth."><i class="fa fa-check"></i><b>2.65</b> <code>stat_bin()</code> using <code>bins = 30</code>. Pick better value with <code>binwidth</code>.</a><ul>
<li class="chapter" data-level="2.65.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#q-q-plots"><i class="fa fa-check"></i><b>2.65.1</b> Q-Q plots</a></li>
<li class="chapter" data-level="2.65.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#shapiro-wilk-example"><i class="fa fa-check"></i><b>2.65.2</b> Hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.66" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-28"><i class="fa fa-check"></i><b>2.66</b> </a></li>
<li class="chapter" data-level="2.67" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#shapiro-wilk-normality-test"><i class="fa fa-check"></i><b>2.67</b> Shapiro-Wilk normality test</a></li>
<li class="chapter" data-level="2.68" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-29"><i class="fa fa-check"></i><b>2.68</b> </a></li>
<li class="chapter" data-level="2.69" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-hebbenwrittenfrequency"><i class="fa fa-check"></i><b>2.69</b> data: hebben$WrittenFrequency</a></li>
<li class="chapter" data-level="2.70" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#w-0.97396-p-value-1.324e-08"><i class="fa fa-check"></i><b>2.70</b> W = 0.97396, p-value = 1.324e-08</a><ul>
<li class="chapter" data-level="2.70.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-parametric-tests"><i class="fa fa-check"></i><b>2.70.1</b> Other parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.71" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>2.71</b> Non-parametric tests</a><ul>
<li class="chapter" data-level="2.71.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxson-tests"><i class="fa fa-check"></i><b>2.71.1</b> Wilcoxson tests</a></li>
<li class="chapter" data-level="2.71.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-wilcoxson-test"><i class="fa fa-check"></i><b>2.71.2</b> Two-sample Wilcoxson test</a></li>
</ul></li>
<li class="chapter" data-level="2.72" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-30"><i class="fa fa-check"></i><b>2.72</b> </a></li>
<li class="chapter" data-level="2.73" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxon-rank-sum-test-with-continuity-correction"><i class="fa fa-check"></i><b>2.73</b> Wilcoxon rank sum test with continuity correction</a></li>
<li class="chapter" data-level="2.74" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-31"><i class="fa fa-check"></i><b>2.74</b> </a></li>
<li class="chapter" data-level="2.75" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-writtenfrequency-by-type"><i class="fa fa-check"></i><b>2.75</b> data: WrittenFrequency by type</a></li>
<li class="chapter" data-level="2.76" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#w-29315-p-value-0.002444"><i class="fa fa-check"></i><b>2.76</b> W = 29315, p-value = 0.002444</a></li>
<li class="chapter" data-level="2.77" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-location-shift-is-not-equal-to-0"><i class="fa fa-check"></i><b>2.77</b> alternative hypothesis: true location shift is not equal to 0</a><ul>
<li class="chapter" data-level="2.77.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#parametric-versus-non-parametric-tests"><i class="fa fa-check"></i><b>2.77.1</b> Parametric versus non-parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.78" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-32"><i class="fa fa-check"></i><b>2.78</b> </a></li>
<li class="chapter" data-level="2.79" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-two-sample-t-test-1"><i class="fa fa-check"></i><b>2.79</b> Welch Two Sample t-test</a></li>
<li class="chapter" data-level="2.80" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-33"><i class="fa fa-check"></i><b>2.80</b> </a></li>
<li class="chapter" data-level="2.81" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-x1-and-x2"><i class="fa fa-check"></i><b>2.81</b> data: x1 and x2</a></li>
<li class="chapter" data-level="2.82" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-5.3111-df-147.12-p-value-3.948e-07"><i class="fa fa-check"></i><b>2.82</b> t = 5.3111, df = 147.12, p-value = 3.948e-07</a></li>
<li class="chapter" data-level="2.83" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-3"><i class="fa fa-check"></i><b>2.83</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.84" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-4"><i class="fa fa-check"></i><b>2.84</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.85" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-34"><i class="fa fa-check"></i><b>2.85</b> 0.3312187 0.7237747</a></li>
<li class="chapter" data-level="2.86" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-4"><i class="fa fa-check"></i><b>2.86</b> sample estimates:</a></li>
<li class="chapter" data-level="2.87" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-of-x-mean-of-y"><i class="fa fa-check"></i><b>2.87</b> mean of x mean of y</a></li>
<li class="chapter" data-level="2.88" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-35"><i class="fa fa-check"></i><b>2.88</b> 1.489870 0.962373</a></li>
<li class="chapter" data-level="2.89" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-36"><i class="fa fa-check"></i><b>2.89</b> </a></li>
<li class="chapter" data-level="2.90" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxon-rank-sum-test-with-continuity-correction-1"><i class="fa fa-check"></i><b>2.90</b> Wilcoxon rank sum test with continuity correction</a></li>
<li class="chapter" data-level="2.91" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-37"><i class="fa fa-check"></i><b>2.91</b> </a></li>
<li class="chapter" data-level="2.92" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-x1-and-x2-1"><i class="fa fa-check"></i><b>2.92</b> data: x1 and x2</a></li>
<li class="chapter" data-level="2.93" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#w-6936-p-value-2.254e-06"><i class="fa fa-check"></i><b>2.93</b> W = 6936, p-value = 2.254e-06</a></li>
<li class="chapter" data-level="2.94" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-location-shift-is-not-equal-to-0-1"><i class="fa fa-check"></i><b>2.94</b> alternative hypothesis: true location shift is not equal to 0</a></li>
<li class="chapter" data-level="2.95" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-reading-1"><i class="fa fa-check"></i><b>2.95</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016-data"><i class="fa fa-check"></i><b>3.1</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data</a></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#loads-french_medial_vowel_devoicing.txt-from-osf-project-for-torreira-ernestus-2010-data"><i class="fa fa-check"></i><b>3.2</b> loads french_medial_vowel_devoicing.txt from OSF project for Torreira &amp; Ernestus (2010) data</a></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#loads-halfrhymemcgillling620.csv-from-osf-project-for-harder-2013-data"><i class="fa fa-check"></i><b>3.3</b> loads halfrhymeMcGillLing620.csv from OSF project for Harder (2013) data</a></li>
<li class="chapter" data-level="3.4" data-path="linear-regression.html"><a href="linear-regression.html#regression-general-introduction"><i class="fa fa-check"></i><b>3.4</b> Regression: General introduction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="linear-regression.html"><a href="linear-regression.html#linear-models"><i class="fa fa-check"></i><b>3.4.1</b> Linear models</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-regression.html"><a href="linear-regression.html#terminology"><i class="fa fa-check"></i><b>3.4.2</b> Terminology</a></li>
<li class="chapter" data-level="3.4.3" data-path="linear-regression.html"><a href="linear-regression.html#steps-and-assumptions-of-regression-analysis"><i class="fa fa-check"></i><b>3.4.3</b> Steps and assumptions of regression analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.5</b> Simple linear regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="linear-regression.html"><a href="linear-regression.html#slr-continuous-predictor"><i class="fa fa-check"></i><b>3.5.1</b> SLR: Continuous predictor</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency-rtlexdec"><i class="fa fa-check"></i><b>3.6</b> WrittenFrequency RTlexdec</a></li>
<li class="chapter" data-level="3.7" data-path="linear-regression.html"><a href="linear-regression.html#section-38"><i class="fa fa-check"></i><b>3.7</b> 1 3.912023 6.543754</a></li>
<li class="chapter" data-level="3.8" data-path="linear-regression.html"><a href="linear-regression.html#section-39"><i class="fa fa-check"></i><b>3.8</b> 2 4.521789 6.397596</a></li>
<li class="chapter" data-level="3.9" data-path="linear-regression.html"><a href="linear-regression.html#section-40"><i class="fa fa-check"></i><b>3.9</b> 3 6.505784 6.304942</a></li>
<li class="chapter" data-level="3.10" data-path="linear-regression.html"><a href="linear-regression.html#section-41"><i class="fa fa-check"></i><b>3.10</b> 4 5.017280 6.424221</a></li>
<li class="chapter" data-level="3.11" data-path="linear-regression.html"><a href="linear-regression.html#section-42"><i class="fa fa-check"></i><b>3.11</b> 5 4.890349 6.450597</a></li>
<li class="chapter" data-level="3.12" data-path="linear-regression.html"><a href="linear-regression.html#section-43"><i class="fa fa-check"></i><b>3.12</b> 6 4.770685 6.531970</a><ul>
<li class="chapter" data-level="3.12.1" data-path="linear-regression.html"><a href="linear-regression.html#slr-parameter-estimation"><i class="fa fa-check"></i><b>3.12.1</b> SLR: Parameter estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="linear-regression.html"><a href="linear-regression.html#section-44"><i class="fa fa-check"></i><b>3.13</b> </a></li>
<li class="chapter" data-level="3.14" data-path="linear-regression.html"><a href="linear-regression.html#call"><i class="fa fa-check"></i><b>3.14</b> Call:</a></li>
<li class="chapter" data-level="3.15" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-data-young"><i class="fa fa-check"></i><b>3.15</b> lm(formula = RTlexdec ~ WrittenFrequency, data = young)</a></li>
<li class="chapter" data-level="3.16" data-path="linear-regression.html"><a href="linear-regression.html#section-45"><i class="fa fa-check"></i><b>3.16</b> </a></li>
<li class="chapter" data-level="3.17" data-path="linear-regression.html"><a href="linear-regression.html#coefficients"><i class="fa fa-check"></i><b>3.17</b> Coefficients:</a></li>
<li class="chapter" data-level="3.18" data-path="linear-regression.html"><a href="linear-regression.html#intercept-writtenfrequency"><i class="fa fa-check"></i><b>3.18</b> (Intercept) WrittenFrequency</a></li>
<li class="chapter" data-level="3.19" data-path="linear-regression.html"><a href="linear-regression.html#section-46"><i class="fa fa-check"></i><b>3.19</b> 6.62556 -0.03711</a><ul>
<li class="chapter" data-level="3.19.1" data-path="linear-regression.html"><a href="linear-regression.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>3.19.1</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="3.20" data-path="linear-regression.html"><a href="linear-regression.html#section-47"><i class="fa fa-check"></i><b>3.20</b> </a></li>
<li class="chapter" data-level="3.21" data-path="linear-regression.html"><a href="linear-regression.html#call-1"><i class="fa fa-check"></i><b>3.21</b> Call:</a></li>
<li class="chapter" data-level="3.22" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-data-young-1"><i class="fa fa-check"></i><b>3.22</b> lm(formula = RTlexdec ~ WrittenFrequency, data = young)</a></li>
<li class="chapter" data-level="3.23" data-path="linear-regression.html"><a href="linear-regression.html#section-48"><i class="fa fa-check"></i><b>3.23</b> </a></li>
<li class="chapter" data-level="3.24" data-path="linear-regression.html"><a href="linear-regression.html#residuals"><i class="fa fa-check"></i><b>3.24</b> Residuals:</a></li>
<li class="chapter" data-level="3.25" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max"><i class="fa fa-check"></i><b>3.25</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.26" data-path="linear-regression.html"><a href="linear-regression.html#section-49"><i class="fa fa-check"></i><b>3.26</b> -0.34664 -0.05523 -0.00546 0.05167 0.34877</a></li>
<li class="chapter" data-level="3.27" data-path="linear-regression.html"><a href="linear-regression.html#section-50"><i class="fa fa-check"></i><b>3.27</b> </a></li>
<li class="chapter" data-level="3.28" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-1"><i class="fa fa-check"></i><b>3.28</b> Coefficients:</a></li>
<li class="chapter" data-level="3.29" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt"><i class="fa fa-check"></i><b>3.29</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.30" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.6255559-0.0049432-1340.34-2e-16-writtenfrequency--0.0371069-0.0009242--40.15-2e-16"><i class="fa fa-check"></i><b>3.30</b> (Intercept) 6.6255559 0.0049432 1340.34 &lt;2e-16 <strong><em> ## WrittenFrequency -0.0371069 0.0009242 -40.15 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.31" data-path="linear-regression.html"><a href="linear-regression.html#section-51"><i class="fa fa-check"></i><b>3.31</b> â</a></li>
<li class="chapter" data-level="3.32" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1"><i class="fa fa-check"></i><b>3.32</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.33" data-path="linear-regression.html"><a href="linear-regression.html#section-52"><i class="fa fa-check"></i><b>3.33</b> </a></li>
<li class="chapter" data-level="3.34" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.08142-on-2282-degrees-of-freedom"><i class="fa fa-check"></i><b>3.34</b> Residual standard error: 0.08142 on 2282 degrees of freedom</a></li>
<li class="chapter" data-level="3.35" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.414-adjusted-r-squared-0.4137"><i class="fa fa-check"></i><b>3.35</b> Multiple R-squared: 0.414, Adjusted R-squared: 0.4137</a></li>
<li class="chapter" data-level="3.36" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-1612-on-1-and-2282-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.36</b> F-statistic: 1612 on 1 and 2282 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.37" data-path="linear-regression.html"><a href="linear-regression.html#section-53"><i class="fa fa-check"></i><b>3.37</b> 2.5 % 97.5 %</a></li>
<li class="chapter" data-level="3.38" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.61586227-6.63524948"><i class="fa fa-check"></i><b>3.38</b> (Intercept) 6.61586227 6.63524948</a></li>
<li class="chapter" data-level="3.39" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency--0.03891921--0.03529463"><i class="fa fa-check"></i><b>3.39</b> WrittenFrequency -0.03891921 -0.03529463</a><ul>
<li class="chapter" data-level="3.39.1" data-path="linear-regression.html"><a href="linear-regression.html#quality-of-fit"><i class="fa fa-check"></i><b>3.39.1</b> Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="3.40" data-path="linear-regression.html"><a href="linear-regression.html#section-54"><i class="fa fa-check"></i><b>3.40</b> </a></li>
<li class="chapter" data-level="3.41" data-path="linear-regression.html"><a href="linear-regression.html#call-2"><i class="fa fa-check"></i><b>3.41</b> Call:</a></li>
<li class="chapter" data-level="3.42" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-data-d"><i class="fa fa-check"></i><b>3.42</b> lm(formula = RTlexdec ~ WrittenFrequency, data = d)</a></li>
<li class="chapter" data-level="3.43" data-path="linear-regression.html"><a href="linear-regression.html#section-55"><i class="fa fa-check"></i><b>3.43</b> </a></li>
<li class="chapter" data-level="3.44" data-path="linear-regression.html"><a href="linear-regression.html#residuals-1"><i class="fa fa-check"></i><b>3.44</b> Residuals:</a></li>
<li class="chapter" data-level="3.45" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-1"><i class="fa fa-check"></i><b>3.45</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.46" data-path="linear-regression.html"><a href="linear-regression.html#section-56"><i class="fa fa-check"></i><b>3.46</b> -0.127857 -0.045072 -0.005826 0.042917 0.235034</a></li>
<li class="chapter" data-level="3.47" data-path="linear-regression.html"><a href="linear-regression.html#section-57"><i class="fa fa-check"></i><b>3.47</b> </a></li>
<li class="chapter" data-level="3.48" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-2"><i class="fa fa-check"></i><b>3.48</b> Coefficients:</a></li>
<li class="chapter" data-level="3.49" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-1"><i class="fa fa-check"></i><b>3.49</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.50" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.61733-0.02190-302.236-2e-16-writtenfrequency--0.03501-0.00419--8.354-4.43e-13"><i class="fa fa-check"></i><b>3.50</b> (Intercept) 6.61733 0.02190 302.236 &lt; 2e-16 <strong><em> ## WrittenFrequency -0.03501 0.00419 -8.354 4.43e-13 </em></strong></a></li>
<li class="chapter" data-level="3.51" data-path="linear-regression.html"><a href="linear-regression.html#section-58"><i class="fa fa-check"></i><b>3.51</b> â</a></li>
<li class="chapter" data-level="3.52" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-1"><i class="fa fa-check"></i><b>3.52</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.53" data-path="linear-regression.html"><a href="linear-regression.html#section-59"><i class="fa fa-check"></i><b>3.53</b> </a></li>
<li class="chapter" data-level="3.54" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.07121-on-98-degrees-of-freedom"><i class="fa fa-check"></i><b>3.54</b> Residual standard error: 0.07121 on 98 degrees of freedom</a></li>
<li class="chapter" data-level="3.55" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.4159-adjusted-r-squared-0.41"><i class="fa fa-check"></i><b>3.55</b> Multiple R-squared: 0.4159, Adjusted R-squared: 0.41</a></li>
<li class="chapter" data-level="3.56" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-69.79-on-1-and-98-df-p-value-4.43e-13"><i class="fa fa-check"></i><b>3.56</b> F-statistic: 69.79 on 1 and 98 DF, p-value: 4.43e-13</a></li>
<li class="chapter" data-level="3.57" data-path="linear-regression.html"><a href="linear-regression.html#section-60"><i class="fa fa-check"></i><b>3.57</b> </a></li>
<li class="chapter" data-level="3.58" data-path="linear-regression.html"><a href="linear-regression.html#pearsons-product-moment-correlation"><i class="fa fa-check"></i><b>3.58</b> Pearsonâs product-moment correlation</a></li>
<li class="chapter" data-level="3.59" data-path="linear-regression.html"><a href="linear-regression.html#section-61"><i class="fa fa-check"></i><b>3.59</b> </a></li>
<li class="chapter" data-level="3.60" data-path="linear-regression.html"><a href="linear-regression.html#data-dwrittenfrequency-and-drtlexdec"><i class="fa fa-check"></i><b>3.60</b> data: d<span class="math inline">\(WrittenFrequency and d\)</span>RTlexdec</a></li>
<li class="chapter" data-level="3.61" data-path="linear-regression.html"><a href="linear-regression.html#t--8.354-df-98-p-value-4.43e-13"><i class="fa fa-check"></i><b>3.61</b> t = -8.354, df = 98, p-value = 4.43e-13</a></li>
<li class="chapter" data-level="3.62" data-path="linear-regression.html"><a href="linear-regression.html#alternative-hypothesis-true-correlation-is-not-equal-to-0"><i class="fa fa-check"></i><b>3.62</b> alternative hypothesis: true correlation is not equal to 0</a></li>
<li class="chapter" data-level="3.63" data-path="linear-regression.html"><a href="linear-regression.html#percent-confidence-interval-5"><i class="fa fa-check"></i><b>3.63</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="3.64" data-path="linear-regression.html"><a href="linear-regression.html#section-62"><i class="fa fa-check"></i><b>3.64</b> -0.7467533 -0.5135699</a></li>
<li class="chapter" data-level="3.65" data-path="linear-regression.html"><a href="linear-regression.html#sample-estimates-5"><i class="fa fa-check"></i><b>3.65</b> sample estimates:</a></li>
<li class="chapter" data-level="3.66" data-path="linear-regression.html"><a href="linear-regression.html#cor"><i class="fa fa-check"></i><b>3.66</b> cor</a></li>
<li class="chapter" data-level="3.67" data-path="linear-regression.html"><a href="linear-regression.html#section-63"><i class="fa fa-check"></i><b>3.67</b> -0.644931</a><ul>
<li class="chapter" data-level="3.67.1" data-path="linear-regression.html"><a href="linear-regression.html#categorical-predictor"><i class="fa fa-check"></i><b>3.67.1</b> Categorical predictor</a></li>
<li class="chapter" data-level="3.67.2" data-path="linear-regression.html"><a href="linear-regression.html#slr-with-a-binary-categorical-predictor-vs.two-sample-t-test"><i class="fa fa-check"></i><b>3.67.2</b> SLR with a binary categorical predictor vs.Â two-sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="3.68" data-path="linear-regression.html"><a href="linear-regression.html#section-64"><i class="fa fa-check"></i><b>3.68</b> </a></li>
<li class="chapter" data-level="3.69" data-path="linear-regression.html"><a href="linear-regression.html#two-sample-t-test-1"><i class="fa fa-check"></i><b>3.69</b> Two Sample t-test</a></li>
<li class="chapter" data-level="3.70" data-path="linear-regression.html"><a href="linear-regression.html#section-65"><i class="fa fa-check"></i><b>3.70</b> </a></li>
<li class="chapter" data-level="3.71" data-path="linear-regression.html"><a href="linear-regression.html#data-rtlexdec-by-agesubject"><i class="fa fa-check"></i><b>3.71</b> data: RTlexdec by AgeSubject</a></li>
<li class="chapter" data-level="3.72" data-path="linear-regression.html"><a href="linear-regression.html#t-67.468-df-4566-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.72</b> t = 67.468, df = 4566, p-value &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.73" data-path="linear-regression.html"><a href="linear-regression.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-4"><i class="fa fa-check"></i><b>3.73</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="3.74" data-path="linear-regression.html"><a href="linear-regression.html#percent-confidence-interval-6"><i class="fa fa-check"></i><b>3.74</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="3.75" data-path="linear-regression.html"><a href="linear-regression.html#section-66"><i class="fa fa-check"></i><b>3.75</b> 0.2152787 0.2281642</a></li>
<li class="chapter" data-level="3.76" data-path="linear-regression.html"><a href="linear-regression.html#sample-estimates-6"><i class="fa fa-check"></i><b>3.76</b> sample estimates:</a></li>
<li class="chapter" data-level="3.77" data-path="linear-regression.html"><a href="linear-regression.html#mean-in-group-old-mean-in-group-young"><i class="fa fa-check"></i><b>3.77</b> mean in group old mean in group young</a></li>
<li class="chapter" data-level="3.78" data-path="linear-regression.html"><a href="linear-regression.html#section-67"><i class="fa fa-check"></i><b>3.78</b> 6.660958 6.439237</a></li>
<li class="chapter" data-level="3.79" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.79</b> Multiple linear regression</a></li>
<li class="chapter" data-level="3.80" data-path="linear-regression.html"><a href="linear-regression.html#section-68"><i class="fa fa-check"></i><b>3.80</b> </a></li>
<li class="chapter" data-level="3.81" data-path="linear-regression.html"><a href="linear-regression.html#call-3"><i class="fa fa-check"></i><b>3.81</b> Call:</a></li>
<li class="chapter" data-level="3.82" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-agesubject-data-english"><i class="fa fa-check"></i><b>3.82</b> lm(formula = RTlexdec ~ WrittenFrequency + AgeSubject, data = english)</a></li>
<li class="chapter" data-level="3.83" data-path="linear-regression.html"><a href="linear-regression.html#section-69"><i class="fa fa-check"></i><b>3.83</b> </a></li>
<li class="chapter" data-level="3.84" data-path="linear-regression.html"><a href="linear-regression.html#residuals-2"><i class="fa fa-check"></i><b>3.84</b> Residuals:</a></li>
<li class="chapter" data-level="3.85" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-2"><i class="fa fa-check"></i><b>3.85</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.86" data-path="linear-regression.html"><a href="linear-regression.html#section-70"><i class="fa fa-check"></i><b>3.86</b> -0.34622 -0.06029 -0.00722 0.05178 0.44999</a></li>
<li class="chapter" data-level="3.87" data-path="linear-regression.html"><a href="linear-regression.html#section-71"><i class="fa fa-check"></i><b>3.87</b> </a></li>
<li class="chapter" data-level="3.88" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-3"><i class="fa fa-check"></i><b>3.88</b> Coefficients:</a></li>
<li class="chapter" data-level="3.89" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-2"><i class="fa fa-check"></i><b>3.89</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.90" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.8467921-0.0039792-1720.64-2e-16-writtenfrequency--0.0370103-0.0007033--52.62-2e-16"><i class="fa fa-check"></i><b>3.90</b> (Intercept) 6.8467921 0.0039792 1720.64 &lt;2e-16 <strong><em> ## WrittenFrequency -0.0370103 0.0007033 -52.62 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#agesubjectyoung--0.2217215-0.0025930--85.51-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08763-on-4565-degrees-of-freedom-multiple-r-squared-0.6883-adjusted-r-squared-0.6882-f-statistic-5040-on-2-and-4565-df-p-value-2.2e-16-1-6.661-goodness-of-fit-metrics-interactions-and-factors-example---call-lmformula-rtnaming-writtenfrequency-agesubject-data-english-residuals-min-1q-median-3q-max--0.160510--0.033425--0.002963-0.030855-0.181032-coefficients-estimate-std.-error-t-value-prt-intercept-6.5517608-0.0029118-2250.09-2e-16-writtenfrequency--0.0116031-0.0005444--21.31-2e-16-agesubjectyoung--0.3651823-0.0041179--88.68-2e-16-writtenfrequencyagesubjectyoung-0.0046191-0.0007699-6.00-2.13e-09-intercept-writtenfrequency-agesubjectyoung-writtenfrequencyagesubjectyoung-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.04796-on-4564-degrees-of-freedom-multiple-r-squared-0.9278-adjusted-r-squared-0.9278-f-statistic-1.956e04-on-3-and-4564-df-p-value-2.2e-16-plotting-interactions-categorical-factors-with-more-than-two-levels-exercise---call-lmformula-familysize-auxiliary-data-regularity-residuals-min-1q-median-3q-max--2.9133--0.7982--0.0250-0.7442-3.5983-coefficients-estimate-std.-error-t-value-prt-intercept-2.59000-0.04902-52.839-2e-16-auxiliaryzijn-0.39274-0.26780-1.467-0.1430-auxiliaryzijnheb-0.32329-0.12594-2.567-0.0105"><span class="toc-section-number">3.91</span> AgeSubjectyoung -0.2217215 0.0025930 -85.51 &lt;2e-16 <strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.08763 on 4565 degrees of freedom ## Multiple R-squared: 0.6883, Adjusted R-squared: 0.6882 ## F-statistic: 5040 on 2 and 4565 DF, p-value: &lt; 2.2e-16 ## [1] 6.661 ### Goodness of fit metrics ### Interactions and factors #### Example {-} ## ## Call: ## lm(formula = RTnaming ~ WrittenFrequency </em> AgeSubject, data = english) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.160510 -0.033425 -0.002963 0.030855 0.181032 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.5517608 0.0029118 2250.09 &lt; 2e-16 ## WrittenFrequency -0.0116031 0.0005444 -21.31 &lt; 2e-16 ## AgeSubjectyoung -0.3651823 0.0041179 -88.68 &lt; 2e-16 ## WrittenFrequency:AgeSubjectyoung 0.0046191 0.0007699 6.00 2.13e-09 ##<br />
## (Intercept) </strong><em> ## WrittenFrequency </em><strong> ## AgeSubjectyoung </strong><em> ## WrittenFrequency:AgeSubjectyoung </em><strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.04796 on 4564 degrees of freedom ## Multiple R-squared: 0.9278, Adjusted R-squared: 0.9278 ## F-statistic: 1.956e+04 on 3 and 4564 DF, p-value: &lt; 2.2e-16 ### Plotting interactions ### Categorical factors with more than two levels #### Exercise {-} ## ## Call: ## lm(formula = FamilySize ~ Auxiliary, data = regularity) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9133 -0.7982 -0.0250 0.7442 3.5983 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 2.59000 0.04902 52.839 &lt;2e-16 </strong><em> ## Auxiliaryzijn 0.39274 0.26780 1.467 0.1430<br />
## Auxiliaryzijnheb 0.32329 0.12594 2.567 0.0105 </em></a></li>
<li class="chapter" data-level="3.92" data-path="linear-regression.html"><a href="linear-regression.html#section-72"><i class="fa fa-check"></i><b>3.92</b> â</a></li>
<li class="chapter" data-level="3.93" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-2"><i class="fa fa-check"></i><b>3.93</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.94" data-path="linear-regression.html"><a href="linear-regression.html#section-73"><i class="fa fa-check"></i><b>3.94</b> </a></li>
<li class="chapter" data-level="3.95" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-1.177-on-697-degrees-of-freedom"><i class="fa fa-check"></i><b>3.95</b> Residual standard error: 1.177 on 697 degrees of freedom</a></li>
<li class="chapter" data-level="3.96" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.01169-adjusted-r-squared-0.008855"><i class="fa fa-check"></i><b>3.96</b> Multiple R-squared: 0.01169, Adjusted R-squared: 0.008855</a></li>
<li class="chapter" data-level="3.97" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-4.123-on-2-and-697-df-p-value-0.0166"><i class="fa fa-check"></i><b>3.97</b> F-statistic: 4.123 on 2 and 697 DF, p-value: 0.0166</a><ul>
<li class="chapter" data-level="3.97.1" data-path="linear-regression.html"><a href="linear-regression.html#releveling-factors"><i class="fa fa-check"></i><b>3.97.1</b> Releveling factors</a></li>
</ul></li>
<li class="chapter" data-level="3.98" data-path="linear-regression.html"><a href="linear-regression.html#section-74"><i class="fa fa-check"></i><b>3.98</b> </a></li>
<li class="chapter" data-level="3.99" data-path="linear-regression.html"><a href="linear-regression.html#call-4"><i class="fa fa-check"></i><b>3.99</b> Call:</a></li>
<li class="chapter" data-level="3.100" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-familysize-auxiliary-data-regularity"><i class="fa fa-check"></i><b>3.100</b> lm(formula = FamilySize ~ Auxiliary, data = regularity)</a></li>
<li class="chapter" data-level="3.101" data-path="linear-regression.html"><a href="linear-regression.html#section-75"><i class="fa fa-check"></i><b>3.101</b> </a></li>
<li class="chapter" data-level="3.102" data-path="linear-regression.html"><a href="linear-regression.html#residuals-3"><i class="fa fa-check"></i><b>3.102</b> Residuals:</a></li>
<li class="chapter" data-level="3.103" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-3"><i class="fa fa-check"></i><b>3.103</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.104" data-path="linear-regression.html"><a href="linear-regression.html#section-76"><i class="fa fa-check"></i><b>3.104</b> -2.9133 -0.7982 -0.0250 0.7442 3.5983</a></li>
<li class="chapter" data-level="3.105" data-path="linear-regression.html"><a href="linear-regression.html#section-77"><i class="fa fa-check"></i><b>3.105</b> </a></li>
<li class="chapter" data-level="3.106" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-4"><i class="fa fa-check"></i><b>3.106</b> Coefficients:</a></li>
<li class="chapter" data-level="3.107" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-3"><i class="fa fa-check"></i><b>3.107</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="linear-regression.html#intercept-2.98274-0.26328-11.329-2e-16-auxiliaryhebben--0.39274-0.26780--1.467-0.143-auxiliaryzijnheb--0.06946-0.28771--0.241-0.809-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-1.177-on-697-degrees-of-freedom-multiple-r-squared-0.01169-adjusted-r-squared-0.008855-f-statistic-4.123-on-2-and-697-df-p-value-0.0166-linear-regression-assumptions-linear-regression-assumptions-visual-methods-assumption-1-linearity-example---call-lmformula-rintensity-rduration-irduration2-data-alt-residuals-min-1q-median-3q-max--16.3199--3.5197--0.2448-2.9515-19.1480-coefficients-estimate-std.-error-t-value-prt-intercept-5.8280-0.2622-22.228-2e-16"><span class="toc-section-number">3.108</span> (Intercept) 2.98274 0.26328 11.329 &lt;2e-16 <strong><em> ## Auxiliaryhebben -0.39274 0.26780 -1.467 0.143<br />
## Auxiliaryzijnheb -0.06946 0.28771 -0.241 0.809<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 1.177 on 697 degrees of freedom ## Multiple R-squared: 0.01169, Adjusted R-squared: 0.008855 ## F-statistic: 4.123 on 2 and 697 DF, p-value: 0.0166 ## Linear regression assumptions {#linear-regression-assumptions} ### Visual methods ### Assumption 1: Linearity #### Example {-} ## ## Call: ## lm(formula = rintensity ~ rduration + I(rduration^2), data = alt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.3199 -3.5197 -0.2448 2.9515 19.1480 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 5.8280 0.2622 22.228 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.109" data-path="linear-regression.html"><a href="linear-regression.html#rduration-3.8841-0.3263-11.904-2e-16-irduration2--3.1381-0.3429--9.151-2e-16"><i class="fa fa-check"></i><b>3.109</b> rduration 3.8841 0.3263 11.904 &lt;2e-16 <strong><em> ## I(rduration^2) -3.1381 0.3429 -9.151 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.110" data-path="linear-regression.html"><a href="linear-regression.html#section-78"><i class="fa fa-check"></i><b>3.110</b> â</a></li>
<li class="chapter" data-level="3.111" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-3"><i class="fa fa-check"></i><b>3.111</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.112" data-path="linear-regression.html"><a href="linear-regression.html#section-79"><i class="fa fa-check"></i><b>3.112</b> </a></li>
<li class="chapter" data-level="3.113" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-5.05-on-627-degrees-of-freedom"><i class="fa fa-check"></i><b>3.113</b> Residual standard error: 5.05 on 627 degrees of freedom</a></li>
<li class="chapter" data-level="3.114" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.358-adjusted-r-squared-0.3559"><i class="fa fa-check"></i><b>3.114</b> Multiple R-squared: 0.358, Adjusted R-squared: 0.3559</a></li>
<li class="chapter" data-level="3.115" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-174.8-on-2-and-627-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.115</b> F-statistic: 174.8 on 2 and 627 DF, p-value: &lt; 2.2e-16</a><ul>
<li class="chapter" data-level="3.115.1" data-path="linear-regression.html"><a href="linear-regression.html#c2ioe"><i class="fa fa-check"></i><b>3.115.1</b> Assumption 2: Independence of errors</a></li>
<li class="chapter" data-level="3.115.2" data-path="linear-regression.html"><a href="linear-regression.html#assumption-3-normality-of-errors"><i class="fa fa-check"></i><b>3.115.2</b> Assumption 3: Normality of errors</a></li>
<li class="chapter" data-level="3.115.3" data-path="linear-regression.html"><a href="linear-regression.html#assumtion-4-constancy-of-variance"><i class="fa fa-check"></i><b>3.115.3</b> Assumtion 4: Constancy of variance</a></li>
<li class="chapter" data-level="3.115.4" data-path="linear-regression.html"><a href="linear-regression.html#interim-summary"><i class="fa fa-check"></i><b>3.115.4</b> Interim summary</a></li>
<li class="chapter" data-level="3.115.5" data-path="linear-regression.html"><a href="linear-regression.html#transforming-to-normality"><i class="fa fa-check"></i><b>3.115.5</b> Transforming to normality</a></li>
<li class="chapter" data-level="3.115.6" data-path="linear-regression.html"><a href="linear-regression.html#assumption-5-linear-independence-of-predictors"><i class="fa fa-check"></i><b>3.115.6</b> Assumption 5: Linear independence of predictors</a></li>
<li class="chapter" data-level="3.115.7" data-path="linear-regression.html"><a href="linear-regression.html#collinearity"><i class="fa fa-check"></i><b>3.115.7</b> Collinearity</a></li>
</ul></li>
<li class="chapter" data-level="3.116" data-path="linear-regression.html"><a href="linear-regression.html#section-80"><i class="fa fa-check"></i><b>3.116</b> </a></li>
<li class="chapter" data-level="3.117" data-path="linear-regression.html"><a href="linear-regression.html#call-5"><i class="fa fa-check"></i><b>3.117</b> Call:</a></li>
<li class="chapter" data-level="3.118" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-familiarity-data-d"><i class="fa fa-check"></i><b>3.118</b> lm(formula = RTlexdec ~ Familiarity, data = d)</a></li>
<li class="chapter" data-level="3.119" data-path="linear-regression.html"><a href="linear-regression.html#section-81"><i class="fa fa-check"></i><b>3.119</b> </a></li>
<li class="chapter" data-level="3.120" data-path="linear-regression.html"><a href="linear-regression.html#residuals-4"><i class="fa fa-check"></i><b>3.120</b> Residuals:</a></li>
<li class="chapter" data-level="3.121" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-4"><i class="fa fa-check"></i><b>3.121</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.122" data-path="linear-regression.html"><a href="linear-regression.html#section-82"><i class="fa fa-check"></i><b>3.122</b> -0.094956 -0.035753 0.002142 0.050448 0.093090</a></li>
<li class="chapter" data-level="3.123" data-path="linear-regression.html"><a href="linear-regression.html#section-83"><i class="fa fa-check"></i><b>3.123</b> </a></li>
<li class="chapter" data-level="3.124" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-5"><i class="fa fa-check"></i><b>3.124</b> Coefficients:</a></li>
<li class="chapter" data-level="3.125" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-4"><i class="fa fa-check"></i><b>3.125</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.126" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.645471-0.038231-173.83-2e-16-familiarity--0.047697-0.009502--5.02-4.44e-05"><i class="fa fa-check"></i><b>3.126</b> (Intercept) 6.645471 0.038231 173.83 &lt; 2e-16 <strong><em> ## Familiarity -0.047697 0.009502 -5.02 4.44e-05 </em></strong></a></li>
<li class="chapter" data-level="3.127" data-path="linear-regression.html"><a href="linear-regression.html#section-84"><i class="fa fa-check"></i><b>3.127</b> â</a></li>
<li class="chapter" data-level="3.128" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-4"><i class="fa fa-check"></i><b>3.128</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.129" data-path="linear-regression.html"><a href="linear-regression.html#section-85"><i class="fa fa-check"></i><b>3.129</b> </a></li>
<li class="chapter" data-level="3.130" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.05699-on-23-degrees-of-freedom"><i class="fa fa-check"></i><b>3.130</b> Residual standard error: 0.05699 on 23 degrees of freedom</a></li>
<li class="chapter" data-level="3.131" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.5228-adjusted-r-squared-0.502"><i class="fa fa-check"></i><b>3.131</b> Multiple R-squared: 0.5228, Adjusted R-squared: 0.502</a></li>
<li class="chapter" data-level="3.132" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-25.2-on-1-and-23-df-p-value-4.442e-05"><i class="fa fa-check"></i><b>3.132</b> F-statistic: 25.2 on 1 and 23 DF, p-value: 4.442e-05</a></li>
<li class="chapter" data-level="3.133" data-path="linear-regression.html"><a href="linear-regression.html#section-86"><i class="fa fa-check"></i><b>3.133</b> </a></li>
<li class="chapter" data-level="3.134" data-path="linear-regression.html"><a href="linear-regression.html#call-6"><i class="fa fa-check"></i><b>3.134</b> Call:</a></li>
<li class="chapter" data-level="3.135" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-familiarity-writtenfrequency-lengthinletters"><i class="fa fa-check"></i><b>3.135</b> lm(formula = RTlexdec ~ Familiarity + WrittenFrequency + LengthInLetters,</a></li>
<li class="chapter" data-level="3.136" data-path="linear-regression.html"><a href="linear-regression.html#data-d"><i class="fa fa-check"></i><b>3.136</b> data = d)</a></li>
<li class="chapter" data-level="3.137" data-path="linear-regression.html"><a href="linear-regression.html#section-87"><i class="fa fa-check"></i><b>3.137</b> </a></li>
<li class="chapter" data-level="3.138" data-path="linear-regression.html"><a href="linear-regression.html#residuals-5"><i class="fa fa-check"></i><b>3.138</b> Residuals:</a></li>
<li class="chapter" data-level="3.139" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-5"><i class="fa fa-check"></i><b>3.139</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.140" data-path="linear-regression.html"><a href="linear-regression.html#section-88"><i class="fa fa-check"></i><b>3.140</b> -0.090416 -0.040823 -0.008442 0.042555 0.094739</a></li>
<li class="chapter" data-level="3.141" data-path="linear-regression.html"><a href="linear-regression.html#section-89"><i class="fa fa-check"></i><b>3.141</b> </a></li>
<li class="chapter" data-level="3.142" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-6"><i class="fa fa-check"></i><b>3.142</b> Coefficients:</a></li>
<li class="chapter" data-level="3.143" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-5"><i class="fa fa-check"></i><b>3.143</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="linear-regression.html#intercept-6.66953-0.07094-94.013-2e-16-familiarity--0.03333-0.01821--1.831-0.0814-.-writtenfrequency--0.01017-0.01117--0.911-0.3728-lengthinletters--0.00643-0.01410--0.456-0.6530-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.05838-on-21-degrees-of-freedom-multiple-r-squared-0.5429-adjusted-r-squared-0.4776-f-statistic-8.313-on-3-and-21-df-p-value-0.0007782-effects-of-collinearity-diagnosing-collinearity-1-16.0162-is-collinearity-a-problem-assumption-6-observations-measuring-influence-lin-reg-measuring-influence-example---outliers-regression-assumptions-reassurance-model-comparison-lm-model-comparison-nested-model-comparison-example---c2ex1-analysis-of-variance-table-model-1-rtlexdec-writtenfrequency-model-2-rtlexdec-writtenfrequency-agesubject-lengthinletters-res.df-rss-df-sum-of-sq-f-prf-1-4566-91.194-2-4564-35.004-2-56.19-3663.1-2.2e-16"><span class="toc-section-number">3.144</span> (Intercept) 6.66953 0.07094 94.013 &lt;2e-16 <strong><em> ## Familiarity -0.03333 0.01821 -1.831 0.0814 .<br />
## WrittenFrequency -0.01017 0.01117 -0.911 0.3728<br />
## LengthInLetters -0.00643 0.01410 -0.456 0.6530<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.05838 on 21 degrees of freedom ## Multiple R-squared: 0.5429, Adjusted R-squared: 0.4776 ## F-statistic: 8.313 on 3 and 21 DF, p-value: 0.0007782 #### Effects of collinearity #### Diagnosing collinearity<br />
## [1] 16.0162 #### Is collinearity a problem? ### Assumption 6: Observations ### Measuring influence {#lin-reg-measuring-influence} #### Example {-} ### Outliers ### Regression assumptions: Reassurance ## Model comparison {#lm-model-comparison} ### Nested model comparison #### Example {- #c2ex1} ## Analysis of Variance Table ## ## Model 1: RTlexdec ~ WrittenFrequency ## Model 2: RTlexdec ~ WrittenFrequency + AgeSubject + LengthInLetters ## Res.Df RSS Df Sum of Sq F Pr(&gt;F)<br />
## 1 4566 91.194<br />
## 2 4564 35.004 2 56.19 3663.1 &lt; 2.2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.145" data-path="linear-regression.html"><a href="linear-regression.html#section-90"><i class="fa fa-check"></i><b>3.145</b> â</a></li>
<li class="chapter" data-level="3.146" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-5"><i class="fa fa-check"></i><b>3.146</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a><ul>
<li class="chapter" data-level="3.146.1" data-path="linear-regression.html"><a href="linear-regression.html#non-nested-model-comparison"><i class="fa fa-check"></i><b>3.146.1</b> Non-nested model comparison</a></li>
</ul></li>
<li class="chapter" data-level="3.147" data-path="linear-regression.html"><a href="linear-regression.html#df-aic"><i class="fa fa-check"></i><b>3.147</b> df AIC</a></li>
<li class="chapter" data-level="3.148" data-path="linear-regression.html"><a href="linear-regression.html#m1-3--4908.994"><i class="fa fa-check"></i><b>3.148</b> m1 3 -4908.994</a></li>
<li class="chapter" data-level="3.149" data-path="linear-regression.html"><a href="linear-regression.html#m2-4--9274.590"><i class="fa fa-check"></i><b>3.149</b> m2 4 -9274.590</a></li>
<li class="chapter" data-level="3.150" data-path="linear-regression.html"><a href="linear-regression.html#m3-5--9278.948"><i class="fa fa-check"></i><b>3.150</b> m3 5 -9278.948</a></li>
<li class="chapter" data-level="3.151" data-path="linear-regression.html"><a href="linear-regression.html#m4-4--4909.437"><i class="fa fa-check"></i><b>3.151</b> m4 4 -4909.437</a></li>
<li class="chapter" data-level="3.152" data-path="linear-regression.html"><a href="linear-regression.html#df-bic"><i class="fa fa-check"></i><b>3.152</b> df BIC</a></li>
<li class="chapter" data-level="3.153" data-path="linear-regression.html"><a href="linear-regression.html#m1-3--4889.713"><i class="fa fa-check"></i><b>3.153</b> m1 3 -4889.713</a></li>
<li class="chapter" data-level="3.154" data-path="linear-regression.html"><a href="linear-regression.html#m2-4--9248.883"><i class="fa fa-check"></i><b>3.154</b> m2 4 -9248.883</a></li>
<li class="chapter" data-level="3.155" data-path="linear-regression.html"><a href="linear-regression.html#m3-5--9246.814"><i class="fa fa-check"></i><b>3.155</b> m3 5 -9246.814</a></li>
<li class="chapter" data-level="3.156" data-path="linear-regression.html"><a href="linear-regression.html#m4-4--4883.729"><i class="fa fa-check"></i><b>3.156</b> m4 4 -4883.729</a><ul>
<li class="chapter" data-level="3.156.1" data-path="linear-regression.html"><a href="linear-regression.html#c2varselect"><i class="fa fa-check"></i><b>3.156.1</b> Variable selection</a></li>
</ul></li>
<li class="chapter" data-level="3.157" data-path="linear-regression.html"><a href="linear-regression.html#split-the-english-data-in-half-randomly"><i class="fa fa-check"></i><b>3.157</b> split the English data in half, randomly:</a></li>
<li class="chapter" data-level="3.158" data-path="linear-regression.html"><a href="linear-regression.html#fit-full-model-to-each-half-dataset"><i class="fa fa-check"></i><b>3.158</b> fit full model to each half-dataset</a></li>
<li class="chapter" data-level="3.159" data-path="linear-regression.html"><a href="linear-regression.html#trace0-suppresses-ouput"><i class="fa fa-check"></i><b>3.159</b> trace=0 suppresses ouput</a></li>
<li class="chapter" data-level="3.160" data-path="linear-regression.html"><a href="linear-regression.html#the-two-resulting-models"><i class="fa fa-check"></i><b>3.160</b> the two resulting models</a></li>
<li class="chapter" data-level="3.161" data-path="linear-regression.html"><a href="linear-regression.html#section-91"><i class="fa fa-check"></i><b>3.161</b> </a></li>
<li class="chapter" data-level="3.162" data-path="linear-regression.html"><a href="linear-regression.html#call-7"><i class="fa fa-check"></i><b>3.162</b> Call:</a></li>
<li class="chapter" data-level="3.163" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-familiarity-agesubject"><i class="fa fa-check"></i><b>3.163</b> lm(formula = RTlexdec ~ WrittenFrequency + Familiarity + AgeSubject +</a></li>
<li class="chapter" data-level="3.164" data-path="linear-regression.html"><a href="linear-regression.html#lengthinletters-familysize-writtenfrequencyfamiliarity"><i class="fa fa-check"></i><b>3.164</b> LengthInLetters + FamilySize + WrittenFrequency:Familiarity +</a></li>
<li class="chapter" data-level="3.165" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyagesubject-writtenfrequencylengthinletters"><i class="fa fa-check"></i><b>3.165</b> WrittenFrequency:AgeSubject + WrittenFrequency:LengthInLetters +</a></li>
<li class="chapter" data-level="3.166" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamilysize-familiarityagesubject-familiaritylengthinletters"><i class="fa fa-check"></i><b>3.166</b> WrittenFrequency:FamilySize + Familiarity:AgeSubject + Familiarity:LengthInLetters +</a></li>
<li class="chapter" data-level="3.167" data-path="linear-regression.html"><a href="linear-regression.html#familiarityfamilysize-agesubjectlengthinletters-lengthinlettersfamilysize"><i class="fa fa-check"></i><b>3.167</b> Familiarity:FamilySize + AgeSubject:LengthInLetters + LengthInLetters:FamilySize +</a></li>
<li class="chapter" data-level="3.168" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamiliarityagesubject-writtenfrequencyagesubjectlengthinletters"><i class="fa fa-check"></i><b>3.168</b> WrittenFrequency:Familiarity:AgeSubject + WrittenFrequency:AgeSubject:LengthInLetters,</a></li>
<li class="chapter" data-level="3.169" data-path="linear-regression.html"><a href="linear-regression.html#data-english.1"><i class="fa fa-check"></i><b>3.169</b> data = english.1)</a></li>
<li class="chapter" data-level="3.170" data-path="linear-regression.html"><a href="linear-regression.html#section-92"><i class="fa fa-check"></i><b>3.170</b> </a></li>
<li class="chapter" data-level="3.171" data-path="linear-regression.html"><a href="linear-regression.html#residuals-6"><i class="fa fa-check"></i><b>3.171</b> Residuals:</a></li>
<li class="chapter" data-level="3.172" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-6"><i class="fa fa-check"></i><b>3.172</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.173" data-path="linear-regression.html"><a href="linear-regression.html#section-93"><i class="fa fa-check"></i><b>3.173</b> -0.42008 -0.05175 -0.00326 0.04572 0.37444</a></li>
<li class="chapter" data-level="3.174" data-path="linear-regression.html"><a href="linear-regression.html#section-94"><i class="fa fa-check"></i><b>3.174</b> </a></li>
<li class="chapter" data-level="3.175" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-7"><i class="fa fa-check"></i><b>3.175</b> Coefficients:</a></li>
<li class="chapter" data-level="3.176" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error"><i class="fa fa-check"></i><b>3.176</b> Estimate Std. Error</a></li>
<li class="chapter" data-level="3.177" data-path="linear-regression.html"><a href="linear-regression.html#intercept-7.189260-0.045538"><i class="fa fa-check"></i><b>3.177</b> (Intercept) 7.189260 0.045538</a></li>
<li class="chapter" data-level="3.178" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency--0.084197-0.011610"><i class="fa fa-check"></i><b>3.178</b> WrittenFrequency -0.084197 0.011610</a></li>
<li class="chapter" data-level="3.179" data-path="linear-regression.html"><a href="linear-regression.html#familiarity--0.058426-0.014137"><i class="fa fa-check"></i><b>3.179</b> Familiarity -0.058426 0.014137</a></li>
<li class="chapter" data-level="3.180" data-path="linear-regression.html"><a href="linear-regression.html#agesubjectyoung--0.413999-0.058362"><i class="fa fa-check"></i><b>3.180</b> AgeSubjectyoung -0.413999 0.058362</a></li>
<li class="chapter" data-level="3.181" data-path="linear-regression.html"><a href="linear-regression.html#lengthinletters--0.004709-0.008692"><i class="fa fa-check"></i><b>3.181</b> LengthInLetters -0.004709 0.008692</a></li>
<li class="chapter" data-level="3.182" data-path="linear-regression.html"><a href="linear-regression.html#familysize--0.112072-0.018225"><i class="fa fa-check"></i><b>3.182</b> FamilySize -0.112072 0.018225</a></li>
<li class="chapter" data-level="3.183" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamiliarity-0.008855-0.001203"><i class="fa fa-check"></i><b>3.183</b> WrittenFrequency:Familiarity 0.008855 0.001203</a></li>
<li class="chapter" data-level="3.184" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyagesubjectyoung-0.045885-0.011738"><i class="fa fa-check"></i><b>3.184</b> WrittenFrequency:AgeSubjectyoung 0.045885 0.011738</a></li>
<li class="chapter" data-level="3.185" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencylengthinletters-0.004581-0.002131"><i class="fa fa-check"></i><b>3.185</b> WrittenFrequency:LengthInLetters 0.004581 0.002131</a></li>
<li class="chapter" data-level="3.186" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamilysize-0.005662-0.001863"><i class="fa fa-check"></i><b>3.186</b> WrittenFrequency:FamilySize 0.005662 0.001863</a></li>
<li class="chapter" data-level="3.187" data-path="linear-regression.html"><a href="linear-regression.html#familiarityagesubjectyoung-0.030455-0.008445"><i class="fa fa-check"></i><b>3.187</b> Familiarity:AgeSubjectyoung 0.030455 0.008445</a></li>
<li class="chapter" data-level="3.188" data-path="linear-regression.html"><a href="linear-regression.html#familiaritylengthinletters--0.006493-0.002830"><i class="fa fa-check"></i><b>3.188</b> Familiarity:LengthInLetters -0.006493 0.002830</a></li>
<li class="chapter" data-level="3.189" data-path="linear-regression.html"><a href="linear-regression.html#familiarityfamilysize-0.007705-0.003262"><i class="fa fa-check"></i><b>3.189</b> Familiarity:FamilySize 0.007705 0.003262</a></li>
<li class="chapter" data-level="3.190" data-path="linear-regression.html"><a href="linear-regression.html#agesubjectyounglengthinletters-0.013042-0.011006"><i class="fa fa-check"></i><b>3.190</b> AgeSubjectyoung:LengthInLetters 0.013042 0.011006</a></li>
<li class="chapter" data-level="3.191" data-path="linear-regression.html"><a href="linear-regression.html#lengthinlettersfamilysize-0.006179-0.003240"><i class="fa fa-check"></i><b>3.191</b> LengthInLetters:FamilySize 0.006179 0.003240</a></li>
<li class="chapter" data-level="3.192" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamiliarityagesubjectyoung--0.006894-0.001396"><i class="fa fa-check"></i><b>3.192</b> WrittenFrequency:Familiarity:AgeSubjectyoung -0.006894 0.001396</a></li>
<li class="chapter" data-level="3.193" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyagesubjectyounglengthinletters--0.003181-0.002059"><i class="fa fa-check"></i><b>3.193</b> WrittenFrequency:AgeSubjectyoung:LengthInLetters -0.003181 0.002059</a></li>
<li class="chapter" data-level="3.194" data-path="linear-regression.html"><a href="linear-regression.html#t-value-prt"><i class="fa fa-check"></i><b>3.194</b> t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.195" data-path="linear-regression.html"><a href="linear-regression.html#intercept-157.875-2e-16-writtenfrequency--7.252-5.61e-13"><i class="fa fa-check"></i><b>3.195</b> (Intercept) 157.875 &lt; 2e-16 <strong><em> ## WrittenFrequency -7.252 5.61e-13 </em></strong></a></li>
<li class="chapter" data-level="3.196" data-path="linear-regression.html"><a href="linear-regression.html#familiarity--4.133-3.71e-05-agesubjectyoung--7.094-1.74e-12"><i class="fa fa-check"></i><b>3.196</b> Familiarity -4.133 3.71e-05 <strong><em> ## AgeSubjectyoung -7.094 1.74e-12 </em></strong></a></li>
<li class="chapter" data-level="3.197" data-path="linear-regression.html"><a href="linear-regression.html#lengthinletters--0.542-0.588063"><i class="fa fa-check"></i><b>3.197</b> LengthInLetters -0.542 0.588063</a></li>
<li class="chapter" data-level="3.198" data-path="linear-regression.html"><a href="linear-regression.html#familysize--6.149-9.17e-10-writtenfrequencyfamiliarity-7.360-2.56e-13"><i class="fa fa-check"></i><b>3.198</b> FamilySize -6.149 9.17e-10 <strong><em> ## WrittenFrequency:Familiarity 7.360 2.56e-13 </em></strong></a></li>
<li><a href="linear-regression.html#writtenfrequencyagesubjectyoung-3.909-9.53e-05-writtenfrequencylengthinletters-2.150-0.031699-writtenfrequencyfamilysize-3.039-0.002405"><span class="toc-section-number">3.199</span> WrittenFrequency:AgeSubjectyoung 3.909 9.53e-05 <strong><em> ## WrittenFrequency:LengthInLetters 2.150 0.031699 </em><br />
## WrittenFrequency:FamilySize 3.039 0.002405 </strong></a></li>
<li><a href="linear-regression.html#familiarityagesubjectyoung-3.606-0.000317-familiaritylengthinletters--2.295-0.021842-familiarityfamilysize-2.362-0.018245-agesubjectyounglengthinletters-1.185-0.236150-lengthinlettersfamilysize-1.907-0.056609-.-writtenfrequencyfamiliarityagesubjectyoung--4.940-8.39e-07-writtenfrequencyagesubjectyounglengthinletters--1.545-0.122548-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.07727-on-2267-degrees-of-freedom-multiple-r-squared-0.755-adjusted-r-squared-0.7533-f-statistic-436.6-on-16-and-2267-df-p-value-2.2e-16-call-lmformula-rtlexdec-writtenfrequency-familiarity-agesubject-lengthinletters-familysize-writtenfrequencyfamiliarity-writtenfrequencylengthinletters-writtenfrequencyfamilysize-familiarityagesubject-familiaritylengthinletters-familiarityfamilysize-lengthinlettersfamilysize-writtenfrequencylengthinlettersfamilysize-data-english.2-residuals-min-1q-median-3q-max--0.30263--0.05327--0.00526-0.04654-0.50932-coefficients-estimate-std.-error-t-value-intercept-7.0214673-0.0616493-113.894-writtenfrequency--0.0338445-0.0137689--2.458-familiarity--0.0768169-0.0139772--5.496-agesubjectyoung--0.2047469-0.0113464--18.045-lengthinletters-0.0228065-0.0137176-1.663-familysize--0.0362279-0.0365663--0.991-writtenfrequencyfamiliarity-0.0072404-0.0009183-7.884-writtenfrequencylengthinletters--0.0024614-0.0029950--0.822-writtenfrequencyfamilysize--0.0096833-0.0055442--1.747-familiarityagesubjectyoung--0.0042687-0.0028607--1.492-familiaritylengthinletters--0.0044449-0.0028657--1.551-familiarityfamilysize-0.0137811-0.0031320-4.400-lengthinlettersfamilysize--0.0059273-0.0082370--0.720-writtenfrequencylengthinlettersfamilysize-0.0020024-0.0012937-1.548-prt-intercept-2e-16-writtenfrequency-0.0140-familiarity-4.32e-08-agesubjectyoung-2e-16-lengthinletters-0.0965-.-familysize-0.3219-writtenfrequencyfamiliarity-4.87e-15-writtenfrequencylengthinletters-0.4113-writtenfrequencyfamilysize-0.0808-.-familiarityagesubjectyoung-0.1358-familiaritylengthinletters-0.1210-familiarityfamilysize-1.13e-05-lengthinlettersfamilysize-0.4718-writtenfrequencylengthinlettersfamilysize-0.1218-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08024-on-2270-degrees-of-freedom-multiple-r-squared-0.7444-adjusted-r-squared-0.7429-f-statistic-508.4-on-13-and-2270-df-p-value-2.2e-16-method-3-gelman2007data-exercise-phrase-medial-devoicing-in-european-french---c2ex5-analysis-of-variance-table-model-1-syldur-speechrate-c1-v2-model-2-syldur-speechrate-c1-v2-func-model-3-syldur-speechrate-c1-v2-func-res.df-rss-df-sum-of-sq-f-prf-1-529-528092-2-528-518990-1-9102.4-9.3121-0.002392"><span class="toc-section-number">3.200</span> Familiarity:AgeSubjectyoung 3.606 0.000317 <strong><em> ## Familiarity:LengthInLetters -2.295 0.021842 </em><br />
## Familiarity:FamilySize 2.362 0.018245 *<br />
## AgeSubjectyoung:LengthInLetters 1.185 0.236150<br />
## LengthInLetters:FamilySize 1.907 0.056609 .<br />
## WrittenFrequency:Familiarity:AgeSubjectyoung -4.940 8.39e-07 </strong><em> ## WrittenFrequency:AgeSubjectyoung:LengthInLetters -1.545 0.122548<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.07727 on 2267 degrees of freedom ## Multiple R-squared: 0.755, Adjusted R-squared: 0.7533 ## F-statistic: 436.6 on 16 and 2267 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + Familiarity + AgeSubject + ## LengthInLetters + FamilySize + WrittenFrequency:Familiarity + ## WrittenFrequency:LengthInLetters + WrittenFrequency:FamilySize + ## Familiarity:AgeSubject + Familiarity:LengthInLetters + Familiarity:FamilySize + ## LengthInLetters:FamilySize + WrittenFrequency:LengthInLetters:FamilySize, ## data = english.2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.30263 -0.05327 -0.00526 0.04654 0.50932 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 7.0214673 0.0616493 113.894 ## WrittenFrequency -0.0338445 0.0137689 -2.458 ## Familiarity -0.0768169 0.0139772 -5.496 ## AgeSubjectyoung -0.2047469 0.0113464 -18.045 ## LengthInLetters 0.0228065 0.0137176 1.663 ## FamilySize -0.0362279 0.0365663 -0.991 ## WrittenFrequency:Familiarity 0.0072404 0.0009183 7.884 ## WrittenFrequency:LengthInLetters -0.0024614 0.0029950 -0.822 ## WrittenFrequency:FamilySize -0.0096833 0.0055442 -1.747 ## Familiarity:AgeSubjectyoung -0.0042687 0.0028607 -1.492 ## Familiarity:LengthInLetters -0.0044449 0.0028657 -1.551 ## Familiarity:FamilySize 0.0137811 0.0031320 4.400 ## LengthInLetters:FamilySize -0.0059273 0.0082370 -0.720 ## WrittenFrequency:LengthInLetters:FamilySize 0.0020024 0.0012937 1.548 ## Pr(&gt;|t|)<br />
## (Intercept) &lt; 2e-16 </em><strong> ## WrittenFrequency 0.0140 *<br />
## Familiarity 4.32e-08 </strong><em> ## AgeSubjectyoung &lt; 2e-16 </em><strong> ## LengthInLetters 0.0965 .<br />
## FamilySize 0.3219<br />
## WrittenFrequency:Familiarity 4.87e-15 </strong><em> ## WrittenFrequency:LengthInLetters 0.4113<br />
## WrittenFrequency:FamilySize 0.0808 .<br />
## Familiarity:AgeSubjectyoung 0.1358<br />
## Familiarity:LengthInLetters 0.1210<br />
## Familiarity:FamilySize 1.13e-05 </em><strong> ## LengthInLetters:FamilySize 0.4718<br />
## WrittenFrequency:LengthInLetters:FamilySize 0.1218<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.08024 on 2270 degrees of freedom ## Multiple R-squared: 0.7444, Adjusted R-squared: 0.7429 ## F-statistic: 508.4 on 13 and 2270 DF, p-value: &lt; 2.2e-16 #### Method 3: <span class="citation">Gelman &amp; Hill (<a href="#ref-gelman2007data">2007</a>)</span> #### Exercise: Phrase medial devoicing in European French {- #c2ex5} ## Analysis of Variance Table ## ## Model 1: syldur ~ (speechrate + c1 + v)^2 ## Model 2: syldur ~ (speechrate + c1 + v)^2 + func ## Model 3: syldur ~ (speechrate + c1 + v)^2 * func ## Res.Df RSS Df Sum of Sq F Pr(&gt;F)<br />
## 1 529 528092<br />
## 2 528 518990 1 9102.4 9.3121 0.002392 </strong></a></li>
<li class="chapter" data-level="3.201" data-path="linear-regression.html"><a href="linear-regression.html#section-95"><i class="fa fa-check"></i><b>3.201</b> 3 523 511219 5 7770.7 1.5900 0.161123</a></li>
<li class="chapter" data-level="3.202" data-path="linear-regression.html"><a href="linear-regression.html#section-96"><i class="fa fa-check"></i><b>3.202</b> â</a></li>
<li class="chapter" data-level="3.203" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-6"><i class="fa fa-check"></i><b>3.203</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.204" data-path="linear-regression.html"><a href="linear-regression.html#section-97"><i class="fa fa-check"></i><b>3.204</b> </a></li>
<li class="chapter" data-level="3.205" data-path="linear-regression.html"><a href="linear-regression.html#call-8"><i class="fa fa-check"></i><b>3.205</b> Call:</a></li>
<li class="chapter" data-level="3.206" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-speechrate-c1-v2-func-data-df"><i class="fa fa-check"></i><b>3.206</b> lm(formula = syldur ~ (speechrate + c1 + v)^2 + func, data = df)</a></li>
<li class="chapter" data-level="3.207" data-path="linear-regression.html"><a href="linear-regression.html#section-98"><i class="fa fa-check"></i><b>3.207</b> </a></li>
<li class="chapter" data-level="3.208" data-path="linear-regression.html"><a href="linear-regression.html#residuals-7"><i class="fa fa-check"></i><b>3.208</b> Residuals:</a></li>
<li class="chapter" data-level="3.209" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-7"><i class="fa fa-check"></i><b>3.209</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.210" data-path="linear-regression.html"><a href="linear-regression.html#section-99"><i class="fa fa-check"></i><b>3.210</b> -130.682 -21.233 0.304 20.544 103.960</a></li>
<li class="chapter" data-level="3.211" data-path="linear-regression.html"><a href="linear-regression.html#section-100"><i class="fa fa-check"></i><b>3.211</b> </a></li>
<li class="chapter" data-level="3.212" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-1-not-defined-because-of-singularities"><i class="fa fa-check"></i><b>3.212</b> Coefficients: (1 not defined because of singularities)</a></li>
<li class="chapter" data-level="3.213" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-6"><i class="fa fa-check"></i><b>3.213</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.214" data-path="linear-regression.html"><a href="linear-regression.html#intercept-247.5718-23.8023-10.401-2e-16-speechrate--15.6166-3.2983--4.735-2.82e-06"><i class="fa fa-check"></i><b>3.214</b> (Intercept) 247.5718 23.8023 10.401 &lt; 2e-16 <strong><em> ## speechrate -15.6166 3.2983 -4.735 2.82e-06 </em></strong></a></li>
<li><a href="linear-regression.html#c1k--89.2652-26.6617--3.348-0.000872-c1p--67.4682-39.4741--1.709-0.088006-.-c1s--27.7955-26.1708--1.062-0.288683-c1t--68.6392-27.3605--2.509-0.012416-vu-4.6582-31.5829-0.147-0.882802-vy-16.2882-20.2343-0.805-0.421194-funcf--13.8005-4.5350--3.043-0.002458"><span class="toc-section-number">3.215</span> c1k -89.2652 26.6617 -3.348 0.000872 <strong><em> ## c1p -67.4682 39.4741 -1.709 0.088006 .<br />
## c1s -27.7955 26.1708 -1.062 0.288683<br />
## c1t -68.6392 27.3605 -2.509 0.012416 </em><br />
## vu 4.6582 31.5829 0.147 0.882802<br />
## vy 16.2882 20.2343 0.805 0.421194<br />
## funcf -13.8005 4.5350 -3.043 0.002458 </strong></a></li>
<li><a href="linear-regression.html#speechratec1k-9.5259-3.7368-2.549-0.011077-speechratec1p-9.2280-5.8037-1.590-0.112428"><span class="toc-section-number">3.216</span> speechrate:c1k 9.5259 3.7368 2.549 0.011077 *<br />
## speechrate:c1p 9.2280 5.8037 1.590 0.112428</a></li>
<li class="chapter" data-level="3.217" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-4.4121-3.5902-1.229-0.219637"><i class="fa fa-check"></i><b>3.217</b> speechrate:c1s 4.4121 3.5902 1.229 0.219637</a></li>
<li><a href="linear-regression.html#speechratec1t-7.5638-3.7154-2.036-0.042268-speechratevu--0.6849-3.9631--0.173-0.862851"><span class="toc-section-number">3.218</span> speechrate:c1t 7.5638 3.7154 2.036 0.042268 *<br />
## speechrate:vu -0.6849 3.9631 -0.173 0.862851</a></li>
<li class="chapter" data-level="3.219" data-path="linear-regression.html"><a href="linear-regression.html#speechratevy--1.6412-2.6474--0.620-0.535579"><i class="fa fa-check"></i><b>3.219</b> speechrate:vy -1.6412 2.6474 -0.620 0.535579</a></li>
<li class="chapter" data-level="3.220" data-path="linear-regression.html"><a href="linear-regression.html#c1kvu-19.8107-22.1307-0.895-0.371104"><i class="fa fa-check"></i><b>3.220</b> c1k:vu 19.8107 22.1307 0.895 0.371104</a></li>
<li class="chapter" data-level="3.221" data-path="linear-regression.html"><a href="linear-regression.html#c1pvu--1.3369-25.6737--0.052-0.958489"><i class="fa fa-check"></i><b>3.221</b> c1p:vu -1.3369 25.6737 -0.052 0.958489</a></li>
<li class="chapter" data-level="3.222" data-path="linear-regression.html"><a href="linear-regression.html#c1svu-0.9348-22.3409-0.042-0.966639"><i class="fa fa-check"></i><b>3.222</b> c1s:vu 0.9348 22.3409 0.042 0.966639</a></li>
<li class="chapter" data-level="3.223" data-path="linear-regression.html"><a href="linear-regression.html#c1tvu-na-na-na-na"><i class="fa fa-check"></i><b>3.223</b> c1t:vu NA NA NA NA</a></li>
<li class="chapter" data-level="3.224" data-path="linear-regression.html"><a href="linear-regression.html#c1kvy--3.1728-13.8966--0.228-0.819491"><i class="fa fa-check"></i><b>3.224</b> c1k:vy -3.1728 13.8966 -0.228 0.819491</a></li>
<li class="chapter" data-level="3.225" data-path="linear-regression.html"><a href="linear-regression.html#c1pvy--9.7528-15.2713--0.639-0.523338"><i class="fa fa-check"></i><b>3.225</b> c1p:vy -9.7528 15.2713 -0.639 0.523338</a></li>
<li class="chapter" data-level="3.226" data-path="linear-regression.html"><a href="linear-regression.html#c1svy--18.2987-11.6317--1.573-0.116279"><i class="fa fa-check"></i><b>3.226</b> c1s:vy -18.2987 11.6317 -1.573 0.116279</a></li>
<li class="chapter" data-level="3.227" data-path="linear-regression.html"><a href="linear-regression.html#c1tvy--5.4756-11.9582--0.458-0.647219"><i class="fa fa-check"></i><b>3.227</b> c1t:vy -5.4756 11.9582 -0.458 0.647219</a></li>
<li class="chapter" data-level="3.228" data-path="linear-regression.html"><a href="linear-regression.html#section-101"><i class="fa fa-check"></i><b>3.228</b> â</a></li>
<li class="chapter" data-level="3.229" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-7"><i class="fa fa-check"></i><b>3.229</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.230" data-path="linear-regression.html"><a href="linear-regression.html#section-102"><i class="fa fa-check"></i><b>3.230</b> </a></li>
<li class="chapter" data-level="3.231" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.35-on-528-degrees-of-freedom"><i class="fa fa-check"></i><b>3.231</b> Residual standard error: 31.35 on 528 degrees of freedom</a></li>
<li class="chapter" data-level="3.232" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.3012-adjusted-r-squared-0.2734"><i class="fa fa-check"></i><b>3.232</b> Multiple R-squared: 0.3012, Adjusted R-squared: 0.2734</a></li>
<li class="chapter" data-level="3.233" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-10.84-on-21-and-528-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.233</b> F-statistic: 10.84 on 21 and 528 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.234" data-path="linear-regression.html"><a href="linear-regression.html#section-103"><i class="fa fa-check"></i><b>3.234</b> </a></li>
<li class="chapter" data-level="3.235" data-path="linear-regression.html"><a href="linear-regression.html#call-9"><i class="fa fa-check"></i><b>3.235</b> Call:</a></li>
<li class="chapter" data-level="3.236" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-speechrate-c1-func-speechratec1"><i class="fa fa-check"></i><b>3.236</b> lm(formula = syldur ~ speechrate + c1 + func + speechrate:c1 +</a></li>
<li class="chapter" data-level="3.237" data-path="linear-regression.html"><a href="linear-regression.html#c1func-data-df"><i class="fa fa-check"></i><b>3.237</b> c1:func, data = df)</a></li>
<li class="chapter" data-level="3.238" data-path="linear-regression.html"><a href="linear-regression.html#section-104"><i class="fa fa-check"></i><b>3.238</b> </a></li>
<li class="chapter" data-level="3.239" data-path="linear-regression.html"><a href="linear-regression.html#residuals-8"><i class="fa fa-check"></i><b>3.239</b> Residuals:</a></li>
<li class="chapter" data-level="3.240" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-8"><i class="fa fa-check"></i><b>3.240</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.241" data-path="linear-regression.html"><a href="linear-regression.html#section-105"><i class="fa fa-check"></i><b>3.241</b> -129.449 -19.780 0.762 21.343 104.048</a></li>
<li class="chapter" data-level="3.242" data-path="linear-regression.html"><a href="linear-regression.html#section-106"><i class="fa fa-check"></i><b>3.242</b> </a></li>
<li class="chapter" data-level="3.243" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-2-not-defined-because-of-singularities"><i class="fa fa-check"></i><b>3.243</b> Coefficients: (2 not defined because of singularities)</a></li>
<li class="chapter" data-level="3.244" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-7"><i class="fa fa-check"></i><b>3.244</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.245" data-path="linear-regression.html"><a href="linear-regression.html#intercept-255.813-20.798-12.300-2e-16-speechrate--16.508-2.991--5.520-5.3e-08"><i class="fa fa-check"></i><b>3.245</b> (Intercept) 255.813 20.798 12.300 &lt; 2e-16 <strong><em> ## speechrate -16.508 2.991 -5.520 5.3e-08 </em></strong></a></li>
<li><a href="linear-regression.html#c1k--87.803-25.813--3.401-0.000720-c1p--71.475-37.858--1.888-0.059566-.-c1s--41.730-23.963--1.741-0.082180-.-c1t--64.292-24.776--2.595-0.009719-funcf--21.398-5.558--3.850-0.000132-speechratec1k-10.350-3.559-2.908-0.003785"><span class="toc-section-number">3.246</span> c1k -87.803 25.813 -3.401 0.000720 <em><strong> ## c1p -71.475 37.858 -1.888 0.059566 .<br />
## c1s -41.730 23.963 -1.741 0.082180 .<br />
## c1t -64.292 24.776 -2.595 0.009719 </strong> ## funcf -21.398 5.558 -3.850 0.000132 </em><strong> ## speechrate:c1k 10.350 3.559 2.908 0.003785 </strong></a></li>
<li class="chapter" data-level="3.247" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1p-9.105-5.564-1.637-0.102310"><i class="fa fa-check"></i><b>3.247</b> speechrate:c1p 9.105 5.564 1.637 0.102310</a></li>
<li class="chapter" data-level="3.248" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-5.058-3.422-1.478-0.139894"><i class="fa fa-check"></i><b>3.248</b> speechrate:c1s 5.058 3.422 1.478 0.139894</a></li>
<li><a href="linear-regression.html#speechratec1t-7.322-3.498-2.093-0.036832-c1kfuncf--1.833-8.565--0.214-0.830655"><span class="toc-section-number">3.249</span> speechrate:c1t 7.322 3.498 2.093 0.036832 *<br />
## c1k:funcf -1.833 8.565 -0.214 0.830655</a></li>
<li class="chapter" data-level="3.250" data-path="linear-regression.html"><a href="linear-regression.html#c1pfuncf-na-na-na-na"><i class="fa fa-check"></i><b>3.250</b> c1p:funcf NA NA NA NA</a></li>
<li><a href="linear-regression.html#c1sfuncf-17.373-7.218-2.407-0.016427-c1tfuncf-na-na-na-na"><span class="toc-section-number">3.251</span> c1s:funcf 17.373 7.218 2.407 0.016427 *<br />
## c1t:funcf NA NA NA NA</a></li>
<li class="chapter" data-level="3.252" data-path="linear-regression.html"><a href="linear-regression.html#section-107"><i class="fa fa-check"></i><b>3.252</b> â</a></li>
<li class="chapter" data-level="3.253" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-8"><i class="fa fa-check"></i><b>3.253</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.254" data-path="linear-regression.html"><a href="linear-regression.html#section-108"><i class="fa fa-check"></i><b>3.254</b> </a></li>
<li class="chapter" data-level="3.255" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.14-on-537-degrees-of-freedom"><i class="fa fa-check"></i><b>3.255</b> Residual standard error: 31.14 on 537 degrees of freedom</a></li>
<li class="chapter" data-level="3.256" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.2987-adjusted-r-squared-0.283"><i class="fa fa-check"></i><b>3.256</b> Multiple R-squared: 0.2987, Adjusted R-squared: 0.283</a></li>
<li class="chapter" data-level="3.257" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-19.06-on-12-and-537-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.257</b> F-statistic: 19.06 on 12 and 537 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.258" data-path="linear-regression.html"><a href="linear-regression.html#section-109"><i class="fa fa-check"></i><b>3.258</b> </a></li>
<li class="chapter" data-level="3.259" data-path="linear-regression.html"><a href="linear-regression.html#call-10"><i class="fa fa-check"></i><b>3.259</b> Call:</a></li>
<li class="chapter" data-level="3.260" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-speechrate-c1-v-func-data-df"><i class="fa fa-check"></i><b>3.260</b> lm(formula = syldur ~ speechrate + c1 + v + func, data = df)</a></li>
<li class="chapter" data-level="3.261" data-path="linear-regression.html"><a href="linear-regression.html#section-110"><i class="fa fa-check"></i><b>3.261</b> </a></li>
<li class="chapter" data-level="3.262" data-path="linear-regression.html"><a href="linear-regression.html#residuals-9"><i class="fa fa-check"></i><b>3.262</b> Residuals:</a></li>
<li class="chapter" data-level="3.263" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-9"><i class="fa fa-check"></i><b>3.263</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.264" data-path="linear-regression.html"><a href="linear-regression.html#section-111"><i class="fa fa-check"></i><b>3.264</b> -131.151 -21.337 0.863 20.419 98.228</a></li>
<li class="chapter" data-level="3.265" data-path="linear-regression.html"><a href="linear-regression.html#section-112"><i class="fa fa-check"></i><b>3.265</b> </a></li>
<li class="chapter" data-level="3.266" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-8"><i class="fa fa-check"></i><b>3.266</b> Coefficients:</a></li>
<li class="chapter" data-level="3.267" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-8"><i class="fa fa-check"></i><b>3.267</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.268" data-path="linear-regression.html"><a href="linear-regression.html#intercept-208.8600-7.9734-26.195-2e-16-speechrate--9.5866-0.9546--10.043-2e-16"><i class="fa fa-check"></i><b>3.268</b> (Intercept) 208.8600 7.9734 26.195 &lt; 2e-16 <strong><em> ## speechrate -9.5866 0.9546 -10.043 &lt; 2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#c1k--26.6525-5.8330--4.569-6.07e-06-c1p--11.0561-6.9893--1.582-0.11426-c1s--2.9871-5.3464--0.559-0.57659-c1t--18.3920-5.8075--3.167-0.00163-vu-12.3446-6.1420-2.010-0.04494"><span class="toc-section-number">3.269</span> c1k -26.6525 5.8330 -4.569 6.07e-06 <em><strong> ## c1p -11.0561 6.9893 -1.582 0.11426<br />
## c1s -2.9871 5.3464 -0.559 0.57659<br />
## c1t -18.3920 5.8075 -3.167 0.00163 </strong> ## vu 12.3446 6.1420 2.010 0.04494 </em></a></li>
<li class="chapter" data-level="3.270" data-path="linear-regression.html"><a href="linear-regression.html#vy--2.0698-3.4933--0.592-0.55377"><i class="fa fa-check"></i><b>3.270</b> vy -2.0698 3.4933 -0.592 0.55377</a></li>
<li><a href="linear-regression.html#funcf--13.3345-3.2684--4.080-5.19e-05-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-31.47-on-541-degrees-of-freedom-multiple-r-squared-0.2787-adjusted-r-squared-0.2681-f-statistic-26.13-on-8-and-541-df-p-value-2.2e-16-call-lmformula-syldur-speechrate-func-c1-v-data-df-residuals-min-1q-median-3q-max--130.275--20.390-0.522-20.501-103.274-coefficients-estimate-std.-error-t-value-prt-intercept-255.785-22.952-11.144-2e-16-speechrate--16.386-3.274--5.005-7.58e-07-funcf--29.289-17.059--1.717-0.08658-.-c1k--86.729-28.237--3.071-0.00224"><span class="toc-section-number">3.271</span> funcf -13.3345 3.2684 -4.080 5.19e-05 <strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 31.47 on 541 degrees of freedom ## Multiple R-squared: 0.2787, Adjusted R-squared: 0.2681 ## F-statistic: 26.13 on 8 and 541 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = syldur ~ speechrate </em> (func + c1 + v), data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -130.275 -20.390 0.522 20.501 103.274 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 255.785 22.952 11.144 &lt; 2e-16 </strong><em> ## speechrate -16.386 3.274 -5.005 7.58e-07 </em><strong> ## funcf -29.289 17.059 -1.717 0.08658 .<br />
## c1k -86.729 28.237 -3.071 0.00224 </strong></a></li>
<li class="chapter" data-level="3.272" data-path="linear-regression.html"><a href="linear-regression.html#c1p--66.594-38.304--1.739-0.08269-."><i class="fa fa-check"></i><b>3.272</b> c1p -66.594 38.304 -1.739 0.08269 .</a></li>
<li class="chapter" data-level="3.273" data-path="linear-regression.html"><a href="linear-regression.html#c1s--29.059-26.392--1.101-0.27137"><i class="fa fa-check"></i><b>3.273</b> c1s -29.059 26.392 -1.101 0.27137</a></li>
<li><a href="linear-regression.html#c1t--60.538-27.829--2.175-0.03004-vu--6.158-27.997--0.220-0.82599"><span class="toc-section-number">3.274</span> c1t -60.538 27.829 -2.175 0.03004 *<br />
## vu -6.158 27.997 -0.220 0.82599</a></li>
<li class="chapter" data-level="3.275" data-path="linear-regression.html"><a href="linear-regression.html#vy-3.596-18.342-0.196-0.84463"><i class="fa fa-check"></i><b>3.275</b> vy 3.596 18.342 0.196 0.84463</a></li>
<li class="chapter" data-level="3.276" data-path="linear-regression.html"><a href="linear-regression.html#speechratefuncf-2.364-2.384-0.992-0.32172"><i class="fa fa-check"></i><b>3.276</b> speechrate:funcf 2.364 2.384 0.992 0.32172</a></li>
<li><a href="linear-regression.html#speechratec1k-8.949-4.009-2.232-0.02604-speechratec1p-8.235-5.645-1.459-0.14522"><span class="toc-section-number">3.277</span> speechrate:c1k 8.949 4.009 2.232 0.02604 *<br />
## speechrate:c1p 8.235 5.645 1.459 0.14522</a></li>
<li class="chapter" data-level="3.278" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-3.813-3.775-1.010-0.31291"><i class="fa fa-check"></i><b>3.278</b> speechrate:c1s 3.813 3.775 1.010 0.31291</a></li>
<li class="chapter" data-level="3.279" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1t-6.203-3.965-1.564-0.11829"><i class="fa fa-check"></i><b>3.279</b> speechrate:c1t 6.203 3.965 1.564 0.11829</a></li>
<li class="chapter" data-level="3.280" data-path="linear-regression.html"><a href="linear-regression.html#speechratevu-2.217-3.953-0.561-0.57512"><i class="fa fa-check"></i><b>3.280</b> speechrate:vu 2.217 3.953 0.561 0.57512</a></li>
<li class="chapter" data-level="3.281" data-path="linear-regression.html"><a href="linear-regression.html#speechratevy--1.013-2.585--0.392-0.69529"><i class="fa fa-check"></i><b>3.281</b> speechrate:vy -1.013 2.585 -0.392 0.69529</a></li>
<li class="chapter" data-level="3.282" data-path="linear-regression.html"><a href="linear-regression.html#section-113"><i class="fa fa-check"></i><b>3.282</b> â</a></li>
<li class="chapter" data-level="3.283" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-9"><i class="fa fa-check"></i><b>3.283</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.284" data-path="linear-regression.html"><a href="linear-regression.html#section-114"><i class="fa fa-check"></i><b>3.284</b> </a></li>
<li class="chapter" data-level="3.285" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.32-on-534-degrees-of-freedom"><i class="fa fa-check"></i><b>3.285</b> Residual standard error: 31.32 on 534 degrees of freedom</a></li>
<li class="chapter" data-level="3.286" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.2945-adjusted-r-squared-0.2747"><i class="fa fa-check"></i><b>3.286</b> Multiple R-squared: 0.2945, Adjusted R-squared: 0.2747</a></li>
<li class="chapter" data-level="3.287" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-14.86-on-15-and-534-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.287</b> F-statistic: 14.86 on 15 and 534 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.288" data-path="linear-regression.html"><a href="linear-regression.html#section-115"><i class="fa fa-check"></i><b>3.288</b> </a></li>
<li class="chapter" data-level="3.289" data-path="linear-regression.html"><a href="linear-regression.html#call-11"><i class="fa fa-check"></i><b>3.289</b> Call:</a></li>
<li class="chapter" data-level="3.290" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-func-speechrate-c1-v-data-df"><i class="fa fa-check"></i><b>3.290</b> lm(formula = syldur ~ func * (speechrate + c1 + v), data = df)</a></li>
<li class="chapter" data-level="3.291" data-path="linear-regression.html"><a href="linear-regression.html#section-116"><i class="fa fa-check"></i><b>3.291</b> </a></li>
<li class="chapter" data-level="3.292" data-path="linear-regression.html"><a href="linear-regression.html#residuals-10"><i class="fa fa-check"></i><b>3.292</b> Residuals:</a></li>
<li class="chapter" data-level="3.293" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-10"><i class="fa fa-check"></i><b>3.293</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.294" data-path="linear-regression.html"><a href="linear-regression.html#section-117"><i class="fa fa-check"></i><b>3.294</b> -132.663 -21.550 1.495 18.620 101.766</a></li>
<li class="chapter" data-level="3.295" data-path="linear-regression.html"><a href="linear-regression.html#section-118"><i class="fa fa-check"></i><b>3.295</b> </a></li>
<li class="chapter" data-level="3.296" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-4-not-defined-because-of-singularities"><i class="fa fa-check"></i><b>3.296</b> Coefficients: (4 not defined because of singularities)</a></li>
<li class="chapter" data-level="3.297" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-9"><i class="fa fa-check"></i><b>3.297</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="linear-regression.html#intercept-223.1977-11.2756-19.795-2e-16-funcf--46.3965-14.9707--3.099-0.00204-speechrate--11.8593-1.4817--8.004-7.47e-15-c1k--18.3159-7.5125--2.438-0.01509-c1p--11.6366-6.9622--1.671-0.09522-.-c1s--7.8271-5.5722--1.405-0.16070-c1t--13.3023-6.4106--2.075-0.03846-vu-11.5966-6.8487-1.693-0.09098-.-vy-0.8120-4.3953-0.185-0.85350-funcfspeechrate-3.4852-1.9453-1.792-0.07376-.-funcfc1k-0.3863-10.7540-0.036-0.97136-funcfc1p-na-na-na-na-funcfc1s-19.3740-8.7143-2.223-0.02661-funcfc1t-na-na-na-na-funcfvu-na-na-na-na-funcfvy-na-na-na-na-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-31.22-on-538-degrees-of-freedom-multiple-r-squared-0.2941-adjusted-r-squared-0.2797-f-statistic-20.38-on-11-and-538-df-p-value-2.2e-16-call-lmformula-syldur-speechrate-c1-func-speechratec1-funcc1-data-df-residuals-min-1q-median-3q-max--129.449--19.780-0.762-21.343-104.048-coefficients-2-not-defined-because-of-singularities-estimate-std.-error-t-value-prt-intercept-255.813-20.798-12.300-2e-16-speechrate--16.508-2.991--5.520-5.3e-08-c1k--87.803-25.813--3.401-0.000720-c1p--71.475-37.858--1.888-0.059566-.-c1s--41.730-23.963--1.741-0.082180-.-c1t--64.292-24.776--2.595-0.009719-funcf--21.398-5.558--3.850-0.000132"><span class="toc-section-number">3.298</span> (Intercept) 223.1977 11.2756 19.795 &lt; 2e-16 <em><strong> ## funcf -46.3965 14.9707 -3.099 0.00204 </strong> ## speechrate -11.8593 1.4817 -8.004 7.47e-15 </em><strong> ## c1k -18.3159 7.5125 -2.438 0.01509 *<br />
## c1p -11.6366 6.9622 -1.671 0.09522 .<br />
## c1s -7.8271 5.5722 -1.405 0.16070<br />
## c1t -13.3023 6.4106 -2.075 0.03846 *<br />
## vu 11.5966 6.8487 1.693 0.09098 .<br />
## vy 0.8120 4.3953 0.185 0.85350<br />
## funcf:speechrate 3.4852 1.9453 1.792 0.07376 .<br />
## funcf:c1k 0.3863 10.7540 0.036 0.97136<br />
## funcf:c1p NA NA NA NA<br />
## funcf:c1s 19.3740 8.7143 2.223 0.02661 *<br />
## funcf:c1t NA NA NA NA<br />
## funcf:vu NA NA NA NA<br />
## funcf:vy NA NA NA NA<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 31.22 on 538 degrees of freedom ## Multiple R-squared: 0.2941, Adjusted R-squared: 0.2797 ## F-statistic: 20.38 on 11 and 538 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = syldur ~ speechrate + c1 + func + speechrate:c1 + ## func:c1, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -129.449 -19.780 0.762 21.343 104.048 ## ## Coefficients: (2 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 255.813 20.798 12.300 &lt; 2e-16 </strong><em> ## speechrate -16.508 2.991 -5.520 5.3e-08 </em><strong> ## c1k -87.803 25.813 -3.401 0.000720 </strong><em> ## c1p -71.475 37.858 -1.888 0.059566 .<br />
## c1s -41.730 23.963 -1.741 0.082180 .<br />
## c1t -64.292 24.776 -2.595 0.009719 <strong> ## funcf -21.398 5.558 -3.850 0.000132 </strong></em></a></li>
<li class="chapter" data-level="3.299" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1k-10.350-3.559-2.908-0.003785"><i class="fa fa-check"></i><b>3.299</b> speechrate:c1k 10.350 3.559 2.908 0.003785 **</a></li>
<li class="chapter" data-level="3.300" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1p-9.105-5.564-1.637-0.102310-1"><i class="fa fa-check"></i><b>3.300</b> speechrate:c1p 9.105 5.564 1.637 0.102310</a></li>
<li class="chapter" data-level="3.301" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-5.058-3.422-1.478-0.139894-1"><i class="fa fa-check"></i><b>3.301</b> speechrate:c1s 5.058 3.422 1.478 0.139894</a></li>
<li><a href="linear-regression.html#speechratec1t-7.322-3.498-2.093-0.036832-c1kfuncf--1.833-8.565--0.214-0.830655-1"><span class="toc-section-number">3.302</span> speechrate:c1t 7.322 3.498 2.093 0.036832 *<br />
## c1k:funcf -1.833 8.565 -0.214 0.830655</a></li>
<li class="chapter" data-level="3.303" data-path="linear-regression.html"><a href="linear-regression.html#c1pfuncf-na-na-na-na-1"><i class="fa fa-check"></i><b>3.303</b> c1p:funcf NA NA NA NA</a></li>
<li><a href="linear-regression.html#c1sfuncf-17.373-7.218-2.407-0.016427-c1tfuncf-na-na-na-na-1"><span class="toc-section-number">3.304</span> c1s:funcf 17.373 7.218 2.407 0.016427 *<br />
## c1t:funcf NA NA NA NA</a></li>
<li class="chapter" data-level="3.305" data-path="linear-regression.html"><a href="linear-regression.html#section-119"><i class="fa fa-check"></i><b>3.305</b> â</a></li>
<li class="chapter" data-level="3.306" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-10"><i class="fa fa-check"></i><b>3.306</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.307" data-path="linear-regression.html"><a href="linear-regression.html#section-120"><i class="fa fa-check"></i><b>3.307</b> </a></li>
<li class="chapter" data-level="3.308" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.14-on-537-degrees-of-freedom-1"><i class="fa fa-check"></i><b>3.308</b> Residual standard error: 31.14 on 537 degrees of freedom</a></li>
<li class="chapter" data-level="3.309" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.2987-adjusted-r-squared-0.283-1"><i class="fa fa-check"></i><b>3.309</b> Multiple R-squared: 0.2987, Adjusted R-squared: 0.283</a></li>
<li class="chapter" data-level="3.310" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-19.06-on-12-and-537-df-p-value-2.2e-16-1"><i class="fa fa-check"></i><b>3.310</b> F-statistic: 19.06 on 12 and 537 DF, p-value: &lt; 2.2e-16</a><ul>
<li class="chapter" data-level="3.310.1" data-path="linear-regression.html"><a href="linear-regression.html#interpretability-issues"><i class="fa fa-check"></i><b>3.310.1</b> Interpretability issues</a></li>
</ul></li>
<li class="chapter" data-level="3.311" data-path="linear-regression.html"><a href="linear-regression.html#section-121"><i class="fa fa-check"></i><b>3.311</b> </a></li>
<li class="chapter" data-level="3.312" data-path="linear-regression.html"><a href="linear-regression.html#call-12"><i class="fa fa-check"></i><b>3.312</b> Call:</a></li>
<li class="chapter" data-level="3.313" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-lengthinletters"><i class="fa fa-check"></i><b>3.313</b> lm(formula = RTlexdec ~ WrittenFrequency + LengthInLetters +</a></li>
<li class="chapter" data-level="3.314" data-path="linear-regression.html"><a href="linear-regression.html#agesubject-data-english"><i class="fa fa-check"></i><b>3.314</b> AgeSubject, data = english)</a></li>
<li class="chapter" data-level="3.315" data-path="linear-regression.html"><a href="linear-regression.html#section-122"><i class="fa fa-check"></i><b>3.315</b> </a></li>
<li class="chapter" data-level="3.316" data-path="linear-regression.html"><a href="linear-regression.html#residuals-11"><i class="fa fa-check"></i><b>3.316</b> Residuals:</a></li>
<li class="chapter" data-level="3.317" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-11"><i class="fa fa-check"></i><b>3.317</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.318" data-path="linear-regression.html"><a href="linear-regression.html#section-123"><i class="fa fa-check"></i><b>3.318</b> -0.34438 -0.06041 -0.00695 0.05241 0.45157</a></li>
<li class="chapter" data-level="3.319" data-path="linear-regression.html"><a href="linear-regression.html#section-124"><i class="fa fa-check"></i><b>3.319</b> </a></li>
<li class="chapter" data-level="3.320" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-9"><i class="fa fa-check"></i><b>3.320</b> Coefficients:</a></li>
<li class="chapter" data-level="3.321" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-10"><i class="fa fa-check"></i><b>3.321</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.322" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.8293072-0.0079946-854.245-2e-16-writtenfrequency--0.0368919-0.0007045--52.366-2e-16"><i class="fa fa-check"></i><b>3.322</b> (Intercept) 6.8293072 0.0079946 854.245 &lt;2e-16 <strong><em> ## WrittenFrequency -0.0368919 0.0007045 -52.366 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#lengthinletters-0.0038897-0.0015428-2.521-0.0117-agesubjectyoung--0.2217215-0.0025915--85.556-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08758-on-4564-degrees-of-freedom-multiple-r-squared-0.6887-adjusted-r-squared-0.6885-f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16-solutions-example---call-lmformula-rtlexdec-writtenfrequency-lengthinletters-agesubject-data-english-residuals-min-1q-median-3q-max--0.34438--0.06041--0.00695-0.05241-0.45157-coefficients-estimate-std.-error-t-value-prt-intercept-6.8293072-0.0079946-854.245-2e-16"><span class="toc-section-number">3.323</span> LengthInLetters 0.0038897 0.0015428 2.521 0.0117 *<br />
## AgeSubjectyoung -0.2217215 0.0025915 -85.556 &lt;2e-16 <strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.08758 on 4564 degrees of freedom ## Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885 ## F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16 #### Solutions #### Example {-} ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + LengthInLetters + ## AgeSubject, data = english) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.34438 -0.06041 -0.00695 0.05241 0.45157 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 6.8293072 0.0079946 854.245 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#writtenfrequency--0.0368919-0.0007045--52.366-2e-16-lengthinletters-0.0038897-0.0015428-2.521-0.0117-agesubjectyoung--0.2217215-0.0025915--85.556-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08758-on-4564-degrees-of-freedom-multiple-r-squared-0.6887-adjusted-r-squared-0.6885-f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16-call-lmformula-rtlexdec-writtenfrequency-lengthinletters-agesubject-data-english2-residuals-min-1q-median-3q-max--0.34438--0.06041--0.00695-0.05241-0.45157-coefficients-estimate-std.-error-t-value-prt-intercept-6.550097-0.001296-5055.020-2e-16-writtenfrequency--0.136025-0.002598--52.366-2e-16-lengthinletters-0.006549-0.002598-2.521-0.0117"><span class="toc-section-number">3.324</span> WrittenFrequency -0.0368919 0.0007045 -52.366 &lt;2e-16 <strong><em> ## LengthInLetters 0.0038897 0.0015428 2.521 0.0117 </em><br />
## AgeSubjectyoung -0.2217215 0.0025915 -85.556 &lt;2e-16 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.08758 on 4564 degrees of freedom ## Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885 ## F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + LengthInLetters + ## AgeSubject, data = english2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.34438 -0.06041 -0.00695 0.05241 0.45157 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 6.550097 0.001296 5055.020 &lt;2e-16 </em><strong> ## WrittenFrequency -0.136025 0.002598 -52.366 &lt;2e-16 </strong><em> ## LengthInLetters 0.006549 0.002598 2.521 0.0117 </em></a></li>
<li><a href="linear-regression.html#agesubject--0.221721-0.002592--85.556-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08758-on-4564-degrees-of-freedom-multiple-r-squared-0.6887-adjusted-r-squared-0.6885-f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16-interim-recipe-building-a-multiple-linear-regression-model-solutions-c2solns-multiple-linear-regression-solutions-regression-equation-1---c2sol1-regression-equation-2---c2sol2-linear-regression-assumptions-solutions-model-comparison-solutions-call-lmformula-rtlexdec-writtenfrequency-agesubject-lengthinletters-data-english-residuals-min-1q-median-3q-max--0.34438--0.06041--0.00695-0.05241-0.45157-coefficients-estimate-std.-error-t-value-prt-intercept-6.8293072-0.0079946-854.245-2e-16"><span class="toc-section-number">3.325</span> AgeSubject -0.221721 0.002592 -85.556 &lt;2e-16 <strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 0.08758 on 4564 degrees of freedom ## Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885 ## F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16 ### Interim recipe: Building a multiple linear regression model ## Solutions {#c2solns} ### Multiple linear regression: Solutions #### Regression equation 1 {- #c2sol1} #### Regression equation 2 {- #c2sol2} ### Linear regression assumptions: Solutions ### Model comparison: Solutions ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + AgeSubject + LengthInLetters, ## data = english) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.34438 -0.06041 -0.00695 0.05241 0.45157 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 6.8293072 0.0079946 854.245 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.326" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency--0.0368919-0.0007045--52.366-2e-16-agesubjectyoung--0.2217215-0.0025915--85.556-2e-16"><i class="fa fa-check"></i><b>3.326</b> WrittenFrequency -0.0368919 0.0007045 -52.366 &lt;2e-16 <strong><em> ## AgeSubjectyoung -0.2217215 0.0025915 -85.556 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#lengthinletters-0.0038897-0.0015428-2.521-0.0117"><span class="toc-section-number">3.327</span> LengthInLetters 0.0038897 0.0015428 2.521 0.0117 *<br />
## â</a></li>
<li class="chapter" data-level="3.328" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-11"><i class="fa fa-check"></i><b>3.328</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="3.329" data-path="linear-regression.html"><a href="linear-regression.html#section-125"><i class="fa fa-check"></i><b>3.329</b> </a></li>
<li class="chapter" data-level="3.330" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.08758-on-4564-degrees-of-freedom"><i class="fa fa-check"></i><b>3.330</b> Residual standard error: 0.08758 on 4564 degrees of freedom</a></li>
<li class="chapter" data-level="3.331" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.6887-adjusted-r-squared-0.6885"><i class="fa fa-check"></i><b>3.331</b> Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885</a></li>
<li class="chapter" data-level="3.332" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.332</b> F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cda.html"><a href="cda.html"><i class="fa fa-check"></i><b>4</b> Categorical data analysis: Preliminaries</a><ul>
<li class="chapter" data-level="4.1" data-path="cda.html"><a href="cda.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016"><i class="fa fa-check"></i><b>4.1</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016)</a></li>
<li class="chapter" data-level="4.2" data-path="cda.html"><a href="cda.html#information-structure-and-production-planning"><i class="fa fa-check"></i><b>4.2</b> âInformation structure and production planningâ</a></li>
<li class="chapter" data-level="4.3" data-path="cda.html"><a href="cda.html#introduction"><i class="fa fa-check"></i><b>4.3</b> Introduction</a><ul>
<li class="chapter" data-level="4.3.1" data-path="cda.html"><a href="cda.html#x2-contingency-tables"><i class="fa fa-check"></i><b>4.3.1</b> 2x2 contingency tables</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="cda.html"><a href="cda.html#warning-package-bindrcpp-was-built-under-r-version-3.4.4"><i class="fa fa-check"></i><b>4.4</b> Warning: package âbindrcppâ was built under R version 3.4.4</a></li>
<li class="chapter" data-level="4.5" data-path="cda.html"><a href="cda.html#context"><i class="fa fa-check"></i><b>4.5</b> context</a></li>
<li class="chapter" data-level="4.6" data-path="cda.html"><a href="cda.html#prominence-alternative-noalternative"><i class="fa fa-check"></i><b>4.6</b> prominence Alternative NoAlternative</a></li>
<li class="chapter" data-level="4.7" data-path="cda.html"><a href="cda.html#adjective-120-55"><i class="fa fa-check"></i><b>4.7</b> Adjective 120 55</a></li>
<li class="chapter" data-level="4.8" data-path="cda.html"><a href="cda.html#noun-85-155"><i class="fa fa-check"></i><b>4.8</b> Noun 85 155</a></li>
<li class="chapter" data-level="4.9" data-path="cda.html"><a href="cda.html#total-number-of-observations"><i class="fa fa-check"></i><b>4.9</b> total number of observations</a></li>
<li class="chapter" data-level="4.10" data-path="cda.html"><a href="cda.html#pcontext-alternative"><i class="fa fa-check"></i><b>4.10</b> P(context = alternative)</a></li>
<li class="chapter" data-level="4.11" data-path="cda.html"><a href="cda.html#pprominence-adjective"><i class="fa fa-check"></i><b>4.11</b> p(prominence = adjective)</a></li>
<li class="chapter" data-level="4.12" data-path="cda.html"><a href="cda.html#print-these-probabilities"><i class="fa fa-check"></i><b>4.12</b> print these probabilities</a></li>
<li class="chapter" data-level="4.13" data-path="cda.html"><a href="cda.html#section-126"><i class="fa fa-check"></i><b>4.13</b> [1] 0.4939759</a></li>
<li class="chapter" data-level="4.14" data-path="cda.html"><a href="cda.html#section-127"><i class="fa fa-check"></i><b>4.14</b> [1] 0.4216867</a><ul>
<li class="chapter" data-level="4.14.1" data-path="cda.html"><a href="cda.html#the-chi-squared-test"><i class="fa fa-check"></i><b>4.14.1</b> The chi-squared test</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="cda.html"><a href="cda.html#section-128"><i class="fa fa-check"></i><b>4.15</b> </a></li>
<li class="chapter" data-level="4.16" data-path="cda.html"><a href="cda.html#pearsons-chi-squared-test-with-yates-continuity-correction"><i class="fa fa-check"></i><b>4.16</b> Pearsonâs Chi-squared test with Yatesâ continuity correction</a></li>
<li class="chapter" data-level="4.17" data-path="cda.html"><a href="cda.html#section-129"><i class="fa fa-check"></i><b>4.17</b> </a></li>
<li class="chapter" data-level="4.18" data-path="cda.html"><a href="cda.html#data-tab"><i class="fa fa-check"></i><b>4.18</b> data: tab</a></li>
<li class="chapter" data-level="4.19" data-path="cda.html"><a href="cda.html#x-squared-43.189-df-1-p-value-4.969e-11"><i class="fa fa-check"></i><b>4.19</b> X-squared = 43.189, df = 1, p-value = 4.969e-11</a></li>
<li class="chapter" data-level="4.20" data-path="cda.html"><a href="cda.html#regularity"><i class="fa fa-check"></i><b>4.20</b> Regularity</a></li>
<li class="chapter" data-level="4.21" data-path="cda.html"><a href="cda.html#auxiliary-irregular-regular"><i class="fa fa-check"></i><b>4.21</b> Auxiliary irregular regular</a></li>
<li class="chapter" data-level="4.22" data-path="cda.html"><a href="cda.html#hebben-108-469"><i class="fa fa-check"></i><b>4.22</b> hebben 108 469</a></li>
<li class="chapter" data-level="4.23" data-path="cda.html"><a href="cda.html#zijn-12-8"><i class="fa fa-check"></i><b>4.23</b> zijn 12 8</a></li>
<li class="chapter" data-level="4.24" data-path="cda.html"><a href="cda.html#zijnheb-39-64"><i class="fa fa-check"></i><b>4.24</b> zijnheb 39 64</a></li>
<li class="chapter" data-level="4.25" data-path="cda.html"><a href="cda.html#warning-in-chisq.testxtabsauxiliary-regularity-regularity-chi-"><i class="fa fa-check"></i><b>4.25</b> Warning in chisq.test(xtabs(~Auxiliary + Regularity, regularity)): Chi-</a></li>
<li class="chapter" data-level="4.26" data-path="cda.html"><a href="cda.html#squared-approximation-may-be-incorrect"><i class="fa fa-check"></i><b>4.26</b> squared approximation may be incorrect</a></li>
<li class="chapter" data-level="4.27" data-path="cda.html"><a href="cda.html#section-130"><i class="fa fa-check"></i><b>4.27</b> </a></li>
<li class="chapter" data-level="4.28" data-path="cda.html"><a href="cda.html#pearsons-chi-squared-test"><i class="fa fa-check"></i><b>4.28</b> Pearsonâs Chi-squared test</a></li>
<li class="chapter" data-level="4.29" data-path="cda.html"><a href="cda.html#section-131"><i class="fa fa-check"></i><b>4.29</b> </a></li>
<li class="chapter" data-level="4.30" data-path="cda.html"><a href="cda.html#data-xtabsauxiliary-regularity-regularity"><i class="fa fa-check"></i><b>4.30</b> data: xtabs(~Auxiliary + Regularity, regularity)</a></li>
<li class="chapter" data-level="4.31" data-path="cda.html"><a href="cda.html#x-squared-34.555-df-2-p-value-3.136e-08"><i class="fa fa-check"></i><b>4.31</b> X-squared = 34.555, df = 2, p-value = 3.136e-08</a></li>
<li class="chapter" data-level="4.32" data-path="cda.html"><a href="cda.html#section-132"><i class="fa fa-check"></i><b>4.32</b> </a></li>
<li class="chapter" data-level="4.33" data-path="cda.html"><a href="cda.html#pearsons-chi-squared-test-with-simulated-p-value-based-on-2000"><i class="fa fa-check"></i><b>4.33</b> Pearsonâs Chi-squared test with simulated p-value (based on 2000</a></li>
<li class="chapter" data-level="4.34" data-path="cda.html"><a href="cda.html#replicates"><i class="fa fa-check"></i><b>4.34</b> replicates)</a></li>
<li class="chapter" data-level="4.35" data-path="cda.html"><a href="cda.html#section-133"><i class="fa fa-check"></i><b>4.35</b> </a></li>
<li class="chapter" data-level="4.36" data-path="cda.html"><a href="cda.html#data-xtabsauxiliary-regularity-regularity-1"><i class="fa fa-check"></i><b>4.36</b> data: xtabs(~Auxiliary + Regularity, regularity)</a></li>
<li class="chapter" data-level="4.37" data-path="cda.html"><a href="cda.html#x-squared-34.555-df-na-p-value-0.0004998"><i class="fa fa-check"></i><b>4.37</b> X-squared = 34.555, df = NA, p-value = 0.0004998</a><ul>
<li class="chapter" data-level="4.37.1" data-path="cda.html"><a href="cda.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.37.1</b> Fisherâs exact test</a></li>
</ul></li>
<li class="chapter" data-level="4.38" data-path="cda.html"><a href="cda.html#regularity-1"><i class="fa fa-check"></i><b>4.38</b> Regularity</a></li>
<li class="chapter" data-level="4.39" data-path="cda.html"><a href="cda.html#auxiliary-irregular-regular-1"><i class="fa fa-check"></i><b>4.39</b> Auxiliary irregular regular</a></li>
<li class="chapter" data-level="4.40" data-path="cda.html"><a href="cda.html#hebben-108-469-1"><i class="fa fa-check"></i><b>4.40</b> hebben 108 469</a></li>
<li class="chapter" data-level="4.41" data-path="cda.html"><a href="cda.html#zijn-12-8-1"><i class="fa fa-check"></i><b>4.41</b> zijn 12 8</a></li>
<li class="chapter" data-level="4.42" data-path="cda.html"><a href="cda.html#zijnheb-39-64-1"><i class="fa fa-check"></i><b>4.42</b> zijnheb 39 64</a></li>
<li class="chapter" data-level="4.43" data-path="cda.html"><a href="cda.html#section-134"><i class="fa fa-check"></i><b>4.43</b> </a></li>
<li class="chapter" data-level="4.44" data-path="cda.html"><a href="cda.html#fishers-exact-test-for-count-data"><i class="fa fa-check"></i><b>4.44</b> Fisherâs Exact Test for Count Data</a></li>
<li class="chapter" data-level="4.45" data-path="cda.html"><a href="cda.html#section-135"><i class="fa fa-check"></i><b>4.45</b> </a></li>
<li class="chapter" data-level="4.46" data-path="cda.html"><a href="cda.html#data-xtabsauxiliary-regularity-regularity-2"><i class="fa fa-check"></i><b>4.46</b> data: xtabs(~Auxiliary + Regularity, regularity)</a></li>
<li class="chapter" data-level="4.47" data-path="cda.html"><a href="cda.html#p-value-1.52e-07"><i class="fa fa-check"></i><b>4.47</b> p-value = 1.52e-07</a></li>
<li class="chapter" data-level="4.48" data-path="cda.html"><a href="cda.html#alternative-hypothesis-two.sided"><i class="fa fa-check"></i><b>4.48</b> alternative hypothesis: two.sided</a></li>
<li class="chapter" data-level="4.49" data-path="cda.html"><a href="cda.html#towards-logistic-regression"><i class="fa fa-check"></i><b>4.49</b> Towards logistic regression</a><ul>
<li class="chapter" data-level="4.49.1" data-path="cda.html"><a href="cda.html#odds"><i class="fa fa-check"></i><b>4.49.1</b> Odds</a></li>
<li class="chapter" data-level="4.49.2" data-path="cda.html"><a href="cda.html#log-odds"><i class="fa fa-check"></i><b>4.49.2</b> Log-odds</a></li>
</ul></li>
<li class="chapter" data-level="4.50" data-path="cda.html"><a href="cda.html#section-136"><i class="fa fa-check"></i><b>4.50</b> [1] 0</a></li>
<li class="chapter" data-level="4.51" data-path="cda.html"><a href="cda.html#section-137"><i class="fa fa-check"></i><b>4.51</b> [1] 0.9946226</a></li>
<li class="chapter" data-level="4.52" data-path="cda.html"><a href="cda.html#section-138"><i class="fa fa-check"></i><b>4.52</b> [1] 1.99243</a></li>
<li class="chapter" data-level="4.53" data-path="cda.html"><a href="cda.html#section-139"><i class="fa fa-check"></i><b>4.53</b> [1] 3.009467</a></li>
<li class="chapter" data-level="4.54" data-path="cda.html"><a href="cda.html#section-140"><i class="fa fa-check"></i><b>4.54</b> [1] 0.01798621</a><ul>
<li class="chapter" data-level="4.54.1" data-path="cda.html"><a href="cda.html#odds-ratios"><i class="fa fa-check"></i><b>4.54.1</b> Odds ratios</a></li>
<li class="chapter" data-level="4.54.2" data-path="cda.html"><a href="cda.html#log-odds-sample-and-population"><i class="fa fa-check"></i><b>4.54.2</b> Log odds: sample and population</a></li>
</ul></li>
<li class="chapter" data-level="4.55" data-path="cda.html"><a href="cda.html#section-141"><i class="fa fa-check"></i><b>4.55</b> [1] 9</a></li>
<li class="chapter" data-level="4.56" data-path="cda.html"><a href="cda.html#section-142"><i class="fa fa-check"></i><b>4.56</b> [1] 2.333333</a></li>
<li class="chapter" data-level="4.57" data-path="cda.html"><a href="cda.html#section-143"><i class="fa fa-check"></i><b>4.57</b> [1] 3.857143</a></li>
<li class="chapter" data-level="4.58" data-path="cda.html"><a href="cda.html#section-144"><i class="fa fa-check"></i><b>4.58</b> [1] 1.349927</a></li>
<li class="chapter" data-level="4.59" data-path="cda.html"><a href="cda.html#cda-other-readings"><i class="fa fa-check"></i><b>4.59</b> Other readings</a></li>
<li class="chapter" data-level="4.60" data-path="cda.html"><a href="cda.html#c3solns"><i class="fa fa-check"></i><b>4.60</b> Solutions</a><ul>
<li class="chapter" data-level="4.60.1" data-path="cda.html"><a href="cda.html#solutions-to-exercise-1"><i class="fa fa-check"></i><b>4.60.1</b> Solutions to Exercise 1:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data"><i class="fa fa-check"></i><b>5.1</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#make-standardized-numericcenteredscaled-versions-of-givenness-dataset-predictors"><i class="fa fa-check"></i><b>5.2</b> make standardized (numeric/centered/scaled) versions of âgivennessâ dataset predictors:</a></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>5.3</b> Simple logistic regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-hyp-test"><i class="fa fa-check"></i><b>5.3.1</b> Hypothesis testing</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-the-coefficients-logit-odds-and-probability"><i class="fa fa-check"></i><b>5.3.2</b> Interpreting the coefficients: Logit, odds, and probability</a></li>
<li class="chapter" data-level="5.3.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-as-a-glm"><i class="fa fa-check"></i><b>5.3.3</b> Logistic regression as a GLM</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#section-145"><i class="fa fa-check"></i><b>5.4</b> </a></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#call-13"><i class="fa fa-check"></i><b>5.5</b> Call:</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#glmformula-stressshift-acoustics.std-family-binomial"><i class="fa fa-check"></i><b>5.6</b> glm(formula = stressshift ~ acoustics.std, family = âbinomialâ,</a></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#data-givenness"><i class="fa fa-check"></i><b>5.7</b> data = givenness)</a></li>
<li class="chapter" data-level="5.8" data-path="logistic-regression.html"><a href="logistic-regression.html#section-146"><i class="fa fa-check"></i><b>5.8</b> </a></li>
<li class="chapter" data-level="5.9" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residuals"><i class="fa fa-check"></i><b>5.9</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="5.10" data-path="logistic-regression.html"><a href="logistic-regression.html#min-1q-median-3q-max-12"><i class="fa fa-check"></i><b>5.10</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="5.11" data-path="logistic-regression.html"><a href="logistic-regression.html#section-147"><i class="fa fa-check"></i><b>5.11</b> -1.6271 -0.8924 -0.6532 1.1213 2.2418</a></li>
<li class="chapter" data-level="5.12" data-path="logistic-regression.html"><a href="logistic-regression.html#section-148"><i class="fa fa-check"></i><b>5.12</b> </a></li>
<li class="chapter" data-level="5.13" data-path="logistic-regression.html"><a href="logistic-regression.html#coefficients-10"><i class="fa fa-check"></i><b>5.13</b> Coefficients:</a></li>
<li class="chapter" data-level="5.14" data-path="logistic-regression.html"><a href="logistic-regression.html#estimate-std.-error-z-value-prz"><i class="fa fa-check"></i><b>5.14</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="5.15" data-path="logistic-regression.html"><a href="logistic-regression.html#intercept--0.6897-0.1167--5.908-3.47e-09-acoustics.std-1.6371-0.2588-6.325-2.54e-10"><i class="fa fa-check"></i><b>5.15</b> (Intercept) -0.6897 0.1167 -5.908 3.47e-09 <strong><em> ## acoustics.std 1.6371 0.2588 6.325 2.54e-10 </em></strong></a></li>
<li class="chapter" data-level="5.16" data-path="logistic-regression.html"><a href="logistic-regression.html#section-149"><i class="fa fa-check"></i><b>5.16</b> â</a></li>
<li class="chapter" data-level="5.17" data-path="logistic-regression.html"><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-12"><i class="fa fa-check"></i><b>5.17</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="5.18" data-path="logistic-regression.html"><a href="logistic-regression.html#section-150"><i class="fa fa-check"></i><b>5.18</b> </a></li>
<li class="chapter" data-level="5.19" data-path="logistic-regression.html"><a href="logistic-regression.html#dispersion-parameter-for-binomial-family-taken-to-be-1"><i class="fa fa-check"></i><b>5.19</b> (Dispersion parameter for binomial family taken to be 1)</a></li>
<li class="chapter" data-level="5.20" data-path="logistic-regression.html"><a href="logistic-regression.html#section-151"><i class="fa fa-check"></i><b>5.20</b> </a></li>
<li class="chapter" data-level="5.21" data-path="logistic-regression.html"><a href="logistic-regression.html#null-deviance-496.24-on-381-degrees-of-freedom"><i class="fa fa-check"></i><b>5.21</b> Null deviance: 496.24 on 381 degrees of freedom</a></li>
<li class="chapter" data-level="5.22" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-deviance-448.07-on-380-degrees-of-freedom"><i class="fa fa-check"></i><b>5.22</b> Residual deviance: 448.07 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="5.23" data-path="logistic-regression.html"><a href="logistic-regression.html#aic-452.07"><i class="fa fa-check"></i><b>5.23</b> AIC: 452.07</a></li>
<li class="chapter" data-level="5.24" data-path="logistic-regression.html"><a href="logistic-regression.html#section-152"><i class="fa fa-check"></i><b>5.24</b> </a></li>
<li class="chapter" data-level="5.25" data-path="logistic-regression.html"><a href="logistic-regression.html#number-of-fisher-scoring-iterations-3"><i class="fa fa-check"></i><b>5.25</b> Number of Fisher Scoring iterations: 3</a></li>
<li class="chapter" data-level="5.26" data-path="logistic-regression.html"><a href="logistic-regression.html#section-153"><i class="fa fa-check"></i><b>5.26</b> [1] -0.6896608</a></li>
<li class="chapter" data-level="5.27" data-path="logistic-regression.html"><a href="logistic-regression.html#section-154"><i class="fa fa-check"></i><b>5.27</b> [1] 0.3341085</a></li>
<li class="chapter" data-level="5.28" data-path="logistic-regression.html"><a href="logistic-regression.html#section-155"><i class="fa fa-check"></i><b>5.28</b> [1] 1.637052</a></li>
<li class="chapter" data-level="5.29" data-path="logistic-regression.html"><a href="logistic-regression.html#section-156"><i class="fa fa-check"></i><b>5.29</b> [1] 5.139996</a></li>
<li class="chapter" data-level="5.30" data-path="logistic-regression.html"><a href="logistic-regression.html#set-up-dataframe-with-range-of-acoustics.std-we-want-to-predict-over"><i class="fa fa-check"></i><b>5.30</b> set up dataframe with range of acoustics.std we want to predict over</a></li>
<li class="chapter" data-level="5.31" data-path="logistic-regression.html"><a href="logistic-regression.html#get-the-models-predictions-in-log-odds-space"><i class="fa fa-check"></i><b>5.31</b> get the modelâs predictions in log-odds space</a></li>
<li class="chapter" data-level="5.32" data-path="logistic-regression.html"><a href="logistic-regression.html#transform-those-preditions-to-probability-space"><i class="fa fa-check"></i><b>5.32</b> transform those preditions to probability space</a></li>
<li class="chapter" data-level="5.33" data-path="logistic-regression.html"><a href="logistic-regression.html#section-157"><i class="fa fa-check"></i><b>5.33</b> </a></li>
<li class="chapter" data-level="5.34" data-path="logistic-regression.html"><a href="logistic-regression.html#call-14"><i class="fa fa-check"></i><b>5.34</b> Call:</a></li>
<li class="chapter" data-level="5.35" data-path="logistic-regression.html"><a href="logistic-regression.html#glmformula-stressshift-nptype-family-binomial-data-givenness"><i class="fa fa-check"></i><b>5.35</b> glm(formula = stressshift ~ npType, family = âbinomialâ, data = givenness)</a></li>
<li class="chapter" data-level="5.36" data-path="logistic-regression.html"><a href="logistic-regression.html#section-158"><i class="fa fa-check"></i><b>5.36</b> </a></li>
<li class="chapter" data-level="5.37" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residuals-1"><i class="fa fa-check"></i><b>5.37</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="5.38" data-path="logistic-regression.html"><a href="logistic-regression.html#min-1q-median-3q-max-13"><i class="fa fa-check"></i><b>5.38</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="5.39" data-path="logistic-regression.html"><a href="logistic-regression.html#section-159"><i class="fa fa-check"></i><b>5.39</b> -1.014 -1.014 -0.850 1.350 1.545</a></li>
<li class="chapter" data-level="5.40" data-path="logistic-regression.html"><a href="logistic-regression.html#section-160"><i class="fa fa-check"></i><b>5.40</b> </a></li>
<li class="chapter" data-level="5.41" data-path="logistic-regression.html"><a href="logistic-regression.html#coefficients-11"><i class="fa fa-check"></i><b>5.41</b> Coefficients:</a></li>
<li class="chapter" data-level="5.42" data-path="logistic-regression.html"><a href="logistic-regression.html#estimate-std.-error-z-value-prz-1"><i class="fa fa-check"></i><b>5.42</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li><a href="logistic-regression.html#intercept--0.8321-0.1587--5.244-1.57e-07-nptypepronoun-0.4353-0.2159-2.016-0.0438-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-492.14-on-380-degrees-of-freedom-aic-496.14-number-of-fisher-scoring-iterations-4-observed-condtion-means-stressshift-nptype-noshift-shift-full-0.6968085-0.3031915-pronoun-0.5979381-0.4020619-differences-from-linear-regression-fitting-and-interpretation-c4differences-fitting-a-logistic-regression-model-interpretation-warning-glm.fit-algorithm-did-not-converge-evaluating-logistic-regression-models-evaluating-logistic-regression-models-likelihood-ratio-test-c4lrt-lr-test-of-the-effect-of-acoustics.std-in-mod1-analysis-of-deviance-table-model-1-stressshift-1-model-2-stressshift-acoustics.std-resid.-df-resid.-dev-df-deviance-prchi-1-381-496.24-2-380-448.07-1-48.17-3.909e-12-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-call-glmformula-stressshift-acoustics.std-family-binomial-data-givenness-deviance-residuals-min-1q-median-3q-max--1.6271--0.8924--0.6532-1.1213-2.2418-coefficients-estimate-std.-error-z-value-prz-intercept--0.6897-0.1167--5.908-3.47e-09-acoustics.std-1.6371-0.2588-6.325-2.54e-10-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-448.07-on-380-degrees-of-freedom-aic-452.07-number-of-fisher-scoring-iterations-3-classification-accuracy-function-for-computing-accuracy-of-a-logistic-regression-model-on-the-dataset-used-to-fit-the-model-lrmod-fitted-model-responsevar-name-of-response-variable-for-lrmod-adapted-from-httpswww.r-bloggers.comevaluating-logistic-regression-models-baseline-accuracy-for-a-logisitic-regression-model-lrmod-with-a-given-response-variable-baseline-accuracy-1-0.7015707-pseudo-r2-logistic-regression-pseudo-r2-example---lr-test-of-the-effect-of-nptype-in-mod2-analysis-of-deviance-table-model-1-stressshift-nptype-model-2-stressshift-1-resid.-df-resid.-dev-df-deviance-prchi-1-380-492.14-2-381-496.24--1--4.0972-0.04295"><span class="toc-section-number">5.43</span> (Intercept) -0.8321 0.1587 -5.244 1.57e-07 <strong><em> ## npTypepronoun 0.4353 0.2159 2.016 0.0438 </em><br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 492.14 on 380 degrees of freedom ## AIC: 496.14 ## ## Number of Fisher Scoring iterations: 4 ## Observed condtion means: ## stressshift ## npType noshift shift ## full 0.6968085 0.3031915 ## pronoun 0.5979381 0.4020619 ### Differences from linear regression: Fitting and interpretation {#c4differences} ### Fitting a logistic regression model ### Interpretation ## Warning: glm.fit: algorithm did not converge ## Evaluating logistic regression models {#evaluating-logistic-regression-models} ### Likelihood ratio test {#c4lrt} ## LR test of the effect of acoustics.std in mod1 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ 1 ## Model 2: stressshift ~ acoustics.std ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 381 496.24<br />
## 2 380 448.07 1 48.17 3.909e-12 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Call: ## glm(formula = stressshift ~ acoustics.std, family = âbinomialâ, ## data = givenness) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.6271 -0.8924 -0.6532 1.1213 2.2418<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.6897 0.1167 -5.908 3.47e-09 </em><strong> ## acoustics.std 1.6371 0.2588 6.325 2.54e-10 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 448.07 on 380 degrees of freedom ## AIC: 452.07 ## ## Number of Fisher Scoring iterations: 3 ### Classification accuracy ## function for computing accuracy of a logistic regression model ## (on the dataset used to fit the model) ## lrMod = fitted model ## responseVar = name of response variable for lrMod ## adapted from: <a href="https://www.r-bloggers.com/evaluating-logistic-regression-models/" class="uri">https://www.r-bloggers.com/evaluating-logistic-regression-models/</a> ## baseline accuracy for a logisitic regression model lrMod ## with a given response variable ## baseline accuracy ## [1] 0.7015707 ### Pseudo-<span class="math inline">\(R^2\)</span> {#logistic-regression-pseudo-r2} #### Example {-} ## LR test of the effect of npType in mod2 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType ## Model 2: stressshift ~ 1 ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 380 492.14<br />
## 2 381 496.24 -1 -4.0972 0.04295 </em></a></li>
<li class="chapter" data-level="5.44" data-path="logistic-regression.html"><a href="logistic-regression.html#section-161"><i class="fa fa-check"></i><b>5.44</b> â</a></li>
<li class="chapter" data-level="5.45" data-path="logistic-regression.html"><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-13"><i class="fa fa-check"></i><b>5.45</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="5.46" data-path="logistic-regression.html"><a href="logistic-regression.html#accuracy-of-mod2"><i class="fa fa-check"></i><b>5.46</b> accuracy of mod2</a></li>
<li class="chapter" data-level="5.47" data-path="logistic-regression.html"><a href="logistic-regression.html#section-162"><i class="fa fa-check"></i><b>5.47</b> [1] 0.6465969</a></li>
<li class="chapter" data-level="5.48" data-path="logistic-regression.html"><a href="logistic-regression.html#its-the-same-as-the-baselines-accuracy"><i class="fa fa-check"></i><b>5.48</b> itâs the same as the baselineâs accuracy</a></li>
<li class="chapter" data-level="5.49" data-path="logistic-regression.html"><a href="logistic-regression.html#section-163"><i class="fa fa-check"></i><b>5.49</b> [1] 0.6465969</a></li>
<li class="chapter" data-level="5.50" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>5.50</b> Multiple logistic regression</a><ul>
<li class="chapter" data-level="5.50.1" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-test-general-case"><i class="fa fa-check"></i><b>5.50.1</b> Likelihood ratio test: General case</a></li>
<li class="chapter" data-level="5.50.2" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-worked-example"><i class="fa fa-check"></i><b>5.50.2</b> Worked example</a></li>
</ul></li>
<li class="chapter" data-level="5.51" data-path="logistic-regression.html"><a href="logistic-regression.html#stressshift"><i class="fa fa-check"></i><b>5.51</b> stressshift</a></li>
<li class="chapter" data-level="5.52" data-path="logistic-regression.html"><a href="logistic-regression.html#conditionlabel-noshift-shift"><i class="fa fa-check"></i><b>5.52</b> conditionLabel noshift shift</a></li>
<li class="chapter" data-level="5.53" data-path="logistic-regression.html"><a href="logistic-regression.html#contrast-0.91919192-0.08080808"><i class="fa fa-check"></i><b>5.53</b> Contrast 0.91919192 0.08080808</a></li>
<li class="chapter" data-level="5.54" data-path="logistic-regression.html"><a href="logistic-regression.html#williams-0.35326087-0.64673913"><i class="fa fa-check"></i><b>5.54</b> Williams 0.35326087 0.64673913</a></li>
<li class="chapter" data-level="5.55" data-path="logistic-regression.html"><a href="logistic-regression.html#stressshift-1"><i class="fa fa-check"></i><b>5.55</b> stressshift</a></li>
<li class="chapter" data-level="5.56" data-path="logistic-regression.html"><a href="logistic-regression.html#nptype-noshift-shift"><i class="fa fa-check"></i><b>5.56</b> npType noshift shift</a></li>
<li class="chapter" data-level="5.57" data-path="logistic-regression.html"><a href="logistic-regression.html#full-0.6968085-0.3031915"><i class="fa fa-check"></i><b>5.57</b> full 0.6968085 0.3031915</a></li>
<li class="chapter" data-level="5.58" data-path="logistic-regression.html"><a href="logistic-regression.html#pronoun-0.5979381-0.4020619"><i class="fa fa-check"></i><b>5.58</b> pronoun 0.5979381 0.4020619</a></li>
<li class="chapter" data-level="5.59" data-path="logistic-regression.html"><a href="logistic-regression.html#stressshift-2"><i class="fa fa-check"></i><b>5.59</b> stressshift</a></li>
<li class="chapter" data-level="5.60" data-path="logistic-regression.html"><a href="logistic-regression.html#voice-noshift-shift"><i class="fa fa-check"></i><b>5.60</b> voice noshift shift</a></li>
<li class="chapter" data-level="5.61" data-path="logistic-regression.html"><a href="logistic-regression.html#active-0.7005348-0.2994652"><i class="fa fa-check"></i><b>5.61</b> active 0.7005348 0.2994652</a></li>
<li class="chapter" data-level="5.62" data-path="logistic-regression.html"><a href="logistic-regression.html#passive-0.5948718-0.4051282"><i class="fa fa-check"></i><b>5.62</b> passive 0.5948718 0.4051282</a></li>
<li class="chapter" data-level="5.63" data-path="logistic-regression.html"><a href="logistic-regression.html#section-164"><i class="fa fa-check"></i><b>5.63</b> </a></li>
<li class="chapter" data-level="5.64" data-path="logistic-regression.html"><a href="logistic-regression.html#call-15"><i class="fa fa-check"></i><b>5.64</b> Call:</a></li>
<li class="chapter" data-level="5.65" data-path="logistic-regression.html"><a href="logistic-regression.html#glmformula-stressshift-nptype.pron-clabel.williams-voice.passive"><i class="fa fa-check"></i><b>5.65</b> glm(formula = stressshift ~ npType.pron + clabel.williams + voice.passive +</a></li>
<li class="chapter" data-level="5.66" data-path="logistic-regression.html"><a href="logistic-regression.html#order.std-family-binomial-data-givenness"><i class="fa fa-check"></i><b>5.66</b> order.std, family = âbinomialâ, data = givenness)</a></li>
<li class="chapter" data-level="5.67" data-path="logistic-regression.html"><a href="logistic-regression.html#section-165"><i class="fa fa-check"></i><b>5.67</b> </a></li>
<li class="chapter" data-level="5.68" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residuals-2"><i class="fa fa-check"></i><b>5.68</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="5.69" data-path="logistic-regression.html"><a href="logistic-regression.html#min-1q-median-3q-max-14"><i class="fa fa-check"></i><b>5.69</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="5.70" data-path="logistic-regression.html"><a href="logistic-regression.html#section-166"><i class="fa fa-check"></i><b>5.70</b> -1.8358 -0.5249 -0.3509 0.7644 2.6344</a></li>
<li class="chapter" data-level="5.71" data-path="logistic-regression.html"><a href="logistic-regression.html#section-167"><i class="fa fa-check"></i><b>5.71</b> </a></li>
<li class="chapter" data-level="5.72" data-path="logistic-regression.html"><a href="logistic-regression.html#coefficients-12"><i class="fa fa-check"></i><b>5.72</b> Coefficients:</a></li>
<li class="chapter" data-level="5.73" data-path="logistic-regression.html"><a href="logistic-regression.html#estimate-std.-error-z-value-prz-2"><i class="fa fa-check"></i><b>5.73</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li><a href="logistic-regression.html#intercept--1.0092-0.1580--6.389-1.67e-10-nptype.pron-0.5985-0.2746-2.179-0.0293-clabel.williams-3.1848-0.3179-10.018-2e-16-voice.passive-0.8026-0.2803-2.863-0.0042-order.std-0.3044-0.2742-1.110-0.2669-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-335.90-on-377-degrees-of-freedom-aic-345.9-number-of-fisher-scoring-iterations-5-1-0.6818186-model-evaluation---analysis-of-deviance-table-model-1-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-model-2-stressshift-1-resid.-df-resid.-dev-df-deviance-prchi-1-377-335.90-2-381-496.24--4--160.34-2.2e-16"><span class="toc-section-number">5.74</span> (Intercept) -1.0092 0.1580 -6.389 1.67e-10 <strong><em> ## npType.pron 0.5985 0.2746 2.179 0.0293 </em><br />
## clabel.williams 3.1848 0.3179 10.018 &lt; 2e-16 </strong><em> ## voice.passive 0.8026 0.2803 2.863 0.0042 <strong> ## order.std 0.3044 0.2742 1.110 0.2669<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 335.90 on 377 degrees of freedom ## AIC: 345.9 ## ## Number of Fisher Scoring iterations: 5 ## [1] 0.6818186 #### Model evaluation {-} ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std ## Model 2: stressshift ~ 1 ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 377 335.90<br />
## 2 381 496.24 -4 -160.34 &lt; 2.2e-16 </strong></em></a></li>
<li class="chapter" data-level="5.75" data-path="logistic-regression.html"><a href="logistic-regression.html#section-168"><i class="fa fa-check"></i><b>5.75</b> â</a></li>
<li class="chapter" data-level="5.76" data-path="logistic-regression.html"><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-14"><i class="fa fa-check"></i><b>5.76</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="5.77" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-accuracy"><i class="fa fa-check"></i><b>5.77</b> classification accuracy</a></li>
<li class="chapter" data-level="5.78" data-path="logistic-regression.html"><a href="logistic-regression.html#section-169"><i class="fa fa-check"></i><b>5.78</b> [1] 0.8089005</a></li>
<li class="chapter" data-level="5.79" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-accuracy"><i class="fa fa-check"></i><b>5.79</b> baseline accuracy</a></li>
<li class="chapter" data-level="5.80" data-path="logistic-regression.html"><a href="logistic-regression.html#section-170"><i class="fa fa-check"></i><b>5.80</b> [1] 0.6465969</a></li>
<li class="chapter" data-level="5.81" data-path="logistic-regression.html"><a href="logistic-regression.html#analysis-of-deviance-table"><i class="fa fa-check"></i><b>5.81</b> Analysis of Deviance Table</a></li>
<li class="chapter" data-level="5.82" data-path="logistic-regression.html"><a href="logistic-regression.html#section-171"><i class="fa fa-check"></i><b>5.82</b> </a></li>
<li class="chapter" data-level="5.83" data-path="logistic-regression.html"><a href="logistic-regression.html#model-1-stressshift-nptype.pron-clabel.williams-voice.passive"><i class="fa fa-check"></i><b>5.83</b> Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive +</a></li>
<li class="chapter" data-level="5.84" data-path="logistic-regression.html"><a href="logistic-regression.html#order.std"><i class="fa fa-check"></i><b>5.84</b> order.std</a></li>
<li class="chapter" data-level="5.85" data-path="logistic-regression.html"><a href="logistic-regression.html#model-2-stressshift-nptype.pron-clabel.williams-voice.passive"><i class="fa fa-check"></i><b>5.85</b> Model 2: stressshift ~ npType.pron + clabel.williams * voice.passive +</a></li>
<li class="chapter" data-level="5.86" data-path="logistic-regression.html"><a href="logistic-regression.html#order.std-1"><i class="fa fa-check"></i><b>5.86</b> order.std</a></li>
<li class="chapter" data-level="5.87" data-path="logistic-regression.html"><a href="logistic-regression.html#resid.-df-resid.-dev-df-deviance-prchi"><i class="fa fa-check"></i><b>5.87</b> Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)</a></li>
<li class="chapter" data-level="5.88" data-path="logistic-regression.html"><a href="logistic-regression.html#section-172"><i class="fa fa-check"></i><b>5.88</b> 1 377 335.90</a></li>
<li><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-analysis-of-deviance-table-model-1-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-model-2-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-nptype.pron-clabel.williams-resid.-df-resid.-dev-df-deviance-prchi-1-377-335.90-2-376-335.31-1-0.5867-0.4437-analysis-of-deviance-table-model-1-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-model-2-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-voice.passive-nptype.pron-resid.-df-resid.-dev-df-deviance-prchi-1-377-335.90-2-376-334.99-1-0.9108-0.3399-call-glmformula-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-family-binomial-data-givenness-deviance-residuals-min-1q-median-3q-max--1.9933--0.4987--0.3543-0.6757-2.6080-coefficients-estimate-std.-error-z-value-prz-intercept--0.9742-0.1625--5.993-2.06e-09-nptype.pron-0.6302-0.2810-2.242-0.02493"><span class="toc-section-number">5.89</span> 2 376 325.81 1 10.085 0.001495 <strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std ## Model 2: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std + npType.pron * clabel.williams ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 377 335.90<br />
## 2 376 335.31 1 0.5867 0.4437 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std ## Model 2: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std + voice.passive * npType.pron ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 377 335.90<br />
## 2 376 334.99 1 0.9108 0.3399 ## ## Call: ## glm(formula = stressshift ~ npType.pron + clabel.williams * voice.passive + ## order.std, family = âbinomialâ, data = givenness) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.9933 -0.4987 -0.3543 0.6757 2.6080<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.9742 0.1625 -5.993 2.06e-09 </strong><em> ## npType.pron 0.6302 0.2810 2.242 0.02493 </em></a></li>
<li><a href="logistic-regression.html#clabel.williams-3.2054-0.3230-9.923-2e-16-voice.passive-0.3209-0.3239-0.991-0.32172-order.std-0.3650-0.2876-1.269-0.20437-clabel.williamsvoice.passive-1.9850-0.6370-3.116-0.00183-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-325.81-on-376-degrees-of-freedom-aic-337.81-number-of-fisher-scoring-iterations-5-1-0.8062827-1-0.8089005-model-criticism-for-logistic-regression-model-criticism-logistic-regression-residual-plots-residual-plots-example-binned-residuals-versus-expected-values---binned-residual-plot-cooks-distance-logistic-regression-cooks-distance-add-a-column-showing-cooks-distance-values-to-dataframe-other-readings-solutions-c4solns-appendix-other-generalized-linear-models-c4appendix2"><span class="toc-section-number">5.90</span> clabel.williams 3.2054 0.3230 9.923 &lt; 2e-16 *<strong> ## voice.passive 0.3209 0.3239 0.991 0.32172<br />
## order.std 0.3650 0.2876 1.269 0.20437<br />
## clabel.williams:voice.passive 1.9850 0.6370 3.116 0.00183 </strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 325.81 on 376 degrees of freedom ## AIC: 337.81 ## ## Number of Fisher Scoring iterations: 5 ## [1] 0.8062827 ## [1] 0.8089005 ## Model criticism for logistic regression {#model-criticism-logistic-regression} ### Residual plots {#residual-plots} #### Example: Binned residuals versus expected values {-} ## binned residual plot ### Cookâs distance {#logistic-regression-cooks-distance} ## add a column showing Cookâs distance values to dataframe ## Other readings ## Solutions {#c4solns} ## Appendix: Other Generalized Linear Models {#c4appendix2}</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><i class="fa fa-check"></i><b>6</b> Practical Regression Topics 1: Multi-level factors, contrast coding, interactions</a><ul>
<li class="chapter" data-level="6.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data-1"><i class="fa fa-check"></i><b>6.1</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="6.2" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#note-stress-shift-generally-called-prominence-shift-etc.-in-the-text"><i class="fa fa-check"></i><b>6.2</b> note: âstress shiftâ generally called âprominence shiftâ etc. in the text</a></li>
<li class="chapter" data-level="6.3" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016-data-1"><i class="fa fa-check"></i><b>6.3</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data</a></li>
<li class="chapter" data-level="6.4" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#loads-french_medial_vowel_devoicing.txt-from-osf-project-for-torreira-ernestus-2010-data-1"><i class="fa fa-check"></i><b>6.4</b> loads french_medial_vowel_devoicing.txt from OSF project for Torreira &amp; Ernestus (2010) data</a></li>
<li class="chapter" data-level="6.5" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multi-level-factors-introduction"><i class="fa fa-check"></i><b>6.5</b> Multi-level factors: Introduction</a></li>
<li class="chapter" data-level="6.6" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding"><i class="fa fa-check"></i><b>6.6</b> Contrast coding</a><ul>
<li class="chapter" data-level="6.6.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#first-examples"><i class="fa fa-check"></i><b>6.6.1</b> First examples</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-173"><i class="fa fa-check"></i><b>6.7</b> </a></li>
<li class="chapter" data-level="6.8" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-16"><i class="fa fa-check"></i><b>6.8</b> Call:</a></li>
<li class="chapter" data-level="6.9" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-acoustics-conditionlabel-data-givenness"><i class="fa fa-check"></i><b>6.9</b> lm(formula = acoustics ~ conditionLabel, data = givenness)</a></li>
<li class="chapter" data-level="6.10" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-174"><i class="fa fa-check"></i><b>6.10</b> </a></li>
<li class="chapter" data-level="6.11" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-12"><i class="fa fa-check"></i><b>6.11</b> Residuals:</a></li>
<li class="chapter" data-level="6.12" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-15"><i class="fa fa-check"></i><b>6.12</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.13" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-175"><i class="fa fa-check"></i><b>6.13</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="6.14" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-176"><i class="fa fa-check"></i><b>6.14</b> </a></li>
<li class="chapter" data-level="6.15" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-13"><i class="fa fa-check"></i><b>6.15</b> Coefficients:</a></li>
<li class="chapter" data-level="6.16" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-11"><i class="fa fa-check"></i><b>6.16</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.17" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.87510-0.05708--15.331-2e-16-conditionlabelwilliams-0.31774-0.08224-3.863-0.000131"><i class="fa fa-check"></i><b>6.17</b> (Intercept) -0.87510 0.05708 -15.331 &lt; 2e-16 <strong><em> ## conditionLabelWilliams 0.31774 0.08224 3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="6.18" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-177"><i class="fa fa-check"></i><b>6.18</b> â</a></li>
<li class="chapter" data-level="6.19" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-15"><i class="fa fa-check"></i><b>6.19</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="6.20" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-178"><i class="fa fa-check"></i><b>6.20</b> </a></li>
<li class="chapter" data-level="6.21" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-standard-error-0.8032-on-380-degrees-of-freedom"><i class="fa fa-check"></i><b>6.21</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="6.22" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526"><i class="fa fa-check"></i><b>6.22</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="6.23" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315"><i class="fa fa-check"></i><b>6.23</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a></li>
<li class="chapter" data-level="6.24" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#williams"><i class="fa fa-check"></i><b>6.24</b> Williams</a></li>
<li class="chapter" data-level="6.25" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-0"><i class="fa fa-check"></i><b>6.25</b> Contrast 0</a></li>
<li class="chapter" data-level="6.26" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#williams-1"><i class="fa fa-check"></i><b>6.26</b> Williams 1</a></li>
<li class="chapter" data-level="6.27" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-179"><i class="fa fa-check"></i><b>6.27</b> </a></li>
<li class="chapter" data-level="6.28" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-17"><i class="fa fa-check"></i><b>6.28</b> Call:</a></li>
<li class="chapter" data-level="6.29" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-acoustics-clabel.williams-data-givenness"><i class="fa fa-check"></i><b>6.29</b> lm(formula = acoustics ~ clabel.williams, data = givenness)</a></li>
<li class="chapter" data-level="6.30" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-180"><i class="fa fa-check"></i><b>6.30</b> </a></li>
<li class="chapter" data-level="6.31" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-13"><i class="fa fa-check"></i><b>6.31</b> Residuals:</a></li>
<li class="chapter" data-level="6.32" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-16"><i class="fa fa-check"></i><b>6.32</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.33" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-181"><i class="fa fa-check"></i><b>6.33</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="6.34" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-182"><i class="fa fa-check"></i><b>6.34</b> </a></li>
<li class="chapter" data-level="6.35" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-14"><i class="fa fa-check"></i><b>6.35</b> Coefficients:</a></li>
<li class="chapter" data-level="6.36" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-12"><i class="fa fa-check"></i><b>6.36</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.37" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.72205-0.04109--17.570-2e-16-clabel.williams-0.31774-0.08224-3.863-0.000131"><i class="fa fa-check"></i><b>6.37</b> (Intercept) -0.72205 0.04109 -17.570 &lt; 2e-16 <strong><em> ## clabel.williams 0.31774 0.08224 3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="6.38" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-183"><i class="fa fa-check"></i><b>6.38</b> â</a></li>
<li class="chapter" data-level="6.39" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-16"><i class="fa fa-check"></i><b>6.39</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="6.40" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-184"><i class="fa fa-check"></i><b>6.40</b> </a></li>
<li class="chapter" data-level="6.41" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-standard-error-0.8032-on-380-degrees-of-freedom-1"><i class="fa fa-check"></i><b>6.41</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="6.42" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526-1"><i class="fa fa-check"></i><b>6.42</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="6.43" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315-1"><i class="fa fa-check"></i><b>6.43</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a></li>
<li class="chapter" data-level="6.44" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#sets-contrast-levels-to--0.5-and-0.5"><i class="fa fa-check"></i><b>6.44</b> sets contrast levels to -0.5 and 0.5</a></li>
<li class="chapter" data-level="6.45" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#carry-out-the-regression-and-see-results"><i class="fa fa-check"></i><b>6.45</b> carry out the regression and see results</a></li>
<li class="chapter" data-level="6.46" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-185"><i class="fa fa-check"></i><b>6.46</b> </a></li>
<li class="chapter" data-level="6.47" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-18"><i class="fa fa-check"></i><b>6.47</b> Call:</a></li>
<li class="chapter" data-level="6.48" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-acoustics-conditionlabel-data-givenness-1"><i class="fa fa-check"></i><b>6.48</b> lm(formula = acoustics ~ conditionLabel, data = givenness)</a></li>
<li class="chapter" data-level="6.49" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-186"><i class="fa fa-check"></i><b>6.49</b> </a></li>
<li class="chapter" data-level="6.50" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-14"><i class="fa fa-check"></i><b>6.50</b> Residuals:</a></li>
<li class="chapter" data-level="6.51" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-17"><i class="fa fa-check"></i><b>6.51</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.52" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-187"><i class="fa fa-check"></i><b>6.52</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="6.53" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-188"><i class="fa fa-check"></i><b>6.53</b> </a></li>
<li class="chapter" data-level="6.54" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-15"><i class="fa fa-check"></i><b>6.54</b> Coefficients:</a></li>
<li class="chapter" data-level="6.55" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-13"><i class="fa fa-check"></i><b>6.55</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.56" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.71623-0.04112--17.417-2e-16-conditionlabel1--0.31774-0.08224--3.863-0.000131"><i class="fa fa-check"></i><b>6.56</b> (Intercept) -0.71623 0.04112 -17.417 &lt; 2e-16 <strong><em> ## conditionLabel1 -0.31774 0.08224 -3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="6.57" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-189"><i class="fa fa-check"></i><b>6.57</b> â</a></li>
<li class="chapter" data-level="6.58" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-17"><i class="fa fa-check"></i><b>6.58</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="6.59" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-190"><i class="fa fa-check"></i><b>6.59</b> </a></li>
<li class="chapter" data-level="6.60" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-standard-error-0.8032-on-380-degrees-of-freedom-2"><i class="fa fa-check"></i><b>6.60</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="6.61" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526-2"><i class="fa fa-check"></i><b>6.61</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="6.62" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315-2"><i class="fa fa-check"></i><b>6.62</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a></li>
<li class="chapter" data-level="6.63" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-191"><i class="fa fa-check"></i><b>6.63</b> </a></li>
<li class="chapter" data-level="6.64" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-19"><i class="fa fa-check"></i><b>6.64</b> Call:</a></li>
<li class="chapter" data-level="6.65" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-syldur-v-data-devoicing"><i class="fa fa-check"></i><b>6.65</b> lm(formula = syldur ~ v, data = devoicing)</a></li>
<li class="chapter" data-level="6.66" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-192"><i class="fa fa-check"></i><b>6.66</b> </a></li>
<li class="chapter" data-level="6.67" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-15"><i class="fa fa-check"></i><b>6.67</b> Residuals:</a></li>
<li class="chapter" data-level="6.68" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-18"><i class="fa fa-check"></i><b>6.68</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.69" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-193"><i class="fa fa-check"></i><b>6.69</b> -108.006 -26.925 1.075 23.055 115.994</a></li>
<li class="chapter" data-level="6.70" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-194"><i class="fa fa-check"></i><b>6.70</b> </a></li>
<li class="chapter" data-level="6.71" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-16"><i class="fa fa-check"></i><b>6.71</b> Coefficients:</a></li>
<li class="chapter" data-level="6.72" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-14"><i class="fa fa-check"></i><b>6.72</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept-123.006-2.050-59.999-2e-16-vu-15.963-6.686-2.388-0.0173-vy--4.082-3.304--1.235-0.2173-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-36.56-on-547-degrees-of-freedom-multiple-r-squared-0.01559-adjusted-r-squared-0.01199-f-statistic-4.331-on-2-and-547-df-p-value-0.01361-u-y-i-0-0-u-1-0-y-0-1-basic-interpretation-of-contrasts-basic-interpretation-of-contrasts-example---c5ex1-reorder-factor-levels-to-make-conceptual-sense-noalternative-is-conceptually-between-alternative-and-new-remove-rows-where-response-is-na-this-is-just-due-to-an-issue-with-this-dataset-add-a-01-variable-where-1-adj-prominence-shifted-0-n-prominence-plot-of-the-basic-pattern-1-0.585-1-0.262-1-0.15-empirical-p-and-log-odds-of-shifting-prominence-a-tibble-3-x-3-context-p-logodds-1-alternative-0.585-0.345-2-noalternative-0.262--1.04-3-new-0.150--1.74-contrast-coding-schemes-dummy-coding-2-3-4-1-0-0-0-2-1-0-0-3-0-1-0-4-0-0-1-2-3-4-5-1-0-0-0-0-2-1-0-0-0-3-0-1-0-0-4-0-0-1-0-5-0-0-0-1-call-glmformula-shifted-context-family-binomial-data-alternatives-deviance-residuals-min-1q-median-3q-max--1.3269--0.7793--0.5696-1.0349-1.9487-coefficients-estimate-std.-error-z-value-prz-intercept-0.3448-0.1418-2.432-0.015-contextnoalternative--1.3809-0.2115--6.529-6.61e-11-contextnew--2.0813-0.2409--8.639-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-789.96-on-621-degrees-of-freedom-residual-deviance-694.53-on-619-degrees-of-freedom-aic-700.53-number-of-fisher-scoring-iterations-4-contrast-matrix-rightarrow-interpretation-1-2-3-1-0-1-0-2-0-0-1-sum-coding-1-2-3-1-1-0-0-2-0-1-0-3-0-0-1-4--1--1--1-1-2-3-4-1-1-0-0-0-2-0-1-0-0-3-0-0-1-0-4-0-0-0-1-5--1--1--1--1-1-2-3-1-0.6666667--0.3333333--0.3333333-2--0.3333333-0.6666667--0.3333333-example---sum-coded-version-of-context-call-glmformula-shifted-context.sum-family-binomial-data-alternatives-deviance-residuals-min-1q-median-3q-max--1.3269--0.7793--0.5696-1.0349-1.9487-coefficients-estimate-std.-error-z-value-prz-intercept--0.80925-0.09584--8.444-2e-16-context.sum1-1.15409-0.12604-9.157-2e-16-context.sum2--0.22684-0.13190--1.720-0.0855-.-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-789.96-on-621-degrees-of-freedom-residual-deviance-694.53-on-619-degrees-of-freedom-aic-700.53-number-of-fisher-scoring-iterations-4-helmert-coding-1-2-3-1--1--1--1-2-1--1--1-3-0-2--1-4-0-0-3-1-2-3-4-1--1--1--1--1-2-1--1--1--1-3-0-2--1--1-4-0-0-3--1-5-0-0-0-4-1-2-3-1--0.5000000-0.5000000-0.0000000-2--0.1666667--0.1666667-0.3333333-example---helmert-coded-version-of-context-call-glmformula-shifted-context.helm-family-binomial-data-alternatives-deviance-residuals-min-1q-median-3q-max--1.3269--0.7793--0.5696-1.0349-1.9487-coefficients-estimate-std.-error-z-value-prz-intercept--0.80925-0.09584--8.444-2e-16-context.helm1--0.69047-0.10575--6.529-6.61e-11-context.helm2--0.46362-0.07388--6.275-3.49e-10-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-789.96-on-621-degrees-of-freedom-residual-deviance-694.53-on-619-degrees-of-freedom-aic-700.53-number-of-fisher-scoring-iterations-4-other-coding-schemes-practical-advice-assessing-a-multi-level-factors-contribution-c5mlf-example---likelihood-ratio-test-to-check-whether-context-significantly-affects-prominence-shift-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-the-regression-coefficients-are-very-different-for-the-two-contrasts-for-context-under-different-coding-schemes-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context.helm-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context.sum-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-practice-with-interactions-example-1-two-way-interaction-with-multi-level-factor---we-should-choose-helmert-contrasts-contrast-1-difference-between-3-and-2-contrast-2-difference-between---and-23-change-factor-levels-for-folbound-so-highestlowest-choose-a-contrast-scheme-for-folbound-so-that-one-contrast-is-21-vs---the-distinction-seen-in-the-plot-call-lmformula-syldur-speechrate-folbound-data-devoicing"><span class="toc-section-number">6.73</span> (Intercept) 123.006 2.050 59.999 &lt;2e-16 <strong><em> ## vu 15.963 6.686 2.388 0.0173 </em><br />
## vy -4.082 3.304 -1.235 0.2173<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 36.56 on 547 degrees of freedom ## Multiple R-squared: 0.01559, Adjusted R-squared: 0.01199 ## F-statistic: 4.331 on 2 and 547 DF, p-value: 0.01361 ## u y ## i 0 0 ## u 1 0 ## y 0 1 ### Basic interpretation of contrasts {#basic-interpretation-of-contrasts} #### Example {- #c5ex1} ## reorder factor levels to make conceptual sense: âNoAlternativeâ is conceptually between âAlternativeâ and âNewâ ## remove rows where response is NA (this is just due to an issue with this dataset) ## add a 0/1 variable where 1 = adj prominence (shifted), 0 = N prominence ## plot of the basic pattern ## [1] 0.585 ## [1] 0.262 ## [1] 0.15 ## empirical p and log-odds of shifting prominence: ## # A tibble: 3 x 3 ## context p logOdds ## <fct> <dbl> <dbl> ## 1 Alternative 0.585 0.345 ## 2 NoAlternative 0.262 -1.04 ## 3 New 0.150 -1.74 ### Contrast coding schemes #### Dummy coding ## 2 3 4 ## 1 0 0 0 ## 2 1 0 0 ## 3 0 1 0 ## 4 0 0 1 ## 2 3 4 5 ## 1 0 0 0 0 ## 2 1 0 0 0 ## 3 0 1 0 0 ## 4 0 0 1 0 ## 5 0 0 0 1 ## ## Call: ## glm(formula = shifted ~ context, family = âbinomialâ, data = alternatives) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.3269 -0.7793 -0.5696 1.0349 1.9487<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) 0.3448 0.1418 2.432 0.015 *<br />
## contextNoAlternative -1.3809 0.2115 -6.529 6.61e-11 </strong><em> ## contextNew -2.0813 0.2409 -8.639 &lt; 2e-16 </em><strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 789.96 on 621 degrees of freedom ## Residual deviance: 694.53 on 619 degrees of freedom ## AIC: 700.53 ## ## Number of Fisher Scoring iterations: 4 #### Contrast matrix <span class="math inline">\(\rightarrow\)</span> interpretation ## [,1] [,2] [,3] ## [1,] 0 1 0 ## [2,] 0 0 1 #### Sum coding ## [,1] [,2] [,3] ## 1 1 0 0 ## 2 0 1 0 ## 3 0 0 1 ## 4 -1 -1 -1 ## [,1] [,2] [,3] [,4] ## 1 1 0 0 0 ## 2 0 1 0 0 ## 3 0 0 1 0 ## 4 0 0 0 1 ## 5 -1 -1 -1 -1 ## [,1] [,2] [,3] ## [1,] 0.6666667 -0.3333333 -0.3333333 ## [2,] -0.3333333 0.6666667 -0.3333333 #### Example {-} ## sum-coded version of context ## ## Call: ## glm(formula = shifted ~ context.sum, family = âbinomialâ, data = alternatives) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.3269 -0.7793 -0.5696 1.0349 1.9487<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.80925 0.09584 -8.444 &lt;2e-16 </strong><em> ## context.sum1 1.15409 0.12604 9.157 &lt;2e-16 </em><strong> ## context.sum2 -0.22684 0.13190 -1.720 0.0855 .<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 789.96 on 621 degrees of freedom ## Residual deviance: 694.53 on 619 degrees of freedom ## AIC: 700.53 ## ## Number of Fisher Scoring iterations: 4 #### Helmert coding ## [,1] [,2] [,3] ## 1 -1 -1 -1 ## 2 1 -1 -1 ## 3 0 2 -1 ## 4 0 0 3 ## [,1] [,2] [,3] [,4] ## 1 -1 -1 -1 -1 ## 2 1 -1 -1 -1 ## 3 0 2 -1 -1 ## 4 0 0 3 -1 ## 5 0 0 0 4 ## [,1] [,2] [,3] ## [1,] -0.5000000 0.5000000 0.0000000 ## [2,] -0.1666667 -0.1666667 0.3333333 #### Example {-} ## Helmert-coded version of context ## ## Call: ## glm(formula = shifted ~ context.helm, family = âbinomialâ, data = alternatives) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.3269 -0.7793 -0.5696 1.0349 1.9487<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.80925 0.09584 -8.444 &lt; 2e-16 </strong><em> ## context.helm1 -0.69047 0.10575 -6.529 6.61e-11 </em><strong> ## context.helm2 -0.46362 0.07388 -6.275 3.49e-10 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 789.96 on 621 degrees of freedom ## Residual deviance: 694.53 on 619 degrees of freedom ## AIC: 700.53 ## ## Number of Fisher Scoring iterations: 4 #### Other coding schemes #### Practical advice ## Assessing a multi-level factorâs contribution {#c5mlf} #### Example {-} ## likelihood ratio test to check whether context significantly affects prominence shift ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </em><strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## the regression coefficients are very different for the two contrasts for context ## under different coding schemesâ¦ ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context.helm ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </em><strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context.sum ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## Practice with interactions #### Example 1: Two-way interaction with multi-level factor {-} ## we should choose </em>Helmert contrasts<em>: ## contrast 1: difference between 3 and 2 ## contrast 2: difference between - and 2/3 ## change factor levels for folbound so highest&gt;lowest ## Choose a contrast scheme for folbound so that one contrast is 2/1 vs - (the distinction seen in the plot) ## ## Call: ## lm(formula = syldur ~ speechrate </em> folbound, data = devoicing)</a></li>
<li class="chapter" data-level="6.74" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-195"><i class="fa fa-check"></i><b>6.74</b> </a></li>
<li class="chapter" data-level="6.75" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-16"><i class="fa fa-check"></i><b>6.75</b> Residuals:</a></li>
<li class="chapter" data-level="6.76" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-19"><i class="fa fa-check"></i><b>6.76</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.77" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-196"><i class="fa fa-check"></i><b>6.77</b> -109.769 -21.641 0.858 21.919 111.630</a></li>
<li class="chapter" data-level="6.78" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-197"><i class="fa fa-check"></i><b>6.78</b> </a></li>
<li class="chapter" data-level="6.79" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-17"><i class="fa fa-check"></i><b>6.79</b> Coefficients:</a></li>
<li class="chapter" data-level="6.80" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-15"><i class="fa fa-check"></i><b>6.80</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.81" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept-204.4614-8.6510-23.635-2e-16-speechrate--10.8602-1.2524--8.671-2e-16"><i class="fa fa-check"></i><b>6.81</b> (Intercept) 204.4614 8.6510 23.635 &lt; 2e-16 <strong><em> ## speechrate -10.8602 1.2524 -8.671 &lt; 2e-16 </em></strong></a></li>
<li class="chapter" data-level="6.82" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#folbound1-0.4630-12.2837-0.038-0.96995"><i class="fa fa-check"></i><b>6.82</b> folbound1 0.4630 12.2837 0.038 0.96995</a></li>
<li><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#folbound2--20.9193-4.9541--4.223-2.83e-05-speechratefolbound1-0.2153-1.7835-0.121-0.90398-speechratefolbound2-1.9173-0.7130-2.689-0.00739-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-32.47-on-544-degrees-of-freedom-multiple-r-squared-0.2276-adjusted-r-squared-0.2205-f-statistic-32.06-on-5-and-544-df-p-value-2.2e-16-example-2-three-way-interaction---call-glmformula-stressshift-conditionlabel.williams-nptype.pron"><span class="toc-section-number">6.83</span> folbound2 -20.9193 4.9541 -4.223 2.83e-05 <em><strong> ## speechrate:folbound1 0.2153 1.7835 0.121 0.90398<br />
## speechrate:folbound2 1.9173 0.7130 2.689 0.00739 </strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Residual standard error: 32.47 on 544 degrees of freedom ## Multiple R-squared: 0.2276, Adjusted R-squared: 0.2205 ## F-statistic: 32.06 on 5 and 544 DF, p-value: &lt; 2.2e-16 #### Example 2: Three-way interaction {-} ## ## Call: ## glm(formula = stressshift ~ conditionLabel.williams </em> npType.pron *</a></li>
<li class="chapter" data-level="6.84" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#voice.passive-family-binomial-data-givenness"><i class="fa fa-check"></i><b>6.84</b> voice.passive, family = âbinomialâ, data = givenness)</a></li>
<li class="chapter" data-level="6.85" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-198"><i class="fa fa-check"></i><b>6.85</b> </a></li>
<li class="chapter" data-level="6.86" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#deviance-residuals-3"><i class="fa fa-check"></i><b>6.86</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="6.87" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-20"><i class="fa fa-check"></i><b>6.87</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.88" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-199"><i class="fa fa-check"></i><b>6.88</b> -1.9728 -0.5746 -0.3518 0.5553 2.5601</a></li>
<li class="chapter" data-level="6.89" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-200"><i class="fa fa-check"></i><b>6.89</b> </a></li>
<li class="chapter" data-level="6.90" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-18"><i class="fa fa-check"></i><b>6.90</b> Coefficients:</a></li>
<li class="chapter" data-level="6.91" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-1"><i class="fa fa-check"></i><b>6.91</b> Estimate Std. Error</a></li>
<li class="chapter" data-level="6.92" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.9807-0.1704"><i class="fa fa-check"></i><b>6.92</b> (Intercept) -0.9807 0.1704</a></li>
<li class="chapter" data-level="6.93" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williams-3.2322-0.3347"><i class="fa fa-check"></i><b>6.93</b> conditionLabel.williams 3.2322 0.3347</a></li>
<li class="chapter" data-level="6.94" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pron-0.4295-0.3403"><i class="fa fa-check"></i><b>6.94</b> npType.pron 0.4295 0.3403</a></li>
<li class="chapter" data-level="6.95" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#voice.passive-0.3168-0.3392"><i class="fa fa-check"></i><b>6.95</b> voice.passive 0.3168 0.3392</a></li>
<li class="chapter" data-level="6.96" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pron-0.7082-0.6684"><i class="fa fa-check"></i><b>6.96</b> conditionLabel.williams:npType.pron 0.7082 0.6684</a></li>
<li class="chapter" data-level="6.97" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsvoice.passive-1.9230-0.6662"><i class="fa fa-check"></i><b>6.97</b> conditionLabel.williams:voice.passive 1.9230 0.6662</a></li>
<li class="chapter" data-level="6.98" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pronvoice.passive--0.8359-0.6776"><i class="fa fa-check"></i><b>6.98</b> npType.pron:voice.passive -0.8359 0.6776</a></li>
<li class="chapter" data-level="6.99" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pronvoice.passive-2.1099-1.3308"><i class="fa fa-check"></i><b>6.99</b> conditionLabel.williams:npType.pron:voice.passive 2.1099 1.3308</a></li>
<li class="chapter" data-level="6.100" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#z-value-prz"><i class="fa fa-check"></i><b>6.100</b> z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="6.101" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--5.756-8.61e-09-conditionlabel.williams-9.658-2e-16"><i class="fa fa-check"></i><b>6.101</b> (Intercept) -5.756 8.61e-09 <strong><em> ## conditionLabel.williams 9.658 &lt; 2e-16 </em></strong></a></li>
<li class="chapter" data-level="6.102" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pron-1.262-0.20691"><i class="fa fa-check"></i><b>6.102</b> npType.pron 1.262 0.20691</a></li>
<li class="chapter" data-level="6.103" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#voice.passive-0.934-0.35028"><i class="fa fa-check"></i><b>6.103</b> voice.passive 0.934 0.35028</a></li>
<li class="chapter" data-level="6.104" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pron-1.060-0.28937"><i class="fa fa-check"></i><b>6.104</b> conditionLabel.williams:npType.pron 1.060 0.28937</a></li>
<li class="chapter" data-level="6.105" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsvoice.passive-2.887-0.00389"><i class="fa fa-check"></i><b>6.105</b> conditionLabel.williams:voice.passive 2.887 0.00389 **</a></li>
<li class="chapter" data-level="6.106" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pronvoice.passive--1.234-0.21731"><i class="fa fa-check"></i><b>6.106</b> npType.pron:voice.passive -1.234 0.21731</a></li>
<li class="chapter" data-level="6.107" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pronvoice.passive-1.585-0.11289"><i class="fa fa-check"></i><b>6.107</b> conditionLabel.williams:npType.pron:voice.passive 1.585 0.11289</a></li>
<li class="chapter" data-level="6.108" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-201"><i class="fa fa-check"></i><b>6.108</b> â</a></li>
<li class="chapter" data-level="6.109" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-18"><i class="fa fa-check"></i><b>6.109</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="6.110" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-202"><i class="fa fa-check"></i><b>6.110</b> </a></li>
<li class="chapter" data-level="6.111" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#dispersion-parameter-for-binomial-family-taken-to-be-1-1"><i class="fa fa-check"></i><b>6.111</b> (Dispersion parameter for binomial family taken to be 1)</a></li>
<li class="chapter" data-level="6.112" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-203"><i class="fa fa-check"></i><b>6.112</b> </a></li>
<li class="chapter" data-level="6.113" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#null-deviance-496.24-on-381-degrees-of-freedom-1"><i class="fa fa-check"></i><b>6.113</b> Null deviance: 496.24 on 381 degrees of freedom</a></li>
<li class="chapter" data-level="6.114" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-deviance-323.94-on-374-degrees-of-freedom"><i class="fa fa-check"></i><b>6.114</b> Residual deviance: 323.94 on 374 degrees of freedom</a></li>
<li class="chapter" data-level="6.115" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#aic-339.94"><i class="fa fa-check"></i><b>6.115</b> AIC: 339.94</a></li>
<li class="chapter" data-level="6.116" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-204"><i class="fa fa-check"></i><b>6.116</b> </a></li>
<li class="chapter" data-level="6.117" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#number-of-fisher-scoring-iterations-5"><i class="fa fa-check"></i><b>6.117</b> Number of Fisher Scoring iterations: 5</a></li>
<li class="chapter" data-level="6.118" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#c5solns"><i class="fa fa-check"></i><b>6.118</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lmem.html"><a href="lmem.html"><i class="fa fa-check"></i><b>7</b> Linear mixed models</a><ul>
<li class="chapter" data-level="7.1" data-path="lmem.html"><a href="lmem.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data-2"><i class="fa fa-check"></i><b>7.1</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="7.2" data-path="lmem.html"><a href="lmem.html#define-numeric-versions-of-factors-for-convenience"><i class="fa fa-check"></i><b>7.2</b> define numeric versions of factors, for convenience</a></li>
<li class="chapter" data-level="7.3" data-path="lmem.html"><a href="lmem.html#make-non-mixed-effect-model-prediction-for-examples-below-just-one-prediction-per"><i class="fa fa-check"></i><b>7.3</b> make non-mixed-effect model prediction for examples below (just one prediction per</a></li>
<li class="chapter" data-level="7.4" data-path="lmem.html"><a href="lmem.html#level-of-conditionlabel"><i class="fa fa-check"></i><b>7.4</b> level of conditionLabel)</a></li>
<li class="chapter" data-level="7.5" data-path="lmem.html"><a href="lmem.html#loads-halfrhymemcgillling620.csv-from-osf-project-for-harder-2013-data-1"><i class="fa fa-check"></i><b>7.5</b> loads halfrhymeMcGillLing620.csv from OSF project for Harder (2013) data</a></li>
<li class="chapter" data-level="7.6" data-path="lmem.html"><a href="lmem.html#need-to-do-this-because-the-relduration-variable-is-only-defined-when-conditionlabel-is-voice"><i class="fa fa-check"></i><b>7.6</b> need to do this because the relDuration variable is only defined when conditionLabel is âvoiceâ</a></li>
<li class="chapter" data-level="7.7" data-path="lmem.html"><a href="lmem.html#mixed-effects-models-motivation"><i class="fa fa-check"></i><b>7.7</b> Mixed-effects models: Motivation</a><ul>
<li class="chapter" data-level="7.7.1" data-path="lmem.html"><a href="lmem.html#simpsons-paradox"><i class="fa fa-check"></i><b>7.7.1</b> Simpsonâs paradox</a></li>
<li class="chapter" data-level="7.7.2" data-path="lmem.html"><a href="lmem.html#repeated-measure-anovas"><i class="fa fa-check"></i><b>7.7.2</b> Repeated-measure ANOVAs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-1-one-grouping-factor-random-intercepts"><i class="fa fa-check"></i><b>7.8</b> Linear mixed models 1: One grouping factor, random intercepts</a><ul>
<li class="chapter" data-level="7.8.1" data-path="lmem.html"><a href="lmem.html#c6model1A"><i class="fa fa-check"></i><b>7.8.1</b> Model 1A: Simple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="lmem.html"><a href="lmem.html#section-205"><i class="fa fa-check"></i><b>7.9</b> </a></li>
<li class="chapter" data-level="7.10" data-path="lmem.html"><a href="lmem.html#call-20"><i class="fa fa-check"></i><b>7.10</b> Call:</a></li>
<li class="chapter" data-level="7.11" data-path="lmem.html"><a href="lmem.html#lmformula-acoustics-conditionlabel.williams-data-givenness"><i class="fa fa-check"></i><b>7.11</b> lm(formula = acoustics ~ conditionLabel.williams, data = givenness)</a></li>
<li class="chapter" data-level="7.12" data-path="lmem.html"><a href="lmem.html#section-206"><i class="fa fa-check"></i><b>7.12</b> </a></li>
<li class="chapter" data-level="7.13" data-path="lmem.html"><a href="lmem.html#residuals-17"><i class="fa fa-check"></i><b>7.13</b> Residuals:</a></li>
<li class="chapter" data-level="7.14" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-21"><i class="fa fa-check"></i><b>7.14</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.15" data-path="lmem.html"><a href="lmem.html#section-207"><i class="fa fa-check"></i><b>7.15</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="7.16" data-path="lmem.html"><a href="lmem.html#section-208"><i class="fa fa-check"></i><b>7.16</b> </a></li>
<li class="chapter" data-level="7.17" data-path="lmem.html"><a href="lmem.html#coefficients-19"><i class="fa fa-check"></i><b>7.17</b> Coefficients:</a></li>
<li class="chapter" data-level="7.18" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-prt-16"><i class="fa fa-check"></i><b>7.18</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.19" data-path="lmem.html"><a href="lmem.html#intercept--0.72205-0.04109--17.570-2e-16-conditionlabel.williams-0.31774-0.08224-3.863-0.000131"><i class="fa fa-check"></i><b>7.19</b> (Intercept) -0.72205 0.04109 -17.570 &lt; 2e-16 <strong><em> ## conditionLabel.williams 0.31774 0.08224 3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="7.20" data-path="lmem.html"><a href="lmem.html#section-209"><i class="fa fa-check"></i><b>7.20</b> â</a></li>
<li class="chapter" data-level="7.21" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-19"><i class="fa fa-check"></i><b>7.21</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="7.22" data-path="lmem.html"><a href="lmem.html#section-210"><i class="fa fa-check"></i><b>7.22</b> </a></li>
<li class="chapter" data-level="7.23" data-path="lmem.html"><a href="lmem.html#residual-standard-error-0.8032-on-380-degrees-of-freedom-3"><i class="fa fa-check"></i><b>7.23</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="7.24" data-path="lmem.html"><a href="lmem.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526-3"><i class="fa fa-check"></i><b>7.24</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="7.25" data-path="lmem.html"><a href="lmem.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315-3"><i class="fa fa-check"></i><b>7.25</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a><ul>
<li class="chapter" data-level="7.25.1" data-path="lmem.html"><a href="lmem.html#c6model1b"><i class="fa fa-check"></i><b>7.25.1</b> Model 1B: Random intercept only</a></li>
</ul></li>
<li class="chapter" data-level="7.26" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod"><i class="fa fa-check"></i><b>7.26</b> Linear mixed model fit by REML [âlmerModâ]</a></li>
<li class="chapter" data-level="7.27" data-path="lmem.html"><a href="lmem.html#formula-acoustics-conditionlabel.williams-1-participant"><i class="fa fa-check"></i><b>7.27</b> Formula: acoustics ~ conditionLabel.williams + (1 | participant)</a></li>
<li class="chapter" data-level="7.28" data-path="lmem.html"><a href="lmem.html#data-givenness-1"><i class="fa fa-check"></i><b>7.28</b> Data: givenness</a></li>
<li class="chapter" data-level="7.29" data-path="lmem.html"><a href="lmem.html#section-211"><i class="fa fa-check"></i><b>7.29</b> </a></li>
<li class="chapter" data-level="7.30" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-897.9"><i class="fa fa-check"></i><b>7.30</b> REML criterion at convergence: 897.9</a></li>
<li class="chapter" data-level="7.31" data-path="lmem.html"><a href="lmem.html#section-212"><i class="fa fa-check"></i><b>7.31</b> </a></li>
<li class="chapter" data-level="7.32" data-path="lmem.html"><a href="lmem.html#scaled-residuals"><i class="fa fa-check"></i><b>7.32</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.33" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-22"><i class="fa fa-check"></i><b>7.33</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.34" data-path="lmem.html"><a href="lmem.html#section-213"><i class="fa fa-check"></i><b>7.34</b> -3.0538 -0.7129 0.0083 0.6540 3.3136</a></li>
<li class="chapter" data-level="7.35" data-path="lmem.html"><a href="lmem.html#section-214"><i class="fa fa-check"></i><b>7.35</b> </a></li>
<li class="chapter" data-level="7.36" data-path="lmem.html"><a href="lmem.html#random-effects"><i class="fa fa-check"></i><b>7.36</b> Random effects:</a></li>
<li class="chapter" data-level="7.37" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev."><i class="fa fa-check"></i><b>7.37</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.38" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.08937-0.299"><i class="fa fa-check"></i><b>7.38</b> participant (Intercept) 0.08937 0.299</a></li>
<li class="chapter" data-level="7.39" data-path="lmem.html"><a href="lmem.html#residual-0.55800-0.747"><i class="fa fa-check"></i><b>7.39</b> Residual 0.55800 0.747</a></li>
<li class="chapter" data-level="7.40" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27"><i class="fa fa-check"></i><b>7.40</b> Number of obs: 382, groups: participant, 27</a></li>
<li class="chapter" data-level="7.41" data-path="lmem.html"><a href="lmem.html#section-215"><i class="fa fa-check"></i><b>7.41</b> </a></li>
<li class="chapter" data-level="7.42" data-path="lmem.html"><a href="lmem.html#fixed-effects"><i class="fa fa-check"></i><b>7.42</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.43" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value"><i class="fa fa-check"></i><b>7.43</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.44" data-path="lmem.html"><a href="lmem.html#intercept--0.71856-0.06916--10.39"><i class="fa fa-check"></i><b>7.44</b> (Intercept) -0.71856 0.06916 -10.39</a></li>
<li class="chapter" data-level="7.45" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.32626-0.07677-4.25"><i class="fa fa-check"></i><b>7.45</b> conditionLabel.williams 0.32626 0.07677 4.25</a></li>
<li class="chapter" data-level="7.46" data-path="lmem.html"><a href="lmem.html#section-216"><i class="fa fa-check"></i><b>7.46</b> </a></li>
<li class="chapter" data-level="7.47" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects"><i class="fa fa-check"></i><b>7.47</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.48" data-path="lmem.html"><a href="lmem.html#intr"><i class="fa fa-check"></i><b>7.48</b> (Intr)</a></li>
<li class="chapter" data-level="7.49" data-path="lmem.html"><a href="lmem.html#cndtnlbl.wl-0.002"><i class="fa fa-check"></i><b>7.49</b> cndtnLbl.wl 0.002</a></li>
<li class="chapter" data-level="7.50" data-path="lmem.html"><a href="lmem.html#intercept"><i class="fa fa-check"></i><b>7.50</b> (Intercept)</a></li>
<li class="chapter" data-level="7.51" data-path="lmem.html"><a href="lmem.html#section-217"><i class="fa fa-check"></i><b>7.51</b> 24 0.085333501</a></li>
<li class="chapter" data-level="7.52" data-path="lmem.html"><a href="lmem.html#section-218"><i class="fa fa-check"></i><b>7.52</b> 297 0.036820472</a></li>
<li class="chapter" data-level="7.53" data-path="lmem.html"><a href="lmem.html#section-219"><i class="fa fa-check"></i><b>7.53</b> 432 -0.411839925</a></li>
<li class="chapter" data-level="7.54" data-path="lmem.html"><a href="lmem.html#section-220"><i class="fa fa-check"></i><b>7.54</b> 524 0.116659623</a></li>
<li class="chapter" data-level="7.55" data-path="lmem.html"><a href="lmem.html#section-221"><i class="fa fa-check"></i><b>7.55</b> 529 -0.485395105</a></li>
<li class="chapter" data-level="7.56" data-path="lmem.html"><a href="lmem.html#section-222"><i class="fa fa-check"></i><b>7.56</b> 530 -0.077424563</a></li>
<li class="chapter" data-level="7.57" data-path="lmem.html"><a href="lmem.html#section-223"><i class="fa fa-check"></i><b>7.57</b> 540 0.244536341</a></li>
<li class="chapter" data-level="7.58" data-path="lmem.html"><a href="lmem.html#section-224"><i class="fa fa-check"></i><b>7.58</b> 541 0.193392070</a></li>
<li class="chapter" data-level="7.59" data-path="lmem.html"><a href="lmem.html#section-225"><i class="fa fa-check"></i><b>7.59</b> 542 -0.126468368</a></li>
<li class="chapter" data-level="7.60" data-path="lmem.html"><a href="lmem.html#section-226"><i class="fa fa-check"></i><b>7.60</b> 544 0.012462384</a></li>
<li class="chapter" data-level="7.61" data-path="lmem.html"><a href="lmem.html#section-227"><i class="fa fa-check"></i><b>7.61</b> 547 -0.335559107</a></li>
<li class="chapter" data-level="7.62" data-path="lmem.html"><a href="lmem.html#section-228"><i class="fa fa-check"></i><b>7.62</b> 548 0.489860310</a></li>
<li class="chapter" data-level="7.63" data-path="lmem.html"><a href="lmem.html#section-229"><i class="fa fa-check"></i><b>7.63</b> 549 -0.135853392</a></li>
<li class="chapter" data-level="7.64" data-path="lmem.html"><a href="lmem.html#section-230"><i class="fa fa-check"></i><b>7.64</b> 550 -0.047183013</a></li>
<li class="chapter" data-level="7.65" data-path="lmem.html"><a href="lmem.html#section-231"><i class="fa fa-check"></i><b>7.65</b> 552 -0.032362240</a></li>
<li class="chapter" data-level="7.66" data-path="lmem.html"><a href="lmem.html#section-232"><i class="fa fa-check"></i><b>7.66</b> 553 0.239715782</a></li>
<li class="chapter" data-level="7.67" data-path="lmem.html"><a href="lmem.html#section-233"><i class="fa fa-check"></i><b>7.67</b> 554 -0.045139278</a></li>
<li class="chapter" data-level="7.68" data-path="lmem.html"><a href="lmem.html#section-234"><i class="fa fa-check"></i><b>7.68</b> 555 -0.204230783</a></li>
<li class="chapter" data-level="7.69" data-path="lmem.html"><a href="lmem.html#section-235"><i class="fa fa-check"></i><b>7.69</b> 556 -0.104644687</a></li>
<li class="chapter" data-level="7.70" data-path="lmem.html"><a href="lmem.html#section-236"><i class="fa fa-check"></i><b>7.70</b> 557 0.199844627</a></li>
<li class="chapter" data-level="7.71" data-path="lmem.html"><a href="lmem.html#section-237"><i class="fa fa-check"></i><b>7.71</b> 558 0.004117646</a></li>
<li class="chapter" data-level="7.72" data-path="lmem.html"><a href="lmem.html#section-238"><i class="fa fa-check"></i><b>7.72</b> 559 -0.336348686</a></li>
<li class="chapter" data-level="7.73" data-path="lmem.html"><a href="lmem.html#section-239"><i class="fa fa-check"></i><b>7.73</b> 560 0.307842484</a></li>
<li class="chapter" data-level="7.74" data-path="lmem.html"><a href="lmem.html#section-240"><i class="fa fa-check"></i><b>7.74</b> 561 0.530048433</a></li>
<li class="chapter" data-level="7.75" data-path="lmem.html"><a href="lmem.html#section-241"><i class="fa fa-check"></i><b>7.75</b> 562 -0.163493454</a></li>
<li class="chapter" data-level="7.76" data-path="lmem.html"><a href="lmem.html#section-242"><i class="fa fa-check"></i><b>7.76</b> 563 -0.072168272</a></li>
<li class="chapter" data-level="7.77" data-path="lmem.html"><a href="lmem.html#section-243"><i class="fa fa-check"></i><b>7.77</b> 564 0.117477201</a></li>
<li class="chapter" data-level="7.78" data-path="lmem.html"><a href="lmem.html#intercept-1"><i class="fa fa-check"></i><b>7.78</b> (Intercept)</a></li>
<li class="chapter" data-level="7.79" data-path="lmem.html"><a href="lmem.html#section-244"><i class="fa fa-check"></i><b>7.79</b> 24 0.1583862</a></li>
<li class="chapter" data-level="7.80" data-path="lmem.html"><a href="lmem.html#section-245"><i class="fa fa-check"></i><b>7.80</b> 297 0.1620712</a></li>
<li class="chapter" data-level="7.81" data-path="lmem.html"><a href="lmem.html#section-246"><i class="fa fa-check"></i><b>7.81</b> 432 0.1620712</a></li>
<li class="chapter" data-level="7.82" data-path="lmem.html"><a href="lmem.html#section-247"><i class="fa fa-check"></i><b>7.82</b> 524 0.1853443</a></li>
<li class="chapter" data-level="7.83" data-path="lmem.html"><a href="lmem.html#section-248"><i class="fa fa-check"></i><b>7.83</b> 529 0.1660260</a></li>
<li class="chapter" data-level="7.84" data-path="lmem.html"><a href="lmem.html#section-249"><i class="fa fa-check"></i><b>7.84</b> 530 0.1620712</a></li>
<li class="chapter" data-level="7.85" data-path="lmem.html"><a href="lmem.html#section-250"><i class="fa fa-check"></i><b>7.85</b> 540 0.1660260</a></li>
<li class="chapter" data-level="7.86" data-path="lmem.html"><a href="lmem.html#section-251"><i class="fa fa-check"></i><b>7.86</b> 541 0.1660260</a></li>
<li class="chapter" data-level="7.87" data-path="lmem.html"><a href="lmem.html#section-252"><i class="fa fa-check"></i><b>7.87</b> 542 0.1583862</a></li>
<li class="chapter" data-level="7.88" data-path="lmem.html"><a href="lmem.html#section-253"><i class="fa fa-check"></i><b>7.88</b> 544 0.1748900</a></li>
<li class="chapter" data-level="7.89" data-path="lmem.html"><a href="lmem.html#section-254"><i class="fa fa-check"></i><b>7.89</b> 547 0.1620712</a></li>
<li class="chapter" data-level="7.90" data-path="lmem.html"><a href="lmem.html#section-255"><i class="fa fa-check"></i><b>7.90</b> 548 0.1660260</a></li>
<li class="chapter" data-level="7.91" data-path="lmem.html"><a href="lmem.html#section-256"><i class="fa fa-check"></i><b>7.91</b> 549 0.1583862</a></li>
<li class="chapter" data-level="7.92" data-path="lmem.html"><a href="lmem.html#section-257"><i class="fa fa-check"></i><b>7.92</b> 550 0.1620712</a></li>
<li class="chapter" data-level="7.93" data-path="lmem.html"><a href="lmem.html#section-258"><i class="fa fa-check"></i><b>7.93</b> 552 0.1748900</a></li>
<li class="chapter" data-level="7.94" data-path="lmem.html"><a href="lmem.html#section-259"><i class="fa fa-check"></i><b>7.94</b> 553 0.1660260</a></li>
<li class="chapter" data-level="7.95" data-path="lmem.html"><a href="lmem.html#section-260"><i class="fa fa-check"></i><b>7.95</b> 554 0.1620712</a></li>
<li class="chapter" data-level="7.96" data-path="lmem.html"><a href="lmem.html#section-261"><i class="fa fa-check"></i><b>7.96</b> 555 0.1620712</a></li>
<li class="chapter" data-level="7.97" data-path="lmem.html"><a href="lmem.html#section-262"><i class="fa fa-check"></i><b>7.97</b> 556 0.1620712</a></li>
<li class="chapter" data-level="7.98" data-path="lmem.html"><a href="lmem.html#section-263"><i class="fa fa-check"></i><b>7.98</b> 557 0.1660260</a></li>
<li class="chapter" data-level="7.99" data-path="lmem.html"><a href="lmem.html#section-264"><i class="fa fa-check"></i><b>7.99</b> 558 0.1660260</a></li>
<li class="chapter" data-level="7.100" data-path="lmem.html"><a href="lmem.html#section-265"><i class="fa fa-check"></i><b>7.100</b> 559 0.1702852</a></li>
<li class="chapter" data-level="7.101" data-path="lmem.html"><a href="lmem.html#section-266"><i class="fa fa-check"></i><b>7.101</b> 560 0.1660260</a></li>
<li class="chapter" data-level="7.102" data-path="lmem.html"><a href="lmem.html#section-267"><i class="fa fa-check"></i><b>7.102</b> 561 0.1620712</a></li>
<li class="chapter" data-level="7.103" data-path="lmem.html"><a href="lmem.html#section-268"><i class="fa fa-check"></i><b>7.103</b> 562 0.1583862</a></li>
<li class="chapter" data-level="7.104" data-path="lmem.html"><a href="lmem.html#section-269"><i class="fa fa-check"></i><b>7.104</b> 563 0.1798897</a></li>
<li class="chapter" data-level="7.105" data-path="lmem.html"><a href="lmem.html#section-270"><i class="fa fa-check"></i><b>7.105</b> 564 0.1702852</a></li>
<li class="chapter" data-level="7.106" data-path="lmem.html"><a href="lmem.html#model-1b-random-intercept-only"><i class="fa fa-check"></i><b>7.106</b> MODEL 1B: random intercept only</a></li>
<li class="chapter" data-level="7.107" data-path="lmem.html"><a href="lmem.html#set-up-a-dataframe-for-which-the-model-should-predict-new-values"><i class="fa fa-check"></i><b>7.107</b> set up a dataframe for which the model should predict new values:</a></li>
<li class="chapter" data-level="7.108" data-path="lmem.html"><a href="lmem.html#each-level-of-conditionlabel-for-each-participant."><i class="fa fa-check"></i><b>7.108</b> each level of conditionLabel, for each participant.</a></li>
<li class="chapter" data-level="7.109" data-path="lmem.html"><a href="lmem.html#its-easiest-to-understand-this-if-we-first-refit-a-version-of-mod1b-using-the-factor-version-of-conditionlabel-rather-than-the-numeric-conditionlabel.williams-version"><i class="fa fa-check"></i><b>7.109</b> itâs easiest to understand this if we first refit a version of mod1b using the <em>factor</em> version of conditionLabel (rather than the numeric conditionLabel.williams version)</a></li>
<li class="chapter" data-level="7.110" data-path="lmem.html"><a href="lmem.html#set-up-a-dataframe-to-predict-values-for-one-row-per-participantcond-label-pair"><i class="fa fa-check"></i><b>7.110</b> set up a dataframe to predict values for: one row per participant/cond label pair</a></li>
<li class="chapter" data-level="7.111" data-path="lmem.html"><a href="lmem.html#get-the-predicted-value-for-each-case"><i class="fa fa-check"></i><b>7.111</b> get the predicted value for each case</a></li>
<li class="chapter" data-level="7.112" data-path="lmem.html"><a href="lmem.html#plot-the-models-prediction-for-each-participant"><i class="fa fa-check"></i><b>7.112</b> plot the modelâs prediction for each participant:</a></li>
<li class="chapter" data-level="7.113" data-path="lmem.html"><a href="lmem.html#get-the-same-predictions-but-for-model-1.-first-fit-a-version-with-the-factor-for-conditionlabel"><i class="fa fa-check"></i><b>7.113</b> get the same predictions but for model 1. first fit a version with the factor for conditionlabel:</a></li>
<li class="chapter" data-level="7.114" data-path="lmem.html"><a href="lmem.html#empirical-mean-acoustic-values-by-participant"><i class="fa fa-check"></i><b>7.114</b> empirical mean acoustic values by participant</a></li>
<li class="chapter" data-level="7.115" data-path="lmem.html"><a href="lmem.html#participant-random-effects"><i class="fa fa-check"></i><b>7.115</b> participant random effects</a></li>
<li class="chapter" data-level="7.116" data-path="lmem.html"><a href="lmem.html#c6lmm2"><i class="fa fa-check"></i><b>7.116</b> Linear mixed models 2: One grouping factor, random intercepts and slopes</a><ul>
<li class="chapter" data-level="7.116.1" data-path="lmem.html"><a href="lmem.html#c6model1c"><i class="fa fa-check"></i><b>7.116.1</b> Model 1C</a></li>
<li class="chapter" data-level="7.116.2" data-path="lmem.html"><a href="lmem.html#fitting-model-1c"><i class="fa fa-check"></i><b>7.116.2</b> Fitting Model 1C</a></li>
</ul></li>
<li class="chapter" data-level="7.117" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod-1"><i class="fa fa-check"></i><b>7.117</b> Linear mixed model fit by REML [âlmerModâ]</a></li>
<li class="chapter" data-level="7.118" data-path="lmem.html"><a href="lmem.html#formula"><i class="fa fa-check"></i><b>7.118</b> Formula:</a></li>
<li class="chapter" data-level="7.119" data-path="lmem.html"><a href="lmem.html#rhymerating-relduration-1-participant-0-relduration"><i class="fa fa-check"></i><b>7.119</b> rhymeRating ~ relDuration + ((1 | participant) + (0 + relDuration |</a></li>
<li class="chapter" data-level="7.120" data-path="lmem.html"><a href="lmem.html#participant"><i class="fa fa-check"></i><b>7.120</b> participant))</a></li>
<li class="chapter" data-level="7.121" data-path="lmem.html"><a href="lmem.html#data-halfrhyme"><i class="fa fa-check"></i><b>7.121</b> Data: halfrhyme</a></li>
<li class="chapter" data-level="7.122" data-path="lmem.html"><a href="lmem.html#section-271"><i class="fa fa-check"></i><b>7.122</b> </a></li>
<li class="chapter" data-level="7.123" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-2578.7"><i class="fa fa-check"></i><b>7.123</b> REML criterion at convergence: 2578.7</a></li>
<li class="chapter" data-level="7.124" data-path="lmem.html"><a href="lmem.html#section-272"><i class="fa fa-check"></i><b>7.124</b> </a></li>
<li class="chapter" data-level="7.125" data-path="lmem.html"><a href="lmem.html#scaled-residuals-1"><i class="fa fa-check"></i><b>7.125</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.126" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-23"><i class="fa fa-check"></i><b>7.126</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.127" data-path="lmem.html"><a href="lmem.html#section-273"><i class="fa fa-check"></i><b>7.127</b> -2.4022 -0.6091 -0.1126 0.6138 3.5726</a></li>
<li class="chapter" data-level="7.128" data-path="lmem.html"><a href="lmem.html#section-274"><i class="fa fa-check"></i><b>7.128</b> </a></li>
<li class="chapter" data-level="7.129" data-path="lmem.html"><a href="lmem.html#random-effects-1"><i class="fa fa-check"></i><b>7.129</b> Random effects:</a></li>
<li class="chapter" data-level="7.130" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-1"><i class="fa fa-check"></i><b>7.130</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.131" data-path="lmem.html"><a href="lmem.html#participant-intercept-1.267-1.126"><i class="fa fa-check"></i><b>7.131</b> participant (Intercept) 1.267 1.126</a></li>
<li class="chapter" data-level="7.132" data-path="lmem.html"><a href="lmem.html#participant.1-relduration-4.482-2.117"><i class="fa fa-check"></i><b>7.132</b> participant.1 relDuration 4.482 2.117</a></li>
<li class="chapter" data-level="7.133" data-path="lmem.html"><a href="lmem.html#residual-1.552-1.246"><i class="fa fa-check"></i><b>7.133</b> Residual 1.552 1.246</a></li>
<li class="chapter" data-level="7.134" data-path="lmem.html"><a href="lmem.html#number-of-obs-756-groups-participant-31"><i class="fa fa-check"></i><b>7.134</b> Number of obs: 756, groups: participant, 31</a></li>
<li class="chapter" data-level="7.135" data-path="lmem.html"><a href="lmem.html#section-275"><i class="fa fa-check"></i><b>7.135</b> </a></li>
<li class="chapter" data-level="7.136" data-path="lmem.html"><a href="lmem.html#fixed-effects-1"><i class="fa fa-check"></i><b>7.136</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.137" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-1"><i class="fa fa-check"></i><b>7.137</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.138" data-path="lmem.html"><a href="lmem.html#intercept-3.3003-0.2125-15.533"><i class="fa fa-check"></i><b>7.138</b> (Intercept) 3.3003 0.2125 15.533</a></li>
<li class="chapter" data-level="7.139" data-path="lmem.html"><a href="lmem.html#relduration-2.7249-0.7816-3.486"><i class="fa fa-check"></i><b>7.139</b> relDuration 2.7249 0.7816 3.486</a></li>
<li class="chapter" data-level="7.140" data-path="lmem.html"><a href="lmem.html#section-276"><i class="fa fa-check"></i><b>7.140</b> </a></li>
<li class="chapter" data-level="7.141" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-1"><i class="fa fa-check"></i><b>7.141</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.142" data-path="lmem.html"><a href="lmem.html#intr-1"><i class="fa fa-check"></i><b>7.142</b> (Intr)</a></li>
<li class="chapter" data-level="7.143" data-path="lmem.html"><a href="lmem.html#relduration-0.192"><i class="fa fa-check"></i><b>7.143</b> relDuration 0.192</a></li>
<li class="chapter" data-level="7.144" data-path="lmem.html"><a href="lmem.html#get-model-predictions-for-mod1c-for-each-participant"><i class="fa fa-check"></i><b>7.144</b> get model predictions for mod1c for each participant</a></li>
<li class="chapter" data-level="7.145" data-path="lmem.html"><a href="lmem.html#first-set-up-a-prediction-frame-say-from-min-to-max-values-of-relduration-in-the-data-for-each-participant"><i class="fa fa-check"></i><b>7.145</b> first, set up a prediction frame, say from min to max values of relDuration in the data, for each participant</a></li>
<li class="chapter" data-level="7.146" data-path="lmem.html"><a href="lmem.html#get-the-predicted-value-for-each-case-1"><i class="fa fa-check"></i><b>7.146</b> get the predicted value for each case</a></li>
<li class="chapter" data-level="7.147" data-path="lmem.html"><a href="lmem.html#plot-the-models-prediction-for-each-participant-1"><i class="fa fa-check"></i><b>7.147</b> plot the modelâs prediction for each participant:</a></li>
<li class="chapter" data-level="7.148" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-3-two-grouping-factors"><i class="fa fa-check"></i><b>7.148</b> Linear mixed models 3: Two grouping factors</a><ul>
<li class="chapter" data-level="7.148.1" data-path="lmem.html"><a href="lmem.html#c6model2A"><i class="fa fa-check"></i><b>7.148.1</b> Model 2A: By-participant and by-item random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="7.149" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod-2"><i class="fa fa-check"></i><b>7.149</b> Linear mixed model fit by REML [âlmerModâ]</a></li>
<li class="chapter" data-level="7.150" data-path="lmem.html"><a href="lmem.html#formula-acoustics-conditionlabel.williams-1-participant-1"><i class="fa fa-check"></i><b>7.150</b> Formula: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |</a></li>
<li class="chapter" data-level="7.151" data-path="lmem.html"><a href="lmem.html#item"><i class="fa fa-check"></i><b>7.151</b> item)</a></li>
<li class="chapter" data-level="7.152" data-path="lmem.html"><a href="lmem.html#data-givenness-2"><i class="fa fa-check"></i><b>7.152</b> Data: givenness</a></li>
<li class="chapter" data-level="7.153" data-path="lmem.html"><a href="lmem.html#section-277"><i class="fa fa-check"></i><b>7.153</b> </a></li>
<li class="chapter" data-level="7.154" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-887"><i class="fa fa-check"></i><b>7.154</b> REML criterion at convergence: 887</a></li>
<li class="chapter" data-level="7.155" data-path="lmem.html"><a href="lmem.html#section-278"><i class="fa fa-check"></i><b>7.155</b> </a></li>
<li class="chapter" data-level="7.156" data-path="lmem.html"><a href="lmem.html#scaled-residuals-2"><i class="fa fa-check"></i><b>7.156</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.157" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-24"><i class="fa fa-check"></i><b>7.157</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.158" data-path="lmem.html"><a href="lmem.html#section-279"><i class="fa fa-check"></i><b>7.158</b> -2.7608 -0.6026 -0.0187 0.6293 3.2908</a></li>
<li class="chapter" data-level="7.159" data-path="lmem.html"><a href="lmem.html#section-280"><i class="fa fa-check"></i><b>7.159</b> </a></li>
<li class="chapter" data-level="7.160" data-path="lmem.html"><a href="lmem.html#random-effects-2"><i class="fa fa-check"></i><b>7.160</b> Random effects:</a></li>
<li class="chapter" data-level="7.161" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-2"><i class="fa fa-check"></i><b>7.161</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.162" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.09266-0.3044"><i class="fa fa-check"></i><b>7.162</b> participant (Intercept) 0.09266 0.3044</a></li>
<li class="chapter" data-level="7.163" data-path="lmem.html"><a href="lmem.html#item-intercept-0.04108-0.2027"><i class="fa fa-check"></i><b>7.163</b> item (Intercept) 0.04108 0.2027</a></li>
<li class="chapter" data-level="7.164" data-path="lmem.html"><a href="lmem.html#residual-0.51732-0.7192"><i class="fa fa-check"></i><b>7.164</b> Residual 0.51732 0.7192</a></li>
<li class="chapter" data-level="7.165" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16"><i class="fa fa-check"></i><b>7.165</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.166" data-path="lmem.html"><a href="lmem.html#section-281"><i class="fa fa-check"></i><b>7.166</b> </a></li>
<li class="chapter" data-level="7.167" data-path="lmem.html"><a href="lmem.html#fixed-effects-2"><i class="fa fa-check"></i><b>7.167</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.168" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-2"><i class="fa fa-check"></i><b>7.168</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.169" data-path="lmem.html"><a href="lmem.html#intercept--0.71655-0.08585--8.347"><i class="fa fa-check"></i><b>7.169</b> (Intercept) -0.71655 0.08585 -8.347</a></li>
<li class="chapter" data-level="7.170" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.33771-0.07406-4.560"><i class="fa fa-check"></i><b>7.170</b> conditionLabel.williams 0.33771 0.07406 4.560</a></li>
<li class="chapter" data-level="7.171" data-path="lmem.html"><a href="lmem.html#section-282"><i class="fa fa-check"></i><b>7.171</b> </a></li>
<li class="chapter" data-level="7.172" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-2"><i class="fa fa-check"></i><b>7.172</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.173" data-path="lmem.html"><a href="lmem.html#intr-2"><i class="fa fa-check"></i><b>7.173</b> (Intr)</a></li>
<li class="chapter" data-level="7.174" data-path="lmem.html"><a href="lmem.html#cndtnlbl.wl-0.001"><i class="fa fa-check"></i><b>7.174</b> cndtnLbl.wl 0.001</a></li>
<li class="chapter" data-level="7.175" data-path="lmem.html"><a href="lmem.html#evaluating-lmms"><i class="fa fa-check"></i><b>7.175</b> Evaluating LMMs</a><ul>
<li class="chapter" data-level="7.175.1" data-path="lmem.html"><a href="lmem.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>7.175.1</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="7.176" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod-3"><i class="fa fa-check"></i><b>7.176</b> Linear mixed model fit by REML [âlmerModâ]</a></li>
<li class="chapter" data-level="7.177" data-path="lmem.html"><a href="lmem.html#formula-acoustics-conditionlabel.williams-1-participant-1-1"><i class="fa fa-check"></i><b>7.177</b> Formula: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |</a></li>
<li class="chapter" data-level="7.178" data-path="lmem.html"><a href="lmem.html#item-1"><i class="fa fa-check"></i><b>7.178</b> item)</a></li>
<li class="chapter" data-level="7.179" data-path="lmem.html"><a href="lmem.html#data-givenness-3"><i class="fa fa-check"></i><b>7.179</b> Data: givenness</a></li>
<li class="chapter" data-level="7.180" data-path="lmem.html"><a href="lmem.html#section-283"><i class="fa fa-check"></i><b>7.180</b> </a></li>
<li class="chapter" data-level="7.181" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-887-1"><i class="fa fa-check"></i><b>7.181</b> REML criterion at convergence: 887</a></li>
<li class="chapter" data-level="7.182" data-path="lmem.html"><a href="lmem.html#section-284"><i class="fa fa-check"></i><b>7.182</b> </a></li>
<li class="chapter" data-level="7.183" data-path="lmem.html"><a href="lmem.html#scaled-residuals-3"><i class="fa fa-check"></i><b>7.183</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.184" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-25"><i class="fa fa-check"></i><b>7.184</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.185" data-path="lmem.html"><a href="lmem.html#section-285"><i class="fa fa-check"></i><b>7.185</b> -2.7608 -0.6026 -0.0187 0.6293 3.2908</a></li>
<li class="chapter" data-level="7.186" data-path="lmem.html"><a href="lmem.html#section-286"><i class="fa fa-check"></i><b>7.186</b> </a></li>
<li class="chapter" data-level="7.187" data-path="lmem.html"><a href="lmem.html#random-effects-3"><i class="fa fa-check"></i><b>7.187</b> Random effects:</a></li>
<li class="chapter" data-level="7.188" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-3"><i class="fa fa-check"></i><b>7.188</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.189" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.09266-0.3044-1"><i class="fa fa-check"></i><b>7.189</b> participant (Intercept) 0.09266 0.3044</a></li>
<li class="chapter" data-level="7.190" data-path="lmem.html"><a href="lmem.html#item-intercept-0.04108-0.2027-1"><i class="fa fa-check"></i><b>7.190</b> item (Intercept) 0.04108 0.2027</a></li>
<li class="chapter" data-level="7.191" data-path="lmem.html"><a href="lmem.html#residual-0.51732-0.7192-1"><i class="fa fa-check"></i><b>7.191</b> Residual 0.51732 0.7192</a></li>
<li class="chapter" data-level="7.192" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16-1"><i class="fa fa-check"></i><b>7.192</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.193" data-path="lmem.html"><a href="lmem.html#section-287"><i class="fa fa-check"></i><b>7.193</b> </a></li>
<li class="chapter" data-level="7.194" data-path="lmem.html"><a href="lmem.html#fixed-effects-3"><i class="fa fa-check"></i><b>7.194</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.195" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-3"><i class="fa fa-check"></i><b>7.195</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.196" data-path="lmem.html"><a href="lmem.html#intercept--0.71655-0.08585--8.347-1"><i class="fa fa-check"></i><b>7.196</b> (Intercept) -0.71655 0.08585 -8.347</a></li>
<li class="chapter" data-level="7.197" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.33771-0.07406-4.560-1"><i class="fa fa-check"></i><b>7.197</b> conditionLabel.williams 0.33771 0.07406 4.560</a></li>
<li class="chapter" data-level="7.198" data-path="lmem.html"><a href="lmem.html#section-288"><i class="fa fa-check"></i><b>7.198</b> </a></li>
<li class="chapter" data-level="7.199" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-3"><i class="fa fa-check"></i><b>7.199</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.200" data-path="lmem.html"><a href="lmem.html#intr-3"><i class="fa fa-check"></i><b>7.200</b> (Intr)</a></li>
<li class="chapter" data-level="7.201" data-path="lmem.html"><a href="lmem.html#cndtnlbl.wl-0.001-1"><i class="fa fa-check"></i><b>7.201</b> cndtnLbl.wl 0.001</a><ul>
<li class="chapter" data-level="7.201.1" data-path="lmem.html"><a href="lmem.html#significance-of-a-random-effect-term"><i class="fa fa-check"></i><b>7.201.1</b> Significance of a random effect term</a></li>
</ul></li>
<li class="chapter" data-level="7.202" data-path="lmem.html"><a href="lmem.html#refitting-models-with-ml-instead-of-reml"><i class="fa fa-check"></i><b>7.202</b> refitting model(s) with ML (instead of REML)</a></li>
<li class="chapter" data-level="7.203" data-path="lmem.html"><a href="lmem.html#data-givenness-4"><i class="fa fa-check"></i><b>7.203</b> Data: givenness</a></li>
<li class="chapter" data-level="7.204" data-path="lmem.html"><a href="lmem.html#models"><i class="fa fa-check"></i><b>7.204</b> Models:</a></li>
<li class="chapter" data-level="7.205" data-path="lmem.html"><a href="lmem.html#mod2a.1-acoustics-conditionlabel.williams-1-participant"><i class="fa fa-check"></i><b>7.205</b> mod2a.1: acoustics ~ conditionLabel.williams + (1 | participant)</a></li>
<li class="chapter" data-level="7.206" data-path="lmem.html"><a href="lmem.html#mod2a-acoustics-conditionlabel.williams-1-participant-1"><i class="fa fa-check"></i><b>7.206</b> mod2a: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |</a></li>
<li class="chapter" data-level="7.207" data-path="lmem.html"><a href="lmem.html#mod2a-item"><i class="fa fa-check"></i><b>7.207</b> mod2a: item)</a></li>
<li class="chapter" data-level="7.208" data-path="lmem.html"><a href="lmem.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq"><i class="fa fa-check"></i><b>7.208</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="7.209" data-path="lmem.html"><a href="lmem.html#mod2a.1-4-899.07-914.86--445.54-891.07"><i class="fa fa-check"></i><b>7.209</b> mod2a.1 4 899.07 914.86 -445.54 891.07</a></li>
<li><a href="lmem.html#mod2a-5-890.58-910.31--440.29-880.58-10.49-1-0.0012-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-significance-of-fixed-effects-c6fixedp-t-statistic-1-0.04262085-likelihood-ratio-tests-refitting-models-with-ml-instead-of-reml-data-givenness-models-mod2a.1-acoustics-1-1-participant-1-item-mod2a-acoustics-conditionlabel.williams-1-participant-1-mod2a-item-df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-mod2a.1-4-908.69-924.48--450.35-900.69-mod2a-5-890.58-910.31--440.29-880.58-20.11-1-7.313e-06-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-satterthwaite-approximation-c6sattapprox-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-acoustics-conditionlabel.williams-1-participant-1-item-data-givenness-reml-criterion-at-convergence-887-scaled-residuals-min-1q-median-3q-max--2.7608--0.6026--0.0187-0.6293-3.2908-random-effects-groups-name-variance-std.dev.-participant-intercept-0.09266-0.3044-item-intercept-0.04108-0.2027-residual-0.51732-0.7192-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-df-t-value-prt-intercept--0.71655-0.08585-27.88067--8.347-4.57e-09-conditionlabel.williams-0.33771-0.07406-342.45831-4.560-7.14e-06-intercept-conditionlabel.williams-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtnlbl.wl-0.001-parametric-bootstrap-fitting-2-glmer-models-..-obtaining-1-p-values-.-mixed-model-anova-table-type-3-tests-pb-method-model-acoustics-conditionlabel.williams-1-participant-1-model-item-data-givenness-effect-df-chisq-p.value-1-conditionlabel.williams-1-20.11-.0010"><span class="toc-section-number">7.210</span> mod2a 5 890.58 910.31 -440.29 880.58 10.49 1 0.0012 <strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ### Significance of fixed effects {#c6fixedp} #### <span class="math inline">\(t\)</span>-statistic ## [1] 0.04262085 #### Likelihood ratio tests ## refitting model(s) with ML (instead of REML) ## Data: givenness ## Models: ## mod2a.1: acoustics ~ 1 + (1 | participant) + (1 | item) ## mod2a: acoustics ~ conditionLabel.williams + (1 | participant) + (1 | ## mod2a: item) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)<br />
## mod2a.1 4 908.69 924.48 -450.35 900.69<br />
## mod2a 5 890.58 910.31 -440.29 880.58 20.11 1 7.313e-06 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 #### Satterthwaite approximation {#c6sattapprox} ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |<br />
## item) ## Data: givenness ## ## REML criterion at convergence: 887 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7608 -0.6026 -0.0187 0.6293 3.2908 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.09266 0.3044<br />
## item (Intercept) 0.04108 0.2027<br />
## Residual 0.51732 0.7192<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.71655 0.08585 27.88067 -8.347 4.57e-09 ## conditionLabel.williams 0.33771 0.07406 342.45831 4.560 7.14e-06 ##<br />
## (Intercept) </em><strong> ## conditionLabel.williams </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) ## cndtnLbl.wl 0.001 #### Parametric bootstrap ## Fitting 2 (g)lmer() models: ## [..] ## Obtaining 1 p-values: ## [.] ## Mixed Model Anova Table (Type 3 tests, PB-method) ## ## Model: acoustics ~ conditionLabel.williams + (1 | participant) + (1 | ## Model: item) ## Data: givenness ## Effect df Chisq p.value ## 1 conditionLabel.williams 1 20.11 </em>** .0010</a></li>
<li class="chapter" data-level="7.211" data-path="lmem.html"><a href="lmem.html#section-289"><i class="fa fa-check"></i><b>7.211</b> â</a></li>
<li class="chapter" data-level="7.212" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-0.1-1"><i class="fa fa-check"></i><b>7.212</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â+â 0.1 ââ 1</a><ul>
<li class="chapter" data-level="7.212.1" data-path="lmem.html"><a href="lmem.html#evaluating-goodness-of-fit"><i class="fa fa-check"></i><b>7.212.1</b> Evaluating goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="7.213" data-path="lmem.html"><a href="lmem.html#section-290"><i class="fa fa-check"></i><b>7.213</b> [1] 0.03779243</a></li>
<li class="chapter" data-level="7.214" data-path="lmem.html"><a href="lmem.html#section-291"><i class="fa fa-check"></i><b>7.214</b> [1] 0.2192169</a></li>
<li class="chapter" data-level="7.215" data-path="lmem.html"><a href="lmem.html#section-292"><i class="fa fa-check"></i><b>7.215</b> [1] 0.3054109</a></li>
<li class="chapter" data-level="7.216" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-4-multiple-predictors"><i class="fa fa-check"></i><b>7.216</b> Linear mixed models 4: Multiple predictors</a><ul>
<li class="chapter" data-level="7.216.1" data-path="lmem.html"><a href="lmem.html#types-of-predictors"><i class="fa fa-check"></i><b>7.216.1</b> Types of predictors</a></li>
<li class="chapter" data-level="7.216.2" data-path="lmem.html"><a href="lmem.html#c6model3A"><i class="fa fa-check"></i><b>7.216.2</b> Model 3A: Random intercepts only</a></li>
</ul></li>
<li class="chapter" data-level="7.217" data-path="lmem.html"><a href="lmem.html#model-3a-multiple-predictors-by-item-and-by-partic-random-effects"><i class="fa fa-check"></i><b>7.217</b> Model 3A: multiple predictors, by-item and by-partic random effects</a></li>
<li class="chapter" data-level="7.218" data-path="lmem.html"><a href="lmem.html#p-values-from-lmertest"><i class="fa fa-check"></i><b>7.218</b> (p-values from lmerTest)</a></li>
<li class="chapter" data-level="7.219" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest"><i class="fa fa-check"></i><b>7.219</b> Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest]</a></li>
<li class="chapter" data-level="7.220" data-path="lmem.html"><a href="lmem.html#formula-1"><i class="fa fa-check"></i><b>7.220</b> Formula:</a></li>
<li class="chapter" data-level="7.221" data-path="lmem.html"><a href="lmem.html#acoustics-conditionlabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>7.221</b> acoustics ~ conditionLabel.williams * npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="7.222" data-path="lmem.html"><a href="lmem.html#order.std-1-participant-1-item"><i class="fa fa-check"></i><b>7.222</b> order.std + (1 | participant) + (1 | item)</a></li>
<li class="chapter" data-level="7.223" data-path="lmem.html"><a href="lmem.html#data-givenness-5"><i class="fa fa-check"></i><b>7.223</b> Data: givenness</a></li>
<li class="chapter" data-level="7.224" data-path="lmem.html"><a href="lmem.html#section-293"><i class="fa fa-check"></i><b>7.224</b> </a></li>
<li class="chapter" data-level="7.225" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-758.6"><i class="fa fa-check"></i><b>7.225</b> REML criterion at convergence: 758.6</a></li>
<li class="chapter" data-level="7.226" data-path="lmem.html"><a href="lmem.html#section-294"><i class="fa fa-check"></i><b>7.226</b> </a></li>
<li class="chapter" data-level="7.227" data-path="lmem.html"><a href="lmem.html#scaled-residuals-4"><i class="fa fa-check"></i><b>7.227</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.228" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-26"><i class="fa fa-check"></i><b>7.228</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.229" data-path="lmem.html"><a href="lmem.html#section-295"><i class="fa fa-check"></i><b>7.229</b> -2.7638 -0.6535 -0.0102 0.5750 3.5847</a></li>
<li class="chapter" data-level="7.230" data-path="lmem.html"><a href="lmem.html#section-296"><i class="fa fa-check"></i><b>7.230</b> </a></li>
<li class="chapter" data-level="7.231" data-path="lmem.html"><a href="lmem.html#random-effects-4"><i class="fa fa-check"></i><b>7.231</b> Random effects:</a></li>
<li class="chapter" data-level="7.232" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-4"><i class="fa fa-check"></i><b>7.232</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.233" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.11624-0.3409"><i class="fa fa-check"></i><b>7.233</b> participant (Intercept) 0.11624 0.3409</a></li>
<li class="chapter" data-level="7.234" data-path="lmem.html"><a href="lmem.html#item-intercept-0.03825-0.1956"><i class="fa fa-check"></i><b>7.234</b> item (Intercept) 0.03825 0.1956</a></li>
<li class="chapter" data-level="7.235" data-path="lmem.html"><a href="lmem.html#residual-0.34715-0.5892"><i class="fa fa-check"></i><b>7.235</b> Residual 0.34715 0.5892</a></li>
<li class="chapter" data-level="7.236" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16-2"><i class="fa fa-check"></i><b>7.236</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.237" data-path="lmem.html"><a href="lmem.html#section-297"><i class="fa fa-check"></i><b>7.237</b> </a></li>
<li class="chapter" data-level="7.238" data-path="lmem.html"><a href="lmem.html#fixed-effects-4"><i class="fa fa-check"></i><b>7.238</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.239" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-df-t-value"><i class="fa fa-check"></i><b>7.239</b> Estimate Std. Error df t value</a></li>
<li class="chapter" data-level="7.240" data-path="lmem.html"><a href="lmem.html#intercept--0.71517-0.08728-29.38442--8.194"><i class="fa fa-check"></i><b>7.240</b> (Intercept) -0.71517 0.08728 29.38442 -8.194</a></li>
<li class="chapter" data-level="7.241" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.32769-0.06074-338.37005-5.395"><i class="fa fa-check"></i><b>7.241</b> conditionLabel.williams 0.32769 0.06074 338.37005 5.395</a></li>
<li class="chapter" data-level="7.242" data-path="lmem.html"><a href="lmem.html#nptype.pron-0.77529-0.06072-338.22707-12.768"><i class="fa fa-check"></i><b>7.242</b> npType.pron 0.77529 0.06072 338.22707 12.768</a></li>
<li class="chapter" data-level="7.243" data-path="lmem.html"><a href="lmem.html#voice.passive-0.05087-0.11572-12.11117-0.440"><i class="fa fa-check"></i><b>7.243</b> voice.passive 0.05087 0.11572 12.11117 0.440</a></li>
<li class="chapter" data-level="7.244" data-path="lmem.html"><a href="lmem.html#order.std--0.12730-0.10819-17.79197--1.177"><i class="fa fa-check"></i><b>7.244</b> order.std -0.12730 0.10819 17.79197 -1.177</a></li>
<li class="chapter" data-level="7.245" data-path="lmem.html"><a href="lmem.html#conditionlabel.williamsnptype.pron-0.31916-0.12126-337.32828-2.632"><i class="fa fa-check"></i><b>7.245</b> conditionLabel.williams:npType.pron 0.31916 0.12126 337.32828 2.632</a></li>
<li class="chapter" data-level="7.246" data-path="lmem.html"><a href="lmem.html#prt"><i class="fa fa-check"></i><b>7.246</b> Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.247" data-path="lmem.html"><a href="lmem.html#intercept-4.45e-09-conditionlabel.williams-1.29e-07"><i class="fa fa-check"></i><b>7.247</b> (Intercept) 4.45e-09 <strong><em> ## conditionLabel.williams 1.29e-07 </em></strong></a></li>
<li><a href="lmem.html#nptype.pron-2e-16-voice.passive-0.66795-order.std-0.25483-conditionlabel.williamsnptype.pron-0.00888-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl.-nptyp.-vc.pss-ordr.s-cndtnlbl.wl-0.001-nptype.pron-0.001--0.015-voice.passv-0.009-0.005--0.023-order.std--0.004-0.015--0.032-0.107-cndtnlb.t.--0.006--0.004-0.003-0.003--0.021-call-lmformula-acoustics-conditionlabel.williams-nptype.pron"><span class="toc-section-number">7.248</span> npType.pron &lt; 2e-16 <em><strong> ## voice.passive 0.66795<br />
## order.std 0.25483<br />
## conditionLabel.williams:npType.pron 0.00888 </strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL. npTyp. vc.pss ordr.s ## cndtnLbl.wl 0.001<br />
## npType.pron 0.001 -0.015<br />
## voice.passv 0.009 0.005 -0.023<br />
## order.std -0.004 0.015 -0.032 0.107<br />
## cndtnLb.:T. -0.006 -0.004 0.003 0.003 -0.021 ## ## Call: ## lm(formula = acoustics ~ conditionLabel.williams </em> npType.pron +</a></li>
<li class="chapter" data-level="7.249" data-path="lmem.html"><a href="lmem.html#voice.passive-order.std-data-givenness"><i class="fa fa-check"></i><b>7.249</b> voice.passive + order.std, data = givenness)</a></li>
<li class="chapter" data-level="7.250" data-path="lmem.html"><a href="lmem.html#section-298"><i class="fa fa-check"></i><b>7.250</b> </a></li>
<li class="chapter" data-level="7.251" data-path="lmem.html"><a href="lmem.html#residuals-18"><i class="fa fa-check"></i><b>7.251</b> Residuals:</a></li>
<li class="chapter" data-level="7.252" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-27"><i class="fa fa-check"></i><b>7.252</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.253" data-path="lmem.html"><a href="lmem.html#section-299"><i class="fa fa-check"></i><b>7.253</b> -1.94657 -0.49206 0.00032 0.46756 2.31921</a></li>
<li class="chapter" data-level="7.254" data-path="lmem.html"><a href="lmem.html#section-300"><i class="fa fa-check"></i><b>7.254</b> </a></li>
<li class="chapter" data-level="7.255" data-path="lmem.html"><a href="lmem.html#coefficients-20"><i class="fa fa-check"></i><b>7.255</b> Coefficients:</a></li>
<li class="chapter" data-level="7.256" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-prt-17"><i class="fa fa-check"></i><b>7.256</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.257" data-path="lmem.html"><a href="lmem.html#intercept--0.72335-0.03582--20.193-2e-16"><i class="fa fa-check"></i><b>7.257</b> (Intercept) -0.72335 0.03582 -20.193 &lt; 2e-16</a></li>
<li class="chapter" data-level="7.258" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.30626-0.07169-4.272-2.46e-05"><i class="fa fa-check"></i><b>7.258</b> conditionLabel.williams 0.30626 0.07169 4.272 2.46e-05</a></li>
<li class="chapter" data-level="7.259" data-path="lmem.html"><a href="lmem.html#nptype.pron-0.75743-0.07171-10.563-2e-16"><i class="fa fa-check"></i><b>7.259</b> npType.pron 0.75743 0.07171 10.563 &lt; 2e-16</a></li>
<li class="chapter" data-level="7.260" data-path="lmem.html"><a href="lmem.html#voice.passive-0.05866-0.07203-0.814-0.4159"><i class="fa fa-check"></i><b>7.260</b> voice.passive 0.05866 0.07203 0.814 0.4159</a></li>
<li class="chapter" data-level="7.261" data-path="lmem.html"><a href="lmem.html#order.std--0.19556-0.07211--2.712-0.0070"><i class="fa fa-check"></i><b>7.261</b> order.std -0.19556 0.07211 -2.712 0.0070</a></li>
<li class="chapter" data-level="7.262" data-path="lmem.html"><a href="lmem.html#conditionlabel.williamsnptype.pron-0.31954-0.14346-2.227-0.0265"><i class="fa fa-check"></i><b>7.262</b> conditionLabel.williams:npType.pron 0.31954 0.14346 2.227 0.0265</a></li>
<li class="chapter" data-level="7.263" data-path="lmem.html"><a href="lmem.html#section-301"><i class="fa fa-check"></i><b>7.263</b> </a></li>
<li class="chapter" data-level="7.264" data-path="lmem.html"><a href="lmem.html#intercept-conditionlabel.williams"><i class="fa fa-check"></i><b>7.264</b> (Intercept) <strong><em> ## conditionLabel.williams </em></strong></a></li>
<li><a href="lmem.html#nptype.pron-voice.passive-order.std-conditionlabel.williamsnptype.pron"><span class="toc-section-number">7.265</span> npType.pron <em><strong> ## voice.passive<br />
## order.std </strong> ## conditionLabel.williams:npType.pron </em></a></li>
<li class="chapter" data-level="7.266" data-path="lmem.html"><a href="lmem.html#section-302"><i class="fa fa-check"></i><b>7.266</b> â</a></li>
<li class="chapter" data-level="7.267" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-20"><i class="fa fa-check"></i><b>7.267</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="7.268" data-path="lmem.html"><a href="lmem.html#section-303"><i class="fa fa-check"></i><b>7.268</b> </a></li>
<li class="chapter" data-level="7.269" data-path="lmem.html"><a href="lmem.html#residual-standard-error-0.7-on-376-degrees-of-freedom"><i class="fa fa-check"></i><b>7.269</b> Residual standard error: 0.7 on 376 degrees of freedom</a></li>
<li class="chapter" data-level="7.270" data-path="lmem.html"><a href="lmem.html#multiple-r-squared-0.2768-adjusted-r-squared-0.2672"><i class="fa fa-check"></i><b>7.270</b> Multiple R-squared: 0.2768, Adjusted R-squared: 0.2672</a></li>
<li class="chapter" data-level="7.271" data-path="lmem.html"><a href="lmem.html#f-statistic-28.78-on-5-and-376-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>7.271</b> F-statistic: 28.78 on 5 and 376 DF, p-value: &lt; 2.2e-16</a><ul>
<li class="chapter" data-level="7.271.1" data-path="lmem.html"><a href="lmem.html#c6model3B"><i class="fa fa-check"></i><b>7.271.1</b> Model 3B: Random intercepts and all possible random slopes</a></li>
</ul></li>
<li class="chapter" data-level="7.272" data-path="lmem.html"><a href="lmem.html#model-3b"><i class="fa fa-check"></i><b>7.272</b> Model 3B</a></li>
<li class="chapter" data-level="7.273" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-1"><i class="fa fa-check"></i><b>7.273</b> Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest]</a></li>
<li class="chapter" data-level="7.274" data-path="lmem.html"><a href="lmem.html#formula-2"><i class="fa fa-check"></i><b>7.274</b> Formula:</a></li>
<li class="chapter" data-level="7.275" data-path="lmem.html"><a href="lmem.html#acoustics-conditionlabel.williams-nptype.pron-voice.passive-1"><i class="fa fa-check"></i><b>7.275</b> acoustics ~ conditionLabel.williams * npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="7.276" data-path="lmem.html"><a href="lmem.html#order.std-1-conditionlabel.williams-nptype.pron"><i class="fa fa-check"></i><b>7.276</b> order.std + (1 + conditionLabel.williams * npType.pron +</a></li>
<li><a href="lmem.html#voice.passive-participant-1-conditionlabel.williams-nptype.pron-item"><span class="toc-section-number">7.277</span> voice.passive || participant) + (1 + conditionLabel.williams *<br />
## npType.pron || item)</a></li>
<li class="chapter" data-level="7.278" data-path="lmem.html"><a href="lmem.html#data-givenness-6"><i class="fa fa-check"></i><b>7.278</b> Data: givenness</a></li>
<li class="chapter" data-level="7.279" data-path="lmem.html"><a href="lmem.html#section-304"><i class="fa fa-check"></i><b>7.279</b> </a></li>
<li class="chapter" data-level="7.280" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-722.6"><i class="fa fa-check"></i><b>7.280</b> REML criterion at convergence: 722.6</a></li>
<li class="chapter" data-level="7.281" data-path="lmem.html"><a href="lmem.html#section-305"><i class="fa fa-check"></i><b>7.281</b> </a></li>
<li class="chapter" data-level="7.282" data-path="lmem.html"><a href="lmem.html#scaled-residuals-5"><i class="fa fa-check"></i><b>7.282</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.283" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-28"><i class="fa fa-check"></i><b>7.283</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.284" data-path="lmem.html"><a href="lmem.html#section-306"><i class="fa fa-check"></i><b>7.284</b> -2.97005 -0.61342 -0.00089 0.55381 2.98506</a></li>
<li class="chapter" data-level="7.285" data-path="lmem.html"><a href="lmem.html#section-307"><i class="fa fa-check"></i><b>7.285</b> </a></li>
<li class="chapter" data-level="7.286" data-path="lmem.html"><a href="lmem.html#random-effects-5"><i class="fa fa-check"></i><b>7.286</b> Random effects:</a></li>
<li class="chapter" data-level="7.287" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-5"><i class="fa fa-check"></i><b>7.287</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.288" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.11589-0.3404"><i class="fa fa-check"></i><b>7.288</b> participant (Intercept) 0.11589 0.3404</a></li>
<li class="chapter" data-level="7.289" data-path="lmem.html"><a href="lmem.html#participant.1-conditionlabel.williams-0.01278-0.1131"><i class="fa fa-check"></i><b>7.289</b> participant.1 conditionLabel.williams 0.01278 0.1131</a></li>
<li class="chapter" data-level="7.290" data-path="lmem.html"><a href="lmem.html#participant.2-nptype.pron-0.01298-0.1139"><i class="fa fa-check"></i><b>7.290</b> participant.2 npType.pron 0.01298 0.1139</a></li>
<li class="chapter" data-level="7.291" data-path="lmem.html"><a href="lmem.html#participant.3-voice.passive-0.08281-0.2878"><i class="fa fa-check"></i><b>7.291</b> participant.3 voice.passive 0.08281 0.2878</a></li>
<li class="chapter" data-level="7.292" data-path="lmem.html"><a href="lmem.html#participant.4-conditionlabel.williamsnptype.pron-0.03131-0.1770"><i class="fa fa-check"></i><b>7.292</b> participant.4 conditionLabel.williams:npType.pron 0.03131 0.1770</a></li>
<li class="chapter" data-level="7.293" data-path="lmem.html"><a href="lmem.html#item-intercept-0.04089-0.2022"><i class="fa fa-check"></i><b>7.293</b> item (Intercept) 0.04089 0.2022</a></li>
<li class="chapter" data-level="7.294" data-path="lmem.html"><a href="lmem.html#item.1-conditionlabel.williams-0.00000-0.0000"><i class="fa fa-check"></i><b>7.294</b> item.1 conditionLabel.williams 0.00000 0.0000</a></li>
<li class="chapter" data-level="7.295" data-path="lmem.html"><a href="lmem.html#item.2-nptype.pron-0.20854-0.4567"><i class="fa fa-check"></i><b>7.295</b> item.2 npType.pron 0.20854 0.4567</a></li>
<li class="chapter" data-level="7.296" data-path="lmem.html"><a href="lmem.html#item.3-conditionlabel.williamsnptype.pron-0.00000-0.0000"><i class="fa fa-check"></i><b>7.296</b> item.3 conditionLabel.williams:npType.pron 0.00000 0.0000</a></li>
<li class="chapter" data-level="7.297" data-path="lmem.html"><a href="lmem.html#residual-0.26762-0.5173"><i class="fa fa-check"></i><b>7.297</b> Residual 0.26762 0.5173</a></li>
<li class="chapter" data-level="7.298" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16-3"><i class="fa fa-check"></i><b>7.298</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.299" data-path="lmem.html"><a href="lmem.html#section-308"><i class="fa fa-check"></i><b>7.299</b> </a></li>
<li class="chapter" data-level="7.300" data-path="lmem.html"><a href="lmem.html#fixed-effects-5"><i class="fa fa-check"></i><b>7.300</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.301" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-df-t-value-1"><i class="fa fa-check"></i><b>7.301</b> Estimate Std. Error df t value</a></li>
<li class="chapter" data-level="7.302" data-path="lmem.html"><a href="lmem.html#intercept--0.71909-0.08702-29.69336--8.263"><i class="fa fa-check"></i><b>7.302</b> (Intercept) -0.71909 0.08702 29.69336 -8.263</a></li>
<li class="chapter" data-level="7.303" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.30897-0.05894-19.87033-5.242"><i class="fa fa-check"></i><b>7.303</b> conditionLabel.williams 0.30897 0.05894 19.87033 5.242</a></li>
<li class="chapter" data-level="7.304" data-path="lmem.html"><a href="lmem.html#nptype.pron-0.78377-0.12831-15.26567-6.108"><i class="fa fa-check"></i><b>7.304</b> npType.pron 0.78377 0.12831 15.26567 6.108</a></li>
<li class="chapter" data-level="7.305" data-path="lmem.html"><a href="lmem.html#voice.passive-0.06037-0.12802-16.52472-0.472"><i class="fa fa-check"></i><b>7.305</b> voice.passive 0.06037 0.12802 16.52472 0.472</a></li>
<li class="chapter" data-level="7.306" data-path="lmem.html"><a href="lmem.html#order.std--0.12414-0.10625-18.30847--1.168"><i class="fa fa-check"></i><b>7.306</b> order.std -0.12414 0.10625 18.30847 -1.168</a></li>
<li class="chapter" data-level="7.307" data-path="lmem.html"><a href="lmem.html#conditionlabel.williamsnptype.pron-0.31522-0.11341-21.95021-2.780"><i class="fa fa-check"></i><b>7.307</b> conditionLabel.williams:npType.pron 0.31522 0.11341 21.95021 2.780</a></li>
<li class="chapter" data-level="7.308" data-path="lmem.html"><a href="lmem.html#prt-1"><i class="fa fa-check"></i><b>7.308</b> Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.309" data-path="lmem.html"><a href="lmem.html#intercept-3.45e-09-conditionlabel.williams-4.03e-05"><i class="fa fa-check"></i><b>7.309</b> (Intercept) 3.45e-09 <strong><em> ## conditionLabel.williams 4.03e-05 </em></strong></a></li>
<li><a href="lmem.html#nptype.pron-1.85e-05-voice.passive-0.6434-order.std-0.2576-conditionlabel.williamsnptype.pron-0.0109-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl.-nptyp.-vc.pss-ordr.s-cndtnlbl.wl-0.002-nptype.pron-0.000--0.005-voice.passv-0.008-0.004--0.009-order.std--0.004-0.019--0.013-0.097-cndtnlb.t.--0.005-0.001-0.002-0.003--0.019-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-acoustics-conditionlabel.williams-nptype.pron-voice.passive-order.std-1-participant-1-item-data-givenness-reml-criterion-at-convergence-758.6-scaled-residuals-min-1q-median-3q-max--2.7638--0.6535--0.0102-0.5750-3.5847-random-effects-groups-name-variance-std.dev.-participant-intercept-0.11624-0.3409-item-intercept-0.03825-0.1956-residual-0.34715-0.5892-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-df-t-value-intercept--0.71517-0.08728-29.38442--8.194-conditionlabel.williams-0.32769-0.06074-338.37005-5.395-nptype.pron-0.77529-0.06072-338.22707-12.768-voice.passive-0.05087-0.11572-12.11117-0.440-order.std--0.12730-0.10819-17.79197--1.177-conditionlabel.williamsnptype.pron-0.31916-0.12126-337.32828-2.632-prt-intercept-4.45e-09-conditionlabel.williams-1.29e-07-nptype.pron-2e-16-voice.passive-0.66795-order.std-0.25483-conditionlabel.williamsnptype.pron-0.00888-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl.-nptyp.-vc.pss-ordr.s-cndtnlbl.wl-0.001-nptype.pron-0.001--0.015-voice.passv-0.009-0.005--0.023-order.std--0.004-0.015--0.032-0.107-cndtnlb.t.--0.006--0.004-0.003-0.003--0.021-assessing-variability-model-comparisons-to-check-whether-conditionlabel.williams-variability-by-participant-refitting-models-with-ml-instead-of-reml-data-givenness-models-mod3b.no.partic.slope-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b.no.partic.slope-order.std-1-participant-0-nptype.pron-participant-mod3b.no.partic.slope-0-voice.passive-participant-0-conditionlabel.williamsnptype.pron-mod3b.no.partic.slope-participant-1-item-0-conditionlabel.williams-mod3b.no.partic.slope-item-0-nptype.pron-item-0-conditionlabel.williamsnptype.pron-mod3b.no.partic.slope-item-conditionlabel.williamsnptype.pron-mod3b-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b-order.std-1-conditionlabel.williams-nptype.pron-mod3b-voice.passive-participant-1-conditionlabel.williams-mod3b-nptype.pron-item-df-aic-bic-loglik-deviance-chisq-chi-df-mod3b.no.partic.slope-15-735.9-795.08--352.95-705.9-mod3b-16-737.8-800.92--352.90-705.8-0.0993-1-prchisq-mod3b.no.partic.slope-mod3b-0.7527-by-item-refitting-models-with-ml-instead-of-reml-data-givenness-models-mod3b.no.item.slope-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b.no.item.slope-order.std-1-participant-0-conditionlabel.williams-mod3b.no.item.slope-participant-0-nptype.pron-participant-0-voice.passive-mod3b.no.item.slope-participant-0-conditionlabel.williamsnptype.pron-mod3b.no.item.slope-participant-1-item-0-nptype.pron-item-0-mod3b.no.item.slope-conditionlabel.williamsnptype.pron-item-conditionlabel.williamsnptype.pron-mod3b-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b-order.std-1-conditionlabel.williams-nptype.pron-mod3b-voice.passive-participant-1-conditionlabel.williams-mod3b-nptype.pron-item-df-aic-bic-loglik-deviance-chisq-chi-df-mod3b.no.item.slope-15-735.8-794.98--352.9-705.8-mod3b-16-737.8-800.92--352.9-705.8-0-1-prchisq-mod3b.no.item.slope-mod3b-1-examine-distibution-of-participant-clabel.wiliams-coefficents-fixed-effect-for-conditionlabel-each-participants-offset-more-on-random-slopes-what-does-adding-a-random-slope-term-do-model-1d-half-rhyme-data-model-of-1-var-with-by-partic-random-intercept-only-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-relduration-1-participant-data-halfrhyme-reml-criterion-at-convergence-2580-scaled-residuals-min-1q-median-3q-max--2.4624--0.6545--0.1025-0.6348-3.6438-random-effects-groups-name-variance-std.dev.-participant-intercept-1.222-1.106-residual-1.575-1.255-number-of-obs-756-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.2918-0.2088-33.0815-15.765-2e-16"><span class="toc-section-number">7.310</span> npType.pron 1.85e-05 <strong><em> ## voice.passive 0.6434<br />
## order.std 0.2576<br />
## conditionLabel.williams:npType.pron 0.0109 </em><br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL. npTyp. vc.pss ordr.s ## cndtnLbl.wl 0.002<br />
## npType.pron 0.000 -0.005<br />
## voice.passv 0.008 0.004 -0.009<br />
## order.std -0.004 0.019 -0.013 0.097<br />
## cndtnLb.:T. -0.005 0.001 0.002 0.003 -0.019 ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: ## acoustics ~ conditionLabel.williams * npType.pron + voice.passive +<br />
## order.std + (1 | participant) + (1 | item) ## Data: givenness ## ## REML criterion at convergence: 758.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7638 -0.6535 -0.0102 0.5750 3.5847 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.11624 0.3409<br />
## item (Intercept) 0.03825 0.1956<br />
## Residual 0.34715 0.5892<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error df t value ## (Intercept) -0.71517 0.08728 29.38442 -8.194 ## conditionLabel.williams 0.32769 0.06074 338.37005 5.395 ## npType.pron 0.77529 0.06072 338.22707 12.768 ## voice.passive 0.05087 0.11572 12.11117 0.440 ## order.std -0.12730 0.10819 17.79197 -1.177 ## conditionLabel.williams:npType.pron 0.31916 0.12126 337.32828 2.632 ## Pr(&gt;|t|)<br />
## (Intercept) 4.45e-09 </strong><em> ## conditionLabel.williams 1.29e-07 </em><strong> ## npType.pron &lt; 2e-16 </strong><em> ## voice.passive 0.66795<br />
## order.std 0.25483<br />
## conditionLabel.williams:npType.pron 0.00888 <strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL. npTyp. vc.pss ordr.s ## cndtnLbl.wl 0.001<br />
## npType.pron 0.001 -0.015<br />
## voice.passv 0.009 0.005 -0.023<br />
## order.std -0.004 0.015 -0.032 0.107<br />
## cndtnLb.:T. -0.006 -0.004 0.003 0.003 -0.021 ### Assessing variability ## model comparisons to check whether conditionLabel.williams variability ## by-participant ## refitting model(s) with ML (instead of REML) ## Data: givenness ## Models: ## mod3b.no.partic.slope: acoustics ~ conditionLabel.williams + npType.pron + voice.passive + ## mod3b.no.partic.slope: order.std + (1 | participant) + (0 + npType.pron | participant) + ## mod3b.no.partic.slope: (0 + voice.passive | participant) + (0 + conditionLabel.williams:npType.pron | ## mod3b.no.partic.slope: participant) + (1 | item) + (0 + conditionLabel.williams | ## mod3b.no.partic.slope: item) + (0 + npType.pron | item) + (0 + conditionLabel.williams:npType.pron | ## mod3b.no.partic.slope: item) + conditionLabel.williams:npType.pron ## mod3b: acoustics ~ conditionLabel.williams * npType.pron + voice.passive + ## mod3b: order.std + (1 + conditionLabel.williams * npType.pron + ## mod3b: voice.passive || participant) + (1 + conditionLabel.williams * ## mod3b: npType.pron || item) ## Df AIC BIC logLik deviance Chisq Chi Df ## mod3b.no.partic.slope 15 735.9 795.08 -352.95 705.9<br />
## mod3b 16 737.8 800.92 -352.90 705.8 0.0993 1 ## Pr(&gt;Chisq) ## mod3b.no.partic.slope<br />
## mod3b 0.7527 ## by-item ## refitting model(s) with ML (instead of REML) ## Data: givenness ## Models: ## mod3b.no.item.slope: acoustics ~ conditionLabel.williams + npType.pron + voice.passive + ## mod3b.no.item.slope: order.std + (1 | participant) + (0 + conditionLabel.williams | ## mod3b.no.item.slope: participant) + (0 + npType.pron | participant) + (0 + voice.passive | ## mod3b.no.item.slope: participant) + (0 + conditionLabel.williams:npType.pron | ## mod3b.no.item.slope: participant) + (1 | item) + (0 + npType.pron | item) + (0 + ## mod3b.no.item.slope: conditionLabel.williams:npType.pron | item) + conditionLabel.williams:npType.pron ## mod3b: acoustics ~ conditionLabel.williams * npType.pron + voice.passive + ## mod3b: order.std + (1 + conditionLabel.williams * npType.pron + ## mod3b: voice.passive || participant) + (1 + conditionLabel.williams * ## mod3b: npType.pron || item) ## Df AIC BIC logLik deviance Chisq Chi Df ## mod3b.no.item.slope 15 735.8 794.98 -352.9 705.8<br />
## mod3b 16 737.8 800.92 -352.9 705.8 0 1 ## Pr(&gt;Chisq) ## mod3b.no.item.slope<br />
## mod3b 1 ## examine distibution of participant clabel.wiliams coefficents: ## fixed effect for conditionLabel ## each participantâs offset ## More on random slopes ### What does adding a random slope term do? ## Model 1D: half-rhyme data model of 1 var, with by-partic random intercept only ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ relDuration + (1 | participant) ## Data: halfrhyme ## ## REML criterion at convergence: 2580 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4624 -0.6545 -0.1025 0.6348 3.6438 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 1.222 1.106<br />
## Residual 1.575 1.255<br />
## Number of obs: 756, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.2918 0.2088 33.0815 15.765 &lt; 2e-16 </strong></em></a></li>
<li><a href="lmem.html#relduration-2.6600-0.6703-728.5548-3.968-7.96e-05-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-relduration-0.219-linear-mixed-model-fit-by-reml-lmermod-formula-rhymerating-relduration-1-participant-0-relduration-participant-data-halfrhyme-reml-criterion-at-convergence-2578.7-scaled-residuals-min-1q-median-3q-max--2.4022--0.6091--0.1126-0.6138-3.5726-random-effects-groups-name-variance-std.dev.-participant-intercept-1.267-1.126-participant.1-relduration-4.482-2.117-residual-1.552-1.246-number-of-obs-756-groups-participant-31-fixed-effects-estimate-std.-error-t-value-intercept-3.3003-0.2125-15.533-relduration-2.7249-0.7816-3.486-correlation-of-fixed-effects-intr-relduration-0.192-discussion-adding-a-random-slope-adding-a-random-slope-extended-exercise-lmm-with-random-slopes---random-effect-correlations-random-effect-correlations-model-predictions-by-subject-for-model-1c-get-the-predicted-value-for-each-case-plot-the-models-prediction-for-each-participant-model-1e-correlated-random-slope-intercept-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-relduration-1-relduration-participant-data-halfrhyme-reml-criterion-at-convergence-2571.9-scaled-residuals-min-1q-median-3q-max--2.4723--0.6129--0.1562-0.5897-3.4874-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-1.496-1.223-relduration-5.728-2.393-0.82-residual-1.548-1.244-number-of-obs-756-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.3068-0.2291-30.4810-14.433-3.62e-15"><span class="toc-section-number">7.311</span> relDuration 2.6600 0.6703 728.5548 3.968 7.96e-05 <em><strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) ## relDuration 0.219 ## Linear mixed model fit by REML [âlmerModâ] ## Formula: ## rhymeRating ~ relDuration + ((1 | participant) + (0 + relDuration |<br />
## participant)) ## Data: halfrhyme ## ## REML criterion at convergence: 2578.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4022 -0.6091 -0.1126 0.6138 3.5726 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 1.267 1.126<br />
## participant.1 relDuration 4.482 2.117<br />
## Residual 1.552 1.246<br />
## Number of obs: 756, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 3.3003 0.2125 15.533 ## relDuration 2.7249 0.7816 3.486 ## ## Correlation of Fixed Effects: ## (Intr) ## relDuration 0.192 ### Discussion: Adding a random slope {#adding-a-random-slope} #### Extended exercise: LMM with random slopes {-} ## Random effect correlations {#random-effect-correlations} ## model predictions by-subject for Model 1C: ## get the predicted value for each case ## plot the modelâs prediction for each participant: ### Model 1E: </strong>Correlated<strong> random slope &amp; intercept ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ relDuration + (1 + relDuration | participant) ## Data: halfrhyme ## ## REML criterion at convergence: 2571.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4723 -0.6129 -0.1562 0.5897 3.4874 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## participant (Intercept) 1.496 1.223<br />
## relDuration 5.728 2.393 0.82 ## Residual 1.548 1.244<br />
## Number of obs: 756, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.3068 0.2291 30.4810 14.433 3.62e-15 </strong></em></a></li>
<li class="chapter" data-level="7.312" data-path="lmem.html"><a href="lmem.html#relduration-2.8161-0.8017-24.8569-3.513-0.00172"><i class="fa fa-check"></i><b>7.312</b> relDuration 2.8161 0.8017 24.8569 3.513 0.00172 **</a></li>
<li class="chapter" data-level="7.313" data-path="lmem.html"><a href="lmem.html#section-309"><i class="fa fa-check"></i><b>7.313</b> â</a></li>
<li class="chapter" data-level="7.314" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-21"><i class="fa fa-check"></i><b>7.314</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="7.315" data-path="lmem.html"><a href="lmem.html#section-310"><i class="fa fa-check"></i><b>7.315</b> </a></li>
<li class="chapter" data-level="7.316" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-4"><i class="fa fa-check"></i><b>7.316</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.317" data-path="lmem.html"><a href="lmem.html#intr-4"><i class="fa fa-check"></i><b>7.317</b> (Intr)</a></li>
<li class="chapter" data-level="7.318" data-path="lmem.html"><a href="lmem.html#relduration-0.591"><i class="fa fa-check"></i><b>7.318</b> relDuration 0.591</a></li>
<li class="chapter" data-level="7.319" data-path="lmem.html"><a href="lmem.html#refitting-models-with-ml-instead-of-reml-1"><i class="fa fa-check"></i><b>7.319</b> refitting model(s) with ML (instead of REML)</a></li>
<li class="chapter" data-level="7.320" data-path="lmem.html"><a href="lmem.html#data-halfrhyme-1"><i class="fa fa-check"></i><b>7.320</b> Data: halfrhyme</a></li>
<li class="chapter" data-level="7.321" data-path="lmem.html"><a href="lmem.html#models-1"><i class="fa fa-check"></i><b>7.321</b> Models:</a></li>
<li class="chapter" data-level="7.322" data-path="lmem.html"><a href="lmem.html#mod1c-rhymerating-relduration-1-participant-0-relduration"><i class="fa fa-check"></i><b>7.322</b> mod1c: rhymeRating ~ relDuration + ((1 | participant) + (0 + relDuration |</a></li>
<li class="chapter" data-level="7.323" data-path="lmem.html"><a href="lmem.html#mod1c-participant"><i class="fa fa-check"></i><b>7.323</b> mod1c: participant))</a></li>
<li class="chapter" data-level="7.324" data-path="lmem.html"><a href="lmem.html#mod1e-rhymerating-relduration-1-relduration-participant"><i class="fa fa-check"></i><b>7.324</b> mod1e: rhymeRating ~ relDuration + (1 + relDuration | participant)</a></li>
<li class="chapter" data-level="7.325" data-path="lmem.html"><a href="lmem.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-1"><i class="fa fa-check"></i><b>7.325</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="7.326" data-path="lmem.html"><a href="lmem.html#mod1c-5-2588.7-2611.8--1289.3-2578.7"><i class="fa fa-check"></i><b>7.326</b> mod1c 5 2588.7 2611.8 -1289.3 2578.7</a></li>
<li><a href="lmem.html#mod1e-6-2583.7-2611.5--1285.8-2571.7-6.9728-1-0.008276-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-model-1c-no-correlation-estimate-std.-error-t-value-intercept-3.300261-0.2124740-15.532541-relduration-2.724922-0.7816163-3.486265-model-1e-correlation-estimate-std.-error-df-t-value-prt-intercept-3.306768-0.2291117-30.48098-14.432996-3.624195e-15-relduration-2.816111-0.8016868-24.85693-3.512732-1.720269e-03-dicussion-adding-a-correlation-c6discuss-model-criticism-for-linear-mixed-models-model-3b-residual-plots-qq-plot-for-model-3b-model-3b-random-effect-distribution-make-partiicpant-means-plot-random-slopes-for-factors-c6factorsissue-model-with-random-effect-correlations-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-conditionlabel-1-conditionlabel-participant-data-halfrhyme-reml-criterion-at-convergence-3826.5-scaled-residuals-min-1q-median-3q-max--4.6442--0.4262--0.0567-0.5333-3.8688-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-0.26067-0.5106-conditionlabel1-0.20112-0.4485-0.91-conditionlabel2-0.05675-0.2382--0.73--0.55-residual-1.25335-1.1195-number-of-obs-1205-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.63504-0.09918-30.04544-36.652-2e-16-conditionlabel1-0.89985-0.09086-29.89488-9.904-5.94e-11-conditionlabel2-1.42441-0.05166-30.13975-27.573-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl1-conditnlbl1-0.677-conditnlbl2--0.511--0.335-models-without-random-effect-correlations-lmem-mwrec-warning-in-checkconvattropt-derivs-optpar-ctrl-controlcheckconv-model-is-nearly-unidentifiable-large-eigenvalue-ratio---rescale-variables-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-conditionlabel-1-conditionlabel-participant-data-halfrhyme-reml-criterion-at-convergence-3826.5-scaled-residuals-min-1q-median-3q-max--4.6442--0.4262--0.0567-0.5333-3.8688-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-8.833e-05-0.009398-participant.1-conditionlabelbad-1.623e-01-0.402815-conditionlabelvoice-1.230e00-1.109149-0.66-conditionlabelgood-1.320e-01-0.363301--0.23-0.37-residual-1.253e00-1.119530-number-of-obs-1205-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.63504-0.09918-30.04544-36.652-2e-16-conditionlabel1-0.89985-0.09086-29.89489-9.904-5.94e-11-conditionlabel2-1.42441-0.05166-30.13975-27.573-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl1-conditnlbl1-0.677-conditnlbl2--0.511--0.335-convergence-code-0-model-is-nearly-unidentifiable-large-eigenvalue-ratio---rescale-variables-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-conditionlabel-1-clabel.c1-clabel.c2-participant-data-halfrhyme-reml-criterion-at-convergence-3860-scaled-residuals-min-1q-median-3q-max--4.2957--0.5188--0.0262-0.5393-3.8347-random-effects-groups-name-variance-std.dev.-participant-intercept-0.30396-0.5513-participant.1-clabel.c1-0.23903-0.4889-participant.2-clabel.c2-0.06519-0.2553-residual-1.24808-1.1172-number-of-obs-1205-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.63410-0.10596-30.02772-34.297-2e-16-conditionlabel1-0.90151-0.09733-30.01033-9.262-2.63e-10-conditionlabel2-1.42488-0.05420-30.28367-26.289-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl1-conditnlbl1--0.061-conditnlbl2-0.043-0.059-other-readings-appendix-extra-examples-c6extraexamples-predicting-confidence-intervals-by-simulation-lmm-simulation-confint-a-simple-recipe-for-simulating-95-confidence-intervals-over-model-predictions-set-up-dataframe-to-predict-for-every-participant-every-value-of-the-predictor-simulate-10k-times-from-the-model-for-newdata-lower-and-upper-95-cis-newdata-now-contains-lower-and-upper-bounds-of-95-ci-with-prediction-median-from-simulations-random-intercept-and-slope-model-for-givenness-data-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-acoustics-conditionlabel.williams-1-conditionlabel.williams-participant-data-givenness-reml-criterion-at-convergence-897.9-scaled-residuals-min-1q-median-3q-max--3.0538--0.7129-0.0083-0.6540-3.3136-random-effects-groups-name-variance-std.dev.-participant-intercept-0.08937-0.299-participant.1-conditionlabel.williams-0.00000-0.000-residual-0.55800-0.747-number-of-obs-382-groups-participant-27-fixed-effects-estimate-std.-error-df-t-value-prt-intercept--0.71856-0.06916-26.21655--10.39-8.66e-11-conditionlabel.williams-0.32626-0.07677-356.75848-4.25-2.73e-05-intercept-conditionlabel.williams-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtnlbl.wl-0.002-appendix-extended-exercise-c6extendedexercise-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-vowelduration-syntax.trans-speechrate.slow-1-syntax.trans-speechrate.slow-item-1-syntax.trans-speechrate.slow"><span class="toc-section-number">7.327</span> mod1e 6 2583.7 2611.5 -1285.8 2571.7 6.9728 1 0.008276 <strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## model 1C (no correlation) ## Estimate Std. Error t value ## (Intercept) 3.300261 0.2124740 15.532541 ## relDuration 2.724922 0.7816163 3.486265 ## model 1E (correlation) ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 3.306768 0.2291117 30.48098 14.432996 3.624195e-15 ## relDuration 2.816111 0.8016868 24.85693 3.512732 1.720269e-03 ### Dicussion: Adding a correlation {#c6discuss} ## Model criticism for linear mixed models ### Model 3B: Residual plots ## QQ plot for Model 3B ### Model 3B: Random effect distribution ## make partiicpant means plot ## Random slopes for factors {#c6factorsissue} ### Model with random-effect correlations ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ conditionLabel + (1 + conditionLabel | participant) ## Data: halfrhyme ## ## REML criterion at convergence: 3826.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.6442 -0.4262 -0.0567 0.5333 3.8688 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 0.26067 0.5106<br />
## conditionLabel1 0.20112 0.4485 0.91<br />
## conditionLabel2 0.05675 0.2382 -0.73 -0.55 ## Residual 1.25335 1.1195<br />
## Number of obs: 1205, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.63504 0.09918 30.04544 36.652 &lt; 2e-16 </strong><em> ## conditionLabel1 0.89985 0.09086 29.89488 9.904 5.94e-11 </em><strong> ## conditionLabel2 1.42441 0.05166 30.13975 27.573 &lt; 2e-16 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL1 ## conditnLbl1 0.677<br />
## conditnLbl2 -0.511 -0.335 ### Models without random-effect correlations {#lmem-mwrec} ## Warning in checkConv(attr(opt, âderivsâ), opt<span class="math inline">\(par, ctrl = control\)</span>checkConv, : Model is nearly unidentifiable: large eigenvalue ratio ## - Rescale variables? ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: ## rhymeRating ~ conditionLabel + (1 + conditionLabel || participant) ## Data: halfrhyme ## ## REML criterion at convergence: 3826.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.6442 -0.4262 -0.0567 0.5333 3.8688 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 8.833e-05 0.009398<br />
## participant.1 conditionLabelbad 1.623e-01 0.402815<br />
## conditionLabelvoice 1.230e+00 1.109149 0.66<br />
## conditionLabelgood 1.320e-01 0.363301 -0.23 0.37 ## Residual 1.253e+00 1.119530<br />
## Number of obs: 1205, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.63504 0.09918 30.04544 36.652 &lt; 2e-16 </em><strong> ## conditionLabel1 0.89985 0.09086 29.89489 9.904 5.94e-11 </strong><em> ## conditionLabel2 1.42441 0.05166 30.13975 27.573 &lt; 2e-16 </em><strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL1 ## conditnLbl1 0.677<br />
## conditnLbl2 -0.511 -0.335 ## convergence code: 0 ## Model is nearly unidentifiable: large eigenvalue ratio ## - Rescale variables? ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ conditionLabel + (1 + clabel.c1 + clabel.c2 ||<br />
## participant) ## Data: halfrhyme ## ## REML criterion at convergence: 3860 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.2957 -0.5188 -0.0262 0.5393 3.8347 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.30396 0.5513<br />
## participant.1 clabel.c1 0.23903 0.4889<br />
## participant.2 clabel.c2 0.06519 0.2553<br />
## Residual 1.24808 1.1172<br />
## Number of obs: 1205, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.63410 0.10596 30.02772 34.297 &lt; 2e-16 </strong><em> ## conditionLabel1 0.90151 0.09733 30.01033 9.262 2.63e-10 </em><strong> ## conditionLabel2 1.42488 0.05420 30.28367 26.289 &lt; 2e-16 </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL1 ## conditnLbl1 -0.061<br />
## conditnLbl2 0.043 0.059 ## Other readings ## Appendix: Extra examples {#c6extraexamples} ### Predicting confidence intervals by simulation {#lmm-simulation-confint} ## a simple recipe for simulating 95% confidence intervals over model predictions ## set up dataframe to predict for (every participant, every value of the predictor) ## (simulate 10k times from the model, for newdata) ## lower and upper 95% CIs ## newdata now contains lower and upper bounds of 95% CI, with âpredictionâ = median from simulations ### Random intercept and slope model for <code>givenness</code> data ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: ## acoustics ~ conditionLabel.williams + (1 + conditionLabel.williams ||<br />
## participant) ## Data: givenness ## ## REML criterion at convergence: 897.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0538 -0.7129 0.0083 0.6540 3.3136 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.08937 0.299<br />
## participant.1 conditionLabel.williams 0.00000 0.000<br />
## Residual 0.55800 0.747<br />
## Number of obs: 382, groups: participant, 27 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.71856 0.06916 26.21655 -10.39 8.66e-11 ## conditionLabel.williams 0.32626 0.07677 356.75848 4.25 2.73e-05 ##<br />
## (Intercept) </em><strong> ## conditionLabel.williams </strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) ## cndtnLbl.wl 0.002 ## Appendix: Extended exercise {#c6extendedexercise} ## Linear mixed model fit by REML. t-tests use Satterthwaiteâs method [ ## lmerModLmerTest] ## Formula: ## vowelduration ~ syntax.trans </em> speechrate.slow + (1 + syntax.trans *<br />
## speechrate.slow || item) + (1 + syntax.trans * speechrate.slow ||</a></li>
<li class="chapter" data-level="7.328" data-path="lmem.html"><a href="lmem.html#participant-1"><i class="fa fa-check"></i><b>7.328</b> participant)</a></li>
<li class="chapter" data-level="7.329" data-path="lmem.html"><a href="lmem.html#data-tapped"><i class="fa fa-check"></i><b>7.329</b> Data: tapped</a></li>
<li class="chapter" data-level="7.330" data-path="lmem.html"><a href="lmem.html#section-311"><i class="fa fa-check"></i><b>7.330</b> </a></li>
<li class="chapter" data-level="7.331" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence--2911.9"><i class="fa fa-check"></i><b>7.331</b> REML criterion at convergence: -2911.9</a></li>
<li class="chapter" data-level="7.332" data-path="lmem.html"><a href="lmem.html#section-312"><i class="fa fa-check"></i><b>7.332</b> </a></li>
<li class="chapter" data-level="7.333" data-path="lmem.html"><a href="lmem.html#scaled-residuals-6"><i class="fa fa-check"></i><b>7.333</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.334" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-29"><i class="fa fa-check"></i><b>7.334</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.335" data-path="lmem.html"><a href="lmem.html#section-313"><i class="fa fa-check"></i><b>7.335</b> -3.8002 -0.5148 -0.0247 0.5248 5.3484</a></li>
<li class="chapter" data-level="7.336" data-path="lmem.html"><a href="lmem.html#section-314"><i class="fa fa-check"></i><b>7.336</b> </a></li>
<li class="chapter" data-level="7.337" data-path="lmem.html"><a href="lmem.html#random-effects-6"><i class="fa fa-check"></i><b>7.337</b> Random effects:</a></li>
<li class="chapter" data-level="7.338" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-6"><i class="fa fa-check"></i><b>7.338</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.339" data-path="lmem.html"><a href="lmem.html#participant-syntax.transspeechrate.slow-0.000e00-0.000000"><i class="fa fa-check"></i><b>7.339</b> participant syntax.trans:speechrate.slow 0.000e+00 0.000000</a></li>
<li class="chapter" data-level="7.340" data-path="lmem.html"><a href="lmem.html#participant.1-speechrate.slow-4.459e-04-0.021115"><i class="fa fa-check"></i><b>7.340</b> participant.1 speechrate.slow 4.459e-04 0.021115</a></li>
<li class="chapter" data-level="7.341" data-path="lmem.html"><a href="lmem.html#participant.2-syntax.trans-4.842e-05-0.006958"><i class="fa fa-check"></i><b>7.341</b> participant.2 syntax.trans 4.842e-05 0.006958</a></li>
<li class="chapter" data-level="7.342" data-path="lmem.html"><a href="lmem.html#participant.3-intercept-3.966e-04-0.019916"><i class="fa fa-check"></i><b>7.342</b> participant.3 (Intercept) 3.966e-04 0.019916</a></li>
<li class="chapter" data-level="7.343" data-path="lmem.html"><a href="lmem.html#item-syntax.transspeechrate.slow-0.000e00-0.000000"><i class="fa fa-check"></i><b>7.343</b> item syntax.trans:speechrate.slow 0.000e+00 0.000000</a></li>
<li class="chapter" data-level="7.344" data-path="lmem.html"><a href="lmem.html#item.1-speechrate.slow-1.245e-04-0.011158"><i class="fa fa-check"></i><b>7.344</b> item.1 speechrate.slow 1.245e-04 0.011158</a></li>
<li class="chapter" data-level="7.345" data-path="lmem.html"><a href="lmem.html#item.2-syntax.trans-4.895e-05-0.006996"><i class="fa fa-check"></i><b>7.345</b> item.2 syntax.trans 4.895e-05 0.006996</a></li>
<li class="chapter" data-level="7.346" data-path="lmem.html"><a href="lmem.html#item.3-intercept-1.428e-03-0.037785"><i class="fa fa-check"></i><b>7.346</b> item.3 (Intercept) 1.428e-03 0.037785</a></li>
<li class="chapter" data-level="7.347" data-path="lmem.html"><a href="lmem.html#residual-7.831e-04-0.027983"><i class="fa fa-check"></i><b>7.347</b> Residual 7.831e-04 0.027983</a></li>
<li class="chapter" data-level="7.348" data-path="lmem.html"><a href="lmem.html#number-of-obs-721-groups-participant-23-item-8"><i class="fa fa-check"></i><b>7.348</b> Number of obs: 721, groups: participant, 23; item, 8</a></li>
<li class="chapter" data-level="7.349" data-path="lmem.html"><a href="lmem.html#section-315"><i class="fa fa-check"></i><b>7.349</b> </a></li>
<li class="chapter" data-level="7.350" data-path="lmem.html"><a href="lmem.html#fixed-effects-6"><i class="fa fa-check"></i><b>7.350</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.351" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-df-t-value-2"><i class="fa fa-check"></i><b>7.351</b> Estimate Std. Error df t value</a></li>
<li class="chapter" data-level="7.352" data-path="lmem.html"><a href="lmem.html#intercept-0.101448-0.014029-8.381835-7.232"><i class="fa fa-check"></i><b>7.352</b> (Intercept) 0.101448 0.014029 8.381835 7.232</a></li>
<li class="chapter" data-level="7.353" data-path="lmem.html"><a href="lmem.html#syntax.trans--0.028215-0.003546-9.113087--7.956"><i class="fa fa-check"></i><b>7.353</b> syntax.trans -0.028215 0.003546 9.113087 -7.956</a></li>
<li class="chapter" data-level="7.354" data-path="lmem.html"><a href="lmem.html#speechrate.slow-0.043487-0.006269-18.830504-6.937"><i class="fa fa-check"></i><b>7.354</b> speechrate.slow 0.043487 0.006269 18.830504 6.937</a></li>
<li class="chapter" data-level="7.355" data-path="lmem.html"><a href="lmem.html#syntax.transspeechrate.slow--0.029350-0.004173-631.448408--7.033"><i class="fa fa-check"></i><b>7.355</b> syntax.trans:speechrate.slow -0.029350 0.004173 631.448408 -7.033</a></li>
<li class="chapter" data-level="7.356" data-path="lmem.html"><a href="lmem.html#prt-2"><i class="fa fa-check"></i><b>7.356</b> Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.357" data-path="lmem.html"><a href="lmem.html#intercept-7.08e-05-syntax.trans-2.15e-05"><i class="fa fa-check"></i><b>7.357</b> (Intercept) 7.08e-05 <strong><em> ## syntax.trans 2.15e-05 </em></strong></a></li>
<li class="chapter" data-level="7.358" data-path="lmem.html"><a href="lmem.html#speechrate.slow-1.37e-06-syntax.transspeechrate.slow-5.25e-12"><i class="fa fa-check"></i><b>7.358</b> speechrate.slow 1.37e-06 <strong><em> ## syntax.trans:speechrate.slow 5.25e-12 </em></strong></a></li>
<li class="chapter" data-level="7.359" data-path="lmem.html"><a href="lmem.html#section-316"><i class="fa fa-check"></i><b>7.359</b> â</a></li>
<li class="chapter" data-level="7.360" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-22"><i class="fa fa-check"></i><b>7.360</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="7.361" data-path="lmem.html"><a href="lmem.html#section-317"><i class="fa fa-check"></i><b>7.361</b> </a></li>
<li class="chapter" data-level="7.362" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-5"><i class="fa fa-check"></i><b>7.362</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.363" data-path="lmem.html"><a href="lmem.html#intr-syntx.-spchr."><i class="fa fa-check"></i><b>7.363</b> (Intr) syntx. spchr.</a></li>
<li class="chapter" data-level="7.364" data-path="lmem.html"><a href="lmem.html#syntax.trns-0.000"><i class="fa fa-check"></i><b>7.364</b> syntax.trns 0.000</a></li>
<li class="chapter" data-level="7.365" data-path="lmem.html"><a href="lmem.html#spechrt.slw-0.000-0.002"><i class="fa fa-check"></i><b>7.365</b> spechrt.slw 0.000 0.002</a></li>
<li class="chapter" data-level="7.366" data-path="lmem.html"><a href="lmem.html#syntx.trn.-0.001--0.001-0.000"><i class="fa fa-check"></i><b>7.366</b> syntx.trn:. 0.001 -0.001 0.000</a></li>
<li class="chapter" data-level="7.367" data-path="lmem.html"><a href="lmem.html#c6solns"><i class="fa fa-check"></i><b>7.367</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#loads-tappedmcgillling620.csv-from-osf-project-for-kilbourn-ceron-et-al-2017-data"><i class="fa fa-check"></i><b>8.1</b> loads tappedMcGillLing620.csv from OSF project for Kilbourn-Ceron et al (2017) data</a></li>
<li class="chapter" data-level="8.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#there-is-some-missing-data-for-tapped-variable-exclude-to-avoid-warnings-later"><i class="fa fa-check"></i><b>8.2</b> there is some missing data for âtappedâ variable â exclude to avoid warnings later</a></li>
<li class="chapter" data-level="8.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016-data-2"><i class="fa fa-check"></i><b>8.3</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data</a></li>
<li class="chapter" data-level="8.4" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data-3"><i class="fa fa-check"></i><b>8.4</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="8.5" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#function-for-computing-accuracy-of-a-logistic-regression-model"><i class="fa fa-check"></i><b>8.5</b> function for computing accuracy of a logistic regression model</a></li>
<li class="chapter" data-level="8.6" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#on-the-dataset-used-to-fit-the-model"><i class="fa fa-check"></i><b>8.6</b> (on the dataset used to fit the model)</a></li>
<li class="chapter" data-level="8.7" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod-fitted-model"><i class="fa fa-check"></i><b>8.7</b> lrMod = fitted model</a></li>
<li class="chapter" data-level="8.8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#responsevar-name-of-response-variable-for-lrmod"><i class="fa fa-check"></i><b>8.8</b> responseVar = name of response variable for lrMod</a></li>
<li class="chapter" data-level="8.9" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#use.ranef-true-or-false-should-we-predict-for-grouping-factor-levels-in-this-data-or-for-an-average-level-truefalse"><i class="fa fa-check"></i><b>8.9</b> use.ranef = TRUE or FALSE (should we predict for grouping factor levels in this data, or for an âaverageâ level? TRUE/FALSE)</a></li>
<li class="chapter" data-level="8.10" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#adapted-from-httpswww.r-bloggers.comevaluating-logistic-regression-models"><i class="fa fa-check"></i><b>8.10</b> adapted from: <a href="https://www.r-bloggers.com/evaluating-logistic-regression-models/" class="uri">https://www.r-bloggers.com/evaluating-logistic-regression-models/</a></a></li>
<li class="chapter" data-level="8.11" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#baseline-accuracy-for-a-logisitic-regression-model-lrmod"><i class="fa fa-check"></i><b>8.11</b> baseline accuracy for a logisitic regression model lrMod</a></li>
<li class="chapter" data-level="8.12" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#with-a-given-response-variable"><i class="fa fa-check"></i><b>8.12</b> with a given response variable</a></li>
<li class="chapter" data-level="8.13" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#preliminaries"><i class="fa fa-check"></i><b>8.13</b> Preliminaries</a><ul>
<li class="chapter" data-level="8.13.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#motivation"><i class="fa fa-check"></i><b>8.13.1</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#basics"><i class="fa fa-check"></i><b>8.14</b> Basics</a><ul>
<li class="chapter" data-level="8.14.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7m1"><i class="fa fa-check"></i><b>8.14.1</b> Model 1: <code>givenness</code> data, crossed random effects (intercepts + slopes)</a></li>
</ul></li>
<li class="chapter" data-level="8.15" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace"><i class="fa fa-check"></i><b>8.15</b> Generalized linear mixed model fit by maximum likelihood (Laplace</a></li>
<li class="chapter" data-level="8.16" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#approximation-glmermod"><i class="fa fa-check"></i><b>8.16</b> Approximation) [glmerMod]</a></li>
<li class="chapter" data-level="8.17" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#family-binomial-logit"><i class="fa fa-check"></i><b>8.17</b> Family: binomial ( logit )</a></li>
<li class="chapter" data-level="8.18" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#formula-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.18</b> Formula: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.19" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-nptype.pron-item-1-clabel.williams"><i class="fa fa-check"></i><b>8.19</b> (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.20" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-voice.passive-participant"><i class="fa fa-check"></i><b>8.20</b> npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.21" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-7"><i class="fa fa-check"></i><b>8.21</b> Data: givenness</a></li>
<li class="chapter" data-level="8.22" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#control-glmercontroloptimizer-bobyqa"><i class="fa fa-check"></i><b>8.22</b> Control: glmerControl(optimizer = âbobyqaâ)</a></li>
<li class="chapter" data-level="8.23" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-318"><i class="fa fa-check"></i><b>8.23</b> </a></li>
<li class="chapter" data-level="8.24" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#aic-bic-loglik-deviance-df.resid"><i class="fa fa-check"></i><b>8.24</b> AIC BIC logLik deviance df.resid</a></li>
<li class="chapter" data-level="8.25" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-319"><i class="fa fa-check"></i><b>8.25</b> 349.6 393.0 -163.8 327.6 371</a></li>
<li class="chapter" data-level="8.26" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-320"><i class="fa fa-check"></i><b>8.26</b> </a></li>
<li class="chapter" data-level="8.27" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#scaled-residuals-7"><i class="fa fa-check"></i><b>8.27</b> Scaled residuals:</a></li>
<li class="chapter" data-level="8.28" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#min-1q-median-3q-max-30"><i class="fa fa-check"></i><b>8.28</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="8.29" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-321"><i class="fa fa-check"></i><b>8.29</b> -2.2442 -0.3174 -0.1881 0.4603 4.5955</a></li>
<li class="chapter" data-level="8.30" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-322"><i class="fa fa-check"></i><b>8.30</b> </a></li>
<li class="chapter" data-level="8.31" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects-7"><i class="fa fa-check"></i><b>8.31</b> Random effects:</a></li>
<li class="chapter" data-level="8.32" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#groups-name-variance-std.dev.-7"><i class="fa fa-check"></i><b>8.32</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="8.33" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant-voice.passive-1.648e00-1.284e00"><i class="fa fa-check"></i><b>8.33</b> participant voice.passive 1.648e+00 1.284e+00</a></li>
<li class="chapter" data-level="8.34" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.1-nptype.pron-5.823e-01-7.631e-01"><i class="fa fa-check"></i><b>8.34</b> participant.1 npType.pron 5.823e-01 7.631e-01</a></li>
<li class="chapter" data-level="8.35" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.2-clabel.williams-5.013e-15-7.080e-08"><i class="fa fa-check"></i><b>8.35</b> participant.2 clabel.williams 5.013e-15 7.080e-08</a></li>
<li class="chapter" data-level="8.36" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.3-intercept-1.685e-01-4.105e-01"><i class="fa fa-check"></i><b>8.36</b> participant.3 (Intercept) 1.685e-01 4.105e-01</a></li>
<li class="chapter" data-level="8.37" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item-nptype.pron-5.394e-01-7.344e-01"><i class="fa fa-check"></i><b>8.37</b> item npType.pron 5.394e-01 7.344e-01</a></li>
<li class="chapter" data-level="8.38" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.1-clabel.williams-1.619e00-1.273e00"><i class="fa fa-check"></i><b>8.38</b> item.1 clabel.williams 1.619e+00 1.273e+00</a></li>
<li class="chapter" data-level="8.39" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.2-intercept-2.624e-14-1.620e-07"><i class="fa fa-check"></i><b>8.39</b> item.2 (Intercept) 2.624e-14 1.620e-07</a></li>
<li class="chapter" data-level="8.40" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#number-of-obs-382-groups-participant-27-item-16-4"><i class="fa fa-check"></i><b>8.40</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="8.41" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-323"><i class="fa fa-check"></i><b>8.41</b> </a></li>
<li class="chapter" data-level="8.42" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects-7"><i class="fa fa-check"></i><b>8.42</b> Fixed effects:</a></li>
<li class="chapter" data-level="8.43" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-3"><i class="fa fa-check"></i><b>8.43</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.44" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1383-0.2076--5.483-4.18e-08-clabel.williams-3.7711-0.5676-6.644-3.05e-11"><i class="fa fa-check"></i><b>8.44</b> (Intercept) -1.1383 0.2076 -5.483 4.18e-08 <strong><em> ## clabel.williams 3.7711 0.5676 6.644 3.05e-11 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#nptype.pron-0.7917-0.3987-1.986-0.0471-voice.passive-0.6496-0.4149-1.566-0.1174"><span class="toc-section-number">8.45</span> npType.pron 0.7917 0.3987 1.986 0.0471 *<br />
## voice.passive 0.6496 0.4149 1.566 0.1174</a></li>
<li class="chapter" data-level="8.46" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-324"><i class="fa fa-check"></i><b>8.46</b> â</a></li>
<li class="chapter" data-level="8.47" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-23"><i class="fa fa-check"></i><b>8.47</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="8.48" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-325"><i class="fa fa-check"></i><b>8.48</b> </a></li>
<li class="chapter" data-level="8.49" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#correlation-of-fixed-effects-6"><i class="fa fa-check"></i><b>8.49</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="8.50" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intr-clbl.w-nptyp."><i class="fa fa-check"></i><b>8.50</b> (Intr) clbl.w npTyp.</a></li>
<li class="chapter" data-level="8.51" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabl.wllms--0.458"><i class="fa fa-check"></i><b>8.51</b> clabl.wllms -0.458</a></li>
<li class="chapter" data-level="8.52" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron--0.141-0.174"><i class="fa fa-check"></i><b>8.52</b> npType.pron -0.141 0.174</a></li>
<li class="chapter" data-level="8.53" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passv--0.036-0.082-0.028"><i class="fa fa-check"></i><b>8.53</b> voice.passv -0.036 0.082 0.028</a></li>
<li class="chapter" data-level="8.54" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#hypothesis-testing-3"><i class="fa fa-check"></i><b>8.54</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="8.54.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects-8"><i class="fa fa-check"></i><b>8.54.1</b> Fixed effects</a></li>
</ul></li>
<li class="chapter" data-level="8.55" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-8"><i class="fa fa-check"></i><b>8.55</b> Data: givenness</a></li>
<li class="chapter" data-level="8.56" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#models-2"><i class="fa fa-check"></i><b>8.56</b> Models:</a></li>
<li class="chapter" data-level="8.57" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-stressshift-clabel.williams-voice.passive-1-clabel.williams"><i class="fa fa-check"></i><b>8.57</b> lrMod1.sub: stressshift ~ clabel.williams + voice.passive + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.58" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-nptype.pron-item-1-clabel.williams-nptype.pron"><i class="fa fa-check"></i><b>8.58</b> lrMod1.sub: npType.pron || item) + (1 + clabel.williams + npType.pron +</a></li>
<li class="chapter" data-level="8.59" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-voice.passive-participant"><i class="fa fa-check"></i><b>8.59</b> lrMod1.sub: voice.passive || participant)</a></li>
<li class="chapter" data-level="8.60" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.60</b> lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.61" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams"><i class="fa fa-check"></i><b>8.61</b> lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.62" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-nptype.pron-voice.passive-participant"><i class="fa fa-check"></i><b>8.62</b> lrMod1: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.63" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-2"><i class="fa fa-check"></i><b>8.63</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="8.64" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-10-351.18-390.63--165.59-331.18"><i class="fa fa-check"></i><b>8.64</b> lrMod1.sub 10 351.18 390.63 -165.59 331.18</a></li>
<li class="chapter" data-level="8.65" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-11-349.64-393.04--163.82-327.64-3.5413-1-0.05986-."><i class="fa fa-check"></i><b>8.65</b> lrMod1 11 349.64 393.04 -163.82 327.64 3.5413 1 0.05986 .</a></li>
<li class="chapter" data-level="8.66" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-326"><i class="fa fa-check"></i><b>8.66</b> â</a></li>
<li class="chapter" data-level="8.67" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-24"><i class="fa fa-check"></i><b>8.67</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="8.68" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fit-model-and-get-lr-based-p-values"><i class="fa fa-check"></i><b>8.68</b> fit model and get LR-based p-values:</a></li>
<li class="chapter" data-level="8.69" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fitting-4-glmer-models"><i class="fa fa-check"></i><b>8.69</b> Fitting 4 (g)lmer() models:</a></li>
<li class="chapter" data-level="8.70" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-327"><i class="fa fa-check"></i><b>8.70</b> [â¦.]</a></li>
<li class="chapter" data-level="8.71" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#see-the-results"><i class="fa fa-check"></i><b>8.71</b> see the results:</a></li>
<li class="chapter" data-level="8.72" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#mixed-model-anova-table-type-3-tests-lrt-method"><i class="fa fa-check"></i><b>8.72</b> Mixed Model Anova Table (Type 3 tests, LRT-method)</a></li>
<li class="chapter" data-level="8.73" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-328"><i class="fa fa-check"></i><b>8.73</b> </a></li>
<li class="chapter" data-level="8.74" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.74</b> Model: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.75" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-1-clabel.williams-nptype.pron-item-1-clabel.williams"><i class="fa fa-check"></i><b>8.75</b> Model: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.76" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-nptype.pron-voice.passive-participant"><i class="fa fa-check"></i><b>8.76</b> Model: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.77" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-9"><i class="fa fa-check"></i><b>8.77</b> Data: givenness</a></li>
<li class="chapter" data-level="8.78" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-full-model-11"><i class="fa fa-check"></i><b>8.78</b> Df full model: 11</a></li>
<li class="chapter" data-level="8.79" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#effect-df-chisq-p.value"><i class="fa fa-check"></i><b>8.79</b> Effect df Chisq p.value</a></li>
<li class="chapter" data-level="8.80" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-1-26.67-.0001"><i class="fa fa-check"></i><b>8.80</b> 1 clabel.williams 1 26.67 *** &lt;.0001</a></li>
<li class="chapter" data-level="8.81" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-1-3.54-.06"><i class="fa fa-check"></i><b>8.81</b> 2 npType.pron 1 3.54 + .06</a></li>
<li class="chapter" data-level="8.82" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-1-2.36-.12"><i class="fa fa-check"></i><b>8.82</b> 3 voice.passive 1 2.36 .12</a></li>
<li class="chapter" data-level="8.83" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-329"><i class="fa fa-check"></i><b>8.83</b> â</a></li>
<li class="chapter" data-level="8.84" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-0.1-1-1"><i class="fa fa-check"></i><b>8.84</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â+â 0.1 ââ 1</a></li>
<li class="chapter" data-level="8.85" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#use-multiple-cores-if-your-machine-has-them."><i class="fa fa-check"></i><b>8.85</b> use multiple cores, if your machine has them.</a></li>
<li class="chapter" data-level="8.86" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-330"><i class="fa fa-check"></i><b>8.86</b> [1] 8</a></li>
<li class="chapter" data-level="8.87" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fit-a-random-intercepts-only-model-in-general-not-ok-but-it-would-take-much-longer-to-fit-the-model-with-random-slopes."><i class="fa fa-check"></i><b>8.87</b> fit a <em>random-intercepts only</em> model (in general, not OK, but it would take much longer to fit the model with random slopes).</a></li>
<li class="chapter" data-level="8.88" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#this-still-takes-5-minutes-on-my-8-core-computer"><i class="fa fa-check"></i><b>8.88</b> This still takes 5 minutes on my 8-core computer:</a></li>
<li class="chapter" data-level="8.89" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fitting-4-glmer-models."><i class="fa fa-check"></i><b>8.89</b> Fitting 4 (g)lmer() models.</a></li>
<li class="chapter" data-level="8.90" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#obtaining-3-p-values"><i class="fa fa-check"></i><b>8.90</b> Obtaining 3 p-values:</a></li>
<li class="chapter" data-level="8.91" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-331"><i class="fa fa-check"></i><b>8.91</b> [â¦]</a></li>
<li class="chapter" data-level="8.92" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#look-at-the-p-values-nb-0.001-minimum-p-value-when-nsim1000"><i class="fa fa-check"></i><b>8.92</b> look at the p-values (nb: 0.001 = minimum p-value when nsim=1000)</a></li>
<li class="chapter" data-level="8.93" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#mixed-model-anova-table-type-3-tests-pb-method"><i class="fa fa-check"></i><b>8.93</b> Mixed Model Anova Table (Type 3 tests, PB-method)</a></li>
<li class="chapter" data-level="8.94" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-332"><i class="fa fa-check"></i><b>8.94</b> </a></li>
<li class="chapter" data-level="8.95" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-stressshift-clabel.williams-nptype.pron-voice.passive-1"><i class="fa fa-check"></i><b>8.95</b> Model: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.96" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-1-item-1-participant"><i class="fa fa-check"></i><b>8.96</b> Model: (1 | item) + (1 | participant)</a></li>
<li class="chapter" data-level="8.97" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-10"><i class="fa fa-check"></i><b>8.97</b> Data: givenness</a></li>
<li class="chapter" data-level="8.98" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#effect-df-chisq-p.value-1"><i class="fa fa-check"></i><b>8.98</b> Effect df Chisq p.value</a></li>
<li class="chapter" data-level="8.99" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-1-150.61-.0010"><i class="fa fa-check"></i><b>8.99</b> 1 clabel.williams 1 150.61 *** .0010</a></li>
<li class="chapter" data-level="8.100" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-1-5.06-.03"><i class="fa fa-check"></i><b>8.100</b> 2 npType.pron 1 5.06 * .03</a></li>
<li class="chapter" data-level="8.101" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-1-7.43-.009"><i class="fa fa-check"></i><b>8.101</b> 3 voice.passive 1 7.43 ** .009</a></li>
<li class="chapter" data-level="8.102" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-333"><i class="fa fa-check"></i><b>8.102</b> â</a></li>
<li class="chapter" data-level="8.103" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-0.1-1-2"><i class="fa fa-check"></i><b>8.103</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â+â 0.1 ââ 1</a><ul>
<li class="chapter" data-level="8.103.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects-8"><i class="fa fa-check"></i><b>8.103.1</b> Random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.104" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-11"><i class="fa fa-check"></i><b>8.104</b> Data: givenness</a></li>
<li class="chapter" data-level="8.105" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#models-3"><i class="fa fa-check"></i><b>8.105</b> Models:</a></li>
<li class="chapter" data-level="8.106" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.106</b> lrMod1.1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.107" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-1-nptype.pron-item-1-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.107</b> lrMod1.1: (1 + npType.pron || item) + (1 + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.108" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-clabel.williams-participant"><i class="fa fa-check"></i><b>8.108</b> lrMod1.1: clabel.williams || participant)</a></li>
<li class="chapter" data-level="8.109" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive-1"><i class="fa fa-check"></i><b>8.109</b> lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.110" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams-1"><i class="fa fa-check"></i><b>8.110</b> lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.111" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-nptype.pron-voice.passive-participant-1"><i class="fa fa-check"></i><b>8.111</b> lrMod1: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.112" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-3"><i class="fa fa-check"></i><b>8.112</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="8.113" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-10-352.24-391.69--166.12-332.24"><i class="fa fa-check"></i><b>8.113</b> lrMod1.1 10 352.24 391.69 -166.12 332.24</a></li>
<li><a href="mixed-effects-logistic-regression.html#lrmod1-11-349.64-393.04--163.82-327.64-4.5994-1-0.03198-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-fixed-and-random-effects-all-terms-involving-voice-excluded-data-givenness-models-lrmod1.1-stressshift-clabel.williams-nptype.pron-1-clabel.williams-lrmod1.1-nptype.pron-item-1-nptype.pron-clabel.williams-lrmod1.1-participant-lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive-lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams-lrmod1-nptype.pron-voice.passive-participant-df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-lrmod1.1-9-353.08-388.59--167.54-335.08-lrmod1-11-349.64-393.04--163.82-327.64-7.4458-2-0.02416"><span class="toc-section-number">8.114</span> lrMod1 11 349.64 393.04 -163.82 327.64 4.5994 1 0.03198 <em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## Fixed and random effects ## all terms involving <code>voice</code> excluded ## Data: givenness ## Models: ## lrMod1.1: stressshift ~ clabel.williams + npType.pron + (1 + clabel.williams + ## lrMod1.1: npType.pron || item) + (1 + npType.pron + clabel.williams || ## lrMod1.1: participant) ## lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive + ## lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams + ## lrMod1: npType.pron + voice.passive || participant) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)<br />
## lrMod1.1 9 353.08 388.59 -167.54 335.08<br />
## lrMod1 11 349.64 393.04 -163.82 327.64 7.4458 2 0.02416 </em></a></li>
<li class="chapter" data-level="8.115" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-334"><i class="fa fa-check"></i><b>8.115</b> â</a></li>
<li class="chapter" data-level="8.116" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-25"><i class="fa fa-check"></i><b>8.116</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="8.117" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#melr-practice"><i class="fa fa-check"></i><b>8.117</b> MELR Practice</a><ul>
<li class="chapter" data-level="8.117.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7ex1"><i class="fa fa-check"></i><b>8.117.1</b> Exercise 1: tapping</a></li>
</ul></li>
<li class="chapter" data-level="8.118" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-criticism-for-mixed-effects-logistic-regression"><i class="fa fa-check"></i><b>8.118</b> Model criticism for mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.118.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effect-distributions"><i class="fa fa-check"></i><b>8.118.1</b> Random-effect distributions</a></li>
<li class="chapter" data-level="8.118.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#residual-plots"><i class="fa fa-check"></i><b>8.118.2</b> Residual plots</a></li>
<li class="chapter" data-level="8.118.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#influence"><i class="fa fa-check"></i><b>8.118.3</b> Influence</a></li>
</ul></li>
<li class="chapter" data-level="8.119" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-335"><i class="fa fa-check"></i><b>8.119</b> [,1]</a></li>
<li class="chapter" data-level="8.120" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-336"><i class="fa fa-check"></i><b>8.120</b> 530 0.225778367</a></li>
<li class="chapter" data-level="8.121" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-337"><i class="fa fa-check"></i><b>8.121</b> 548 0.185550214</a></li>
<li class="chapter" data-level="8.122" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-338"><i class="fa fa-check"></i><b>8.122</b> 563 0.074174496</a></li>
<li class="chapter" data-level="8.123" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-339"><i class="fa fa-check"></i><b>8.123</b> 529 0.063628074</a></li>
<li class="chapter" data-level="8.124" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-340"><i class="fa fa-check"></i><b>8.124</b> 554 0.055073386</a></li>
<li class="chapter" data-level="8.125" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-341"><i class="fa fa-check"></i><b>8.125</b> 297 0.053395685</a></li>
<li class="chapter" data-level="8.126" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-342"><i class="fa fa-check"></i><b>8.126</b> 541 0.052571319</a></li>
<li class="chapter" data-level="8.127" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-343"><i class="fa fa-check"></i><b>8.127</b> 549 0.044627482</a></li>
<li class="chapter" data-level="8.128" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-344"><i class="fa fa-check"></i><b>8.128</b> 24 0.043046353</a></li>
<li class="chapter" data-level="8.129" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-345"><i class="fa fa-check"></i><b>8.129</b> 540 0.039707331</a></li>
<li class="chapter" data-level="8.130" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-346"><i class="fa fa-check"></i><b>8.130</b> 547 0.039506196</a></li>
<li class="chapter" data-level="8.131" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-347"><i class="fa fa-check"></i><b>8.131</b> 557 0.038630256</a></li>
<li class="chapter" data-level="8.132" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-348"><i class="fa fa-check"></i><b>8.132</b> 432 0.035733805</a></li>
<li class="chapter" data-level="8.133" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-349"><i class="fa fa-check"></i><b>8.133</b> 555 0.030503148</a></li>
<li class="chapter" data-level="8.134" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-350"><i class="fa fa-check"></i><b>8.134</b> 544 0.028093074</a></li>
<li class="chapter" data-level="8.135" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-351"><i class="fa fa-check"></i><b>8.135</b> 553 0.025852398</a></li>
<li class="chapter" data-level="8.136" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-352"><i class="fa fa-check"></i><b>8.136</b> 556 0.022235841</a></li>
<li class="chapter" data-level="8.137" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-353"><i class="fa fa-check"></i><b>8.137</b> 564 0.019375321</a></li>
<li class="chapter" data-level="8.138" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-354"><i class="fa fa-check"></i><b>8.138</b> 559 0.016134504</a></li>
<li class="chapter" data-level="8.139" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-355"><i class="fa fa-check"></i><b>8.139</b> 550 0.015203804</a></li>
<li class="chapter" data-level="8.140" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-356"><i class="fa fa-check"></i><b>8.140</b> 552 0.013620053</a></li>
<li class="chapter" data-level="8.141" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-357"><i class="fa fa-check"></i><b>8.141</b> 558 0.012093557</a></li>
<li class="chapter" data-level="8.142" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-358"><i class="fa fa-check"></i><b>8.142</b> 561 0.012054054</a></li>
<li class="chapter" data-level="8.143" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-359"><i class="fa fa-check"></i><b>8.143</b> 560 0.010068154</a></li>
<li class="chapter" data-level="8.144" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-360"><i class="fa fa-check"></i><b>8.144</b> 542 0.008765176</a></li>
<li class="chapter" data-level="8.145" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-361"><i class="fa fa-check"></i><b>8.145</b> 524 0.008675731</a></li>
<li class="chapter" data-level="8.146" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-362"><i class="fa fa-check"></i><b>8.146</b> 562 0.008593942</a></li>
<li class="chapter" data-level="8.147" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-4"><i class="fa fa-check"></i><b>8.147</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.148" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1383258-0.2076053--5.483124-4.178800e-08"><i class="fa fa-check"></i><b>8.148</b> (Intercept) -1.1383258 0.2076053 -5.483124 4.178800e-08</a></li>
<li class="chapter" data-level="8.149" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-3.7710505-0.5675843-6.644036-3.052075e-11"><i class="fa fa-check"></i><b>8.149</b> clabel.williams 3.7710505 0.5675843 6.644036 3.052075e-11</a></li>
<li class="chapter" data-level="8.150" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-0.7917211-0.3987366-1.985574-4.708063e-02"><i class="fa fa-check"></i><b>8.150</b> npType.pron 0.7917211 0.3987366 1.985574 4.708063e-02</a></li>
<li class="chapter" data-level="8.151" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-0.6496316-0.4149409-1.565600-1.174422e-01"><i class="fa fa-check"></i><b>8.151</b> voice.passive 0.6496316 0.4149409 1.565600 1.174422e-01</a></li>
<li class="chapter" data-level="8.152" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-5"><i class="fa fa-check"></i><b>8.152</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.153" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1848192-0.2138651--5.540030-3.024197e-08"><i class="fa fa-check"></i><b>8.153</b> (Intercept) -1.1848192 0.2138651 -5.540030 3.024197e-08</a></li>
<li class="chapter" data-level="8.154" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-3.8105677-0.5956800-6.397005-1.584543e-10"><i class="fa fa-check"></i><b>8.154</b> clabel.williams 3.8105677 0.5956800 6.397005 1.584543e-10</a></li>
<li class="chapter" data-level="8.155" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-0.9129111-0.3427896-2.663182-7.740552e-03"><i class="fa fa-check"></i><b>8.155</b> npType.pron 0.9129111 0.3427896 2.663182 7.740552e-03</a></li>
<li class="chapter" data-level="8.156" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-0.3137257-0.3848432-0.815204-4.149556e-01"><i class="fa fa-check"></i><b>8.156</b> voice.passive 0.3137257 0.3848432 0.815204 4.149556e-01</a></li>
<li class="chapter" data-level="8.157" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measures"><i class="fa fa-check"></i><b>8.157</b> Evaluation measures</a><ul>
<li class="chapter" data-level="8.157.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measure-1-likelihood-ratio-test"><i class="fa fa-check"></i><b>8.157.1</b> Evaluation measure 1: Likelihood ratio test</a></li>
</ul></li>
<li class="chapter" data-level="8.158" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-12"><i class="fa fa-check"></i><b>8.158</b> Data: givenness</a></li>
<li class="chapter" data-level="8.159" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#models-4"><i class="fa fa-check"></i><b>8.159</b> Models:</a></li>
<li class="chapter" data-level="8.160" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#m0-stressshift-1-item-1-participant"><i class="fa fa-check"></i><b>8.160</b> m0: stressshift ~ (1 | item) + (1 | participant)</a></li>
<li class="chapter" data-level="8.161" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive-2"><i class="fa fa-check"></i><b>8.161</b> lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.162" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams-2"><i class="fa fa-check"></i><b>8.162</b> lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.163" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-nptype.pron-voice.passive-participant-2"><i class="fa fa-check"></i><b>8.163</b> lrMod1: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.164" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-4"><i class="fa fa-check"></i><b>8.164</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="8.165" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#m0-3-502.24-514.08--248.12-496.24"><i class="fa fa-check"></i><b>8.165</b> m0 3 502.24 514.08 -248.12 496.24</a></li>
<li><a href="mixed-effects-logistic-regression.html#lrmod1-11-349.64-393.04--163.82-327.64-168.6-8-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-evaluation-measure-2-classification-accuracy-1-0.8638743-1-0.6465969-1-0.7879581-miscellaneous-mixed-effects-regression-topics-random-effect-correlation-issues-c7m2-groups-name-std.dev.-corr-participant-intercept-0.67835-clabel.williams-1.19637--0.726-nptype.pron-1.30652--0.218-0.657-voice.passive-1.32666--0.141--0.094--0.796-item-intercept-0.45694-clabel.williams-1.51394--1.000-nptype.pron-0.85705-1.000--1.000-example-dropping-correlation-terms-groups-name-std.dev.-corr-participant-intercept-0.60099-clabel.williams-1.05584--0.642-nptype.pron-1.30842--0.070-0.655-voice.passive-1.29183--0.201--0.157--0.827-item-intercept-0.41505-clabel.williams-1.40683--1.000-item.1-nptype.pron-0.70982-groups-name-std.dev.-corr-participant-intercept-0.54756-clabel.williams-1.02080--0.549-nptype.pron-1.33817-0.007-0.644-voice.passive-1.30948--0.327--0.082--0.807-item-intercept-0.00000-item.1-clabel.williams-1.13985-item.2-nptype.pron-0.70400-data-givenness-models-lrmod2.red2-stressshift-clabel.williams-nptype.pron-voice.passive-lrmod2.red2-1-clabel.williams-nptype.pron-voice.passive-participant-lrmod2.red2-1-item-0-clabel.williams-item-0-nptype.pron-lrmod2.red2-item-lrmod2-stressshift-clabel.williams-nptype.pron-voice.passive-lrmod2-1-clabel.williams-nptype.pron-item-1-clabel.williams-lrmod2-nptype.pron-voice.passive-participant-df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-lrmod2.red2-17-352.88-419.95--159.44-318.88-lrmod2-20-353.31-432.22--156.66-313.31-5.5704-3-0.1345-example-bayesian-mems-bayesian-mems-cov-prior-participant-wishartdf-6.5-scale-inf-posterior.scale-cov-common.scale-true-item-wishartdf-5.5-scale-inf-posterior.scale-cov-common.scale-true-prior-dev--2.976-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-bglmermod-family-binomial-logit-formula-stressshift-clabel.williams-nptype.pron-voice.passive-1-clabel.williams-nptype.pron-item-1-clabel.williams-nptype.pron-voice.passive-participant-data-givenness-control-glmercontroloptimizer-bobyqa-aic-bic-loglik-deviance-df.resid-360.5-439.4--160.3-320.5-362-scaled-residuals-min-1q-median-3q-max--2.05023--0.24401--0.07532-0.29963-2.57711-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-1.1974-1.0943-clabel.williams-3.1481-1.7743--0.62-nptype.pron-3.4775-1.8648--0.18-0.50-voice.passive-3.7961-1.9484-0.03-0.06--0.68-item-intercept-0.7312-0.8551-clabel.williams-4.6235-2.1502--0.79-nptype.pron-1.9166-1.3844-0.56--0.73-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-z-value-prz-intercept--1.9235-0.5112--3.763-0.000168"><span class="toc-section-number">8.166</span> lrMod1 11 349.64 393.04 -163.82 327.64 168.6 8 &lt; 2.2e-16 <strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ### Evaluation measure 2: Classification accuracy ## [1] 0.8638743 ## [1] 0.6465969 ## [1] 0.7879581 ## Miscellaneous mixed-effects regression topics ### Random-effect correlation issues {#c7m2} ## Groups Name Std.Dev. Corr<br />
## participant (Intercept) 0.67835<br />
## clabel.williams 1.19637 -0.726<br />
## npType.pron 1.30652 -0.218 0.657<br />
## voice.passive 1.32666 -0.141 -0.094 -0.796 ## item (Intercept) 0.45694<br />
## clabel.williams 1.51394 -1.000<br />
## npType.pron 0.85705 1.000 -1.000 #### Example: Dropping correlation terms ## Groups Name Std.Dev. Corr<br />
## participant (Intercept) 0.60099<br />
## clabel.williams 1.05584 -0.642<br />
## npType.pron 1.30842 -0.070 0.655<br />
## voice.passive 1.29183 -0.201 -0.157 -0.827 ## item (Intercept) 0.41505<br />
## clabel.williams 1.40683 -1.000<br />
## item.1 npType.pron 0.70982 ## Groups Name Std.Dev. Corr<br />
## participant (Intercept) 0.54756<br />
## clabel.williams 1.02080 -0.549<br />
## npType.pron 1.33817 0.007 0.644<br />
## voice.passive 1.30948 -0.327 -0.082 -0.807 ## item (Intercept) 0.00000<br />
## item.1 clabel.williams 1.13985<br />
## item.2 npType.pron 0.70400 ## Data: givenness ## Models: ## lrMod2.red2: stressshift ~ clabel.williams + npType.pron + voice.passive + ## lrMod2.red2: (1 + clabel.williams + npType.pron + voice.passive | participant) + ## lrMod2.red2: (1 | item) + (0 + clabel.williams | item) + (0 + npType.pron | ## lrMod2.red2: item) ## lrMod2: stressshift ~ clabel.williams + npType.pron + voice.passive + ## lrMod2: (1 + clabel.williams + npType.pron | item) + (1 + clabel.williams + ## lrMod2: npType.pron + voice.passive | participant) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## lrMod2.red2 17 352.88 419.95 -159.44 318.88<br />
## lrMod2 20 353.31 432.22 -156.66 313.31 5.5704 3 0.1345 #### Example: Bayesian MEMs {#bayesian-mems} ## Cov prior : participant ~ wishart(df = 6.5, scale = Inf, posterior.scale = cov, common.scale = TRUE) ## : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov, common.scale = TRUE) ## Prior dev : -2.976 ## ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [bglmerMod] ## Family: binomial ( logit ) ## Formula: stressshift ~ clabel.williams + npType.pron + voice.passive +<br />
## (1 + clabel.williams + npType.pron | item) + (1 + clabel.williams +<br />
## npType.pron + voice.passive | participant) ## Data: givenness ## Control: glmerControl(optimizer = âbobyqaâ) ## ## AIC BIC logLik deviance df.resid ## 360.5 439.4 -160.3 320.5 362 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.05023 -0.24401 -0.07532 0.29963 2.57711 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 1.1974 1.0943<br />
## clabel.williams 3.1481 1.7743 -0.62<br />
## npType.pron 3.4775 1.8648 -0.18 0.50<br />
## voice.passive 3.7961 1.9484 0.03 0.06 -0.68 ## item (Intercept) 0.7312 0.8551<br />
## clabel.williams 4.6235 2.1502 -0.79<br />
## npType.pron 1.9166 1.3844 0.56 -0.73<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -1.9235 0.5112 -3.763 0.000168 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#clabel.williams-5.8044-1.1396-5.093-3.52e-07-nptype.pron-0.9937-0.6655-1.493-0.135425-voice.passive-1.2633-0.6879-1.836-0.066286-.-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-clbl.w-nptyp.-clabl.wllms--0.799-nptype.pron-0.027-0.011-voice.passv--0.151-0.235--0.199-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-glmermod-family-binomial-logit-formula-stressshift-clabel.williams-nptype.pron-voice.passive-1-clabel.williams-nptype.pron-item-1-clabel.williams-nptype.pron-voice.passive-participant-data-givenness-control-glmercontroloptimizer-bobyqa-aic-bic-loglik-deviance-df.resid-353.3-432.2--156.7-313.3-362-scaled-residuals-min-1q-median-3q-max--2.1302--0.2737--0.1186-0.4182-3.7528-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-0.4602-0.6783-clabel.williams-1.4313-1.1964--0.73-nptype.pron-1.7070-1.3065--0.22-0.66-voice.passive-1.7600-1.3267--0.14--0.09--0.80-item-intercept-0.2088-0.4569-clabel.williams-2.2920-1.5139--1.00-nptype.pron-0.7345-0.8571-1.00--1.00-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-z-value-prz-intercept--1.5286-0.3601--4.245-2.19e-05"><span class="toc-section-number">8.167</span> clabel.williams 5.8044 1.1396 5.093 3.52e-07 <strong><em> ## npType.pron 0.9937 0.6655 1.493 0.135425<br />
## voice.passive 1.2633 0.6879 1.836 0.066286 .<br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) clbl.w npTyp. ## clabl.wllms -0.799<br />
## npType.pron 0.027 0.011<br />
## voice.passv -0.151 0.235 -0.199 ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: stressshift ~ clabel.williams + npType.pron + voice.passive +<br />
## (1 + clabel.williams + npType.pron | item) + (1 + clabel.williams +<br />
## npType.pron + voice.passive | participant) ## Data: givenness ## Control: glmerControl(optimizer = âbobyqaâ) ## ## AIC BIC logLik deviance df.resid ## 353.3 432.2 -156.7 313.3 362 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.1302 -0.2737 -0.1186 0.4182 3.7528 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 0.4602 0.6783<br />
## clabel.williams 1.4313 1.1964 -0.73<br />
## npType.pron 1.7070 1.3065 -0.22 0.66<br />
## voice.passive 1.7600 1.3267 -0.14 -0.09 -0.80 ## item (Intercept) 0.2088 0.4569<br />
## clabel.williams 2.2920 1.5139 -1.00<br />
## npType.pron 0.7345 0.8571 1.00 -1.00<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -1.5286 0.3601 -4.245 2.19e-05 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#clabel.williams-4.5928-0.8186-5.611-2.02e-08-nptype.pron-0.8047-0.4997-1.610-0.1073-voice.passive-0.9398-0.4722-1.990-0.0466-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-other-readings-appendices-appendix-random-slopes-for-factors-melr-random-slopes-for-factors-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-glmermod-family-binomial-logit-formula-prominence-context-1-context-item-1-context-participant-data-alternatives-control-glmercontroloptimizer-bobyqa-aic-bic-loglik-deviance-df.resid-654.6-721.1--312.3-624.6-607-scaled-residuals-min-1q-median-3q-max--3.5691--0.5550-0.2148-0.5648-2.5891-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-0.6585734-0.81153-context1-0.0917516-0.30291-0.06-context2-0.0169077-0.13003--0.24-0.95-item-intercept-0.6781250-0.82348-context1-0.0008455-0.02908-0.81-context2-0.4283623-0.65449-0.62-0.96-number-of-obs-622-groups-participant-18-item-12-fixed-effects-estimate-std.-error-z-value-prz-intercept-1.2516-0.3652-3.427-0.00061-context1-0.8659-0.1492-5.803-6.5e-09-context2-0.8132-0.2662-3.054-0.00226"><span class="toc-section-number">8.168</span> clabel.williams 4.5928 0.8186 5.611 2.02e-08 <strong><em> ## npType.pron 0.8047 0.4997 1.610 0.1073<br />
## voice.passive 0.9398 0.4722 1.990 0.0466 </em><br />
## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## Other readings ## Appendices ### Appendix: Random slopes for factors {#melr-random-slopes-for-factors} ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: prominence ~ context + (1 + context | item) + (1 + context |<br />
## participant) ## Data: alternatives ## Control: glmerControl(optimizer = âbobyqaâ) ## ## AIC BIC logLik deviance df.resid ## 654.6 721.1 -312.3 624.6 607 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.5691 -0.5550 0.2148 0.5648 2.5891 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 0.6585734 0.81153<br />
## context1 0.0917516 0.30291 0.06<br />
## context2 0.0169077 0.13003 -0.24 0.95 ## item (Intercept) 0.6781250 0.82348<br />
## context1 0.0008455 0.02908 0.81<br />
## context2 0.4283623 0.65449 0.62 0.96 ## Number of obs: 622, groups: participant, 18; item, 12 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) 1.2516 0.3652 3.427 0.00061 </strong><em> ## context1 0.8659 0.1492 5.803 6.5e-09 </em><strong> ## context2 0.8132 0.2662 3.054 0.00226 </strong></a></li>
<li class="chapter" data-level="8.169" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-363"><i class="fa fa-check"></i><b>8.169</b> â</a></li>
<li class="chapter" data-level="8.170" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-26"><i class="fa fa-check"></i><b>8.170</b> Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1</a></li>
<li class="chapter" data-level="8.171" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-364"><i class="fa fa-check"></i><b>8.171</b> </a></li>
<li class="chapter" data-level="8.172" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#correlation-of-fixed-effects-7"><i class="fa fa-check"></i><b>8.172</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="8.173" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intr-cntxt1"><i class="fa fa-check"></i><b>8.173</b> (Intr) cntxt1</a></li>
<li class="chapter" data-level="8.174" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#context1-0.092"><i class="fa fa-check"></i><b>8.174</b> context1 0.092</a></li>
<li class="chapter" data-level="8.175" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#context2-0.566-0.062"><i class="fa fa-check"></i><b>8.175</b> context2 0.566 0.062</a><ul>
<li class="chapter" data-level="8.175.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7appendix2"><i class="fa fa-check"></i><b>8.175.1</b> Appendix: Multi-level factors and uncorrelated random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.176" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-1"><i class="fa fa-check"></i><b>8.176</b> Generalized linear mixed model fit by maximum likelihood (Laplace</a></li>
<li class="chapter" data-level="8.177" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#approximation-glmermod-1"><i class="fa fa-check"></i><b>8.177</b> Approximation) [glmerMod]</a></li>
<li class="chapter" data-level="8.178" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#family-binomial-logit-1"><i class="fa fa-check"></i><b>8.178</b> Family: binomial ( logit )</a></li>
<li class="chapter" data-level="8.179" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#formula-shifted-context-1-context1-context2-item-1"><i class="fa fa-check"></i><b>8.179</b> Formula: shifted ~ context + (1 + context1 + context2 || item) + (1 +</a></li>
<li class="chapter" data-level="8.180" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#context1-context2-participant"><i class="fa fa-check"></i><b>8.180</b> context1 + context2 || participant)</a></li>
<li class="chapter" data-level="8.181" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-alternatives"><i class="fa fa-check"></i><b>8.181</b> Data: alternatives</a></li>
<li class="chapter" data-level="8.182" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#control-glmercontroloptimizer-bobyqa-1"><i class="fa fa-check"></i><b>8.182</b> Control: glmerControl(optimizer = âbobyqaâ)</a></li>
<li class="chapter" data-level="8.183" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-365"><i class="fa fa-check"></i><b>8.183</b> </a></li>
<li class="chapter" data-level="8.184" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#aic-bic-loglik-deviance-df.resid-1"><i class="fa fa-check"></i><b>8.184</b> AIC BIC logLik deviance df.resid</a></li>
<li class="chapter" data-level="8.185" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-366"><i class="fa fa-check"></i><b>8.185</b> 646.8 686.7 -314.4 628.8 613</a></li>
<li class="chapter" data-level="8.186" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-367"><i class="fa fa-check"></i><b>8.186</b> </a></li>
<li class="chapter" data-level="8.187" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#scaled-residuals-8"><i class="fa fa-check"></i><b>8.187</b> Scaled residuals:</a></li>
<li class="chapter" data-level="8.188" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#min-1q-median-3q-max-31"><i class="fa fa-check"></i><b>8.188</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="8.189" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-368"><i class="fa fa-check"></i><b>8.189</b> -2.9286 -0.5564 -0.2484 0.5676 3.5763</a></li>
<li class="chapter" data-level="8.190" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-369"><i class="fa fa-check"></i><b>8.190</b> </a></li>
<li class="chapter" data-level="8.191" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects-9"><i class="fa fa-check"></i><b>8.191</b> Random effects:</a></li>
<li class="chapter" data-level="8.192" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#groups-name-variance-std.dev.-8"><i class="fa fa-check"></i><b>8.192</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="8.193" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant-context2-0.00000-0.0000"><i class="fa fa-check"></i><b>8.193</b> participant context2 0.00000 0.0000</a></li>
<li class="chapter" data-level="8.194" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.1-context1-0.06545-0.2558"><i class="fa fa-check"></i><b>8.194</b> participant.1 context1 0.06545 0.2558</a></li>
<li class="chapter" data-level="8.195" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.2-intercept-0.67379-0.8208"><i class="fa fa-check"></i><b>8.195</b> participant.2 (Intercept) 0.67379 0.8208</a></li>
<li class="chapter" data-level="8.196" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item-context2-0.29399-0.5422"><i class="fa fa-check"></i><b>8.196</b> item context2 0.29399 0.5422</a></li>
<li class="chapter" data-level="8.197" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.1-context1-0.00000-0.0000"><i class="fa fa-check"></i><b>8.197</b> item.1 context1 0.00000 0.0000</a></li>
<li class="chapter" data-level="8.198" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.2-intercept-0.56035-0.7486"><i class="fa fa-check"></i><b>8.198</b> item.2 (Intercept) 0.56035 0.7486</a></li>
<li class="chapter" data-level="8.199" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#number-of-obs-622-groups-participant-18-item-12"><i class="fa fa-check"></i><b>8.199</b> Number of obs: 622, groups: participant, 18; item, 12</a></li>
<li class="chapter" data-level="8.200" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-370"><i class="fa fa-check"></i><b>8.200</b> </a></li>
<li class="chapter" data-level="8.201" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects-9"><i class="fa fa-check"></i><b>8.201</b> Fixed effects:</a></li>
<li class="chapter" data-level="8.202" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-6"><i class="fa fa-check"></i><b>8.202</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.203" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1533-0.3199--3.605-0.000312-context1--0.8716-0.1375--6.338-2.32e-10"><i class="fa fa-check"></i><b>8.203</b> (Intercept) -1.1533 0.3199 -3.605 0.000312 <strong><em> ## context1 -0.8716 0.1375 -6.338 2.32e-10 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#context2--0.7014-0.1909--3.673-0.000240-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cntxt1-context1-0.054-context2-0.129-0.018-data-alternatives-models-alternativesmod2-shifted-context-1-context1-context2-item-1-alternativesmod2-context1-context2-participant-alternativesmod1-prominence-context-1-context-item-1-context-alternativesmod1-participant-df-aic-bic-loglik-deviance-chisq-chi-df-alternativesmod2-9-646.83-686.73--314.42-628.83-alternativesmod1-15-654.56-721.05--312.28-624.56-4.2702-6-prchisq-alternativesmod2-alternativesmod1-0.6402-appendix-what-can-happen-if-a-random-slope-isnt-included-estimate-std.-error-z-value-prz-intercept--1.0110841-0.1644734--6.147402-7.876258e-10-clabel.williams-3.1918034-0.3288389-9.706283-2.834878e-22-nptype.pron-0.6148035-0.2767721-2.221335-2.632827e-02-voice.passive-0.7639485-0.2781885-2.746154-6.029846e-03-estimate-std.-error-z-value-prz-intercept--1.1383258-0.2076053--5.483124-4.178800e-08-clabel.williams-3.7710505-0.5675843-6.644036-3.052075e-11-nptype.pron-0.7917211-0.3987366-1.985574-4.708063e-02-voice.passive-0.6496316-0.4149409-1.565600-1.174422e-01-groups-name-variance-std.dev.-participant-intercept-0.039786-0.19946-item-intercept-0.000000-0.00000-groups-name-variance-std.dev.-participant-voice.passive-1.6482e00-1.2838e00-participant.1-nptype.pron-5.8230e-01-7.6308e-01-participant.2-clabel.williams-5.0132e-15-7.0804e-08-participant.3-intercept-1.6855e-01-4.1054e-01-item-nptype.pron-5.3942e-01-7.3445e-01-item.1-clabel.williams-1.6193e00-1.2725e00-item.2-intercept-2.6237e-14-1.6198e-07-solutions-c7solns-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-glmermod-family-binomial-logit-formula-tapped-speechrate.slow-syntax.trans-1-syntax.trans-speechrate.slow-participant-1-syntax.trans-speechrate.slow-item-data-tapped-aic-bic-loglik-deviance-df.resid-330.0-371.2--156.0-312.0-706-scaled-residuals-min-1q-median-3q-max--2.4530--0.2026--0.0697--0.0302-4.1061-random-effects-groups-name-variance-std.dev.-participant-intercept-2.011e00-1.418e00-participant.1-syntax.trans-0.000e00-0.000e00-participant.2-speechrate.slow-1.272e01-3.566e00-item-intercept-3.174e-01-5.634e-01-item.1-syntax.trans-4.284e-01-6.545e-01-item.2-speechrate.slow-5.115e-10-2.262e-05-number-of-obs-715-groups-participant-23-item-8-fixed-effects-estimate-std.-error-z-value-prz-intercept--4.3843-0.6155--7.123-1.06e-12"><span class="toc-section-number">8.204</span> context2 -0.7014 0.1909 -3.673 0.000240 <strong><em> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) cntxt1 ## context1 0.054<br />
## context2 0.129 0.018 ## Data: alternatives ## Models: ## alternativesMod2: shifted ~ context + (1 + context1 + context2 || item) + (1 + ## alternativesMod2: context1 + context2 || participant) ## alternativesMod1: prominence ~ context + (1 + context | item) + (1 + context | ## alternativesMod1: participant) ## Df AIC BIC logLik deviance Chisq Chi Df ## alternativesMod2 9 646.83 686.73 -314.42 628.83<br />
## alternativesMod1 15 654.56 721.05 -312.28 624.56 4.2702 6 ## Pr(&gt;Chisq) ## alternativesMod2<br />
## alternativesMod1 0.6402 ### Appendix: What can happen if a random slope isnât included? ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.0110841 0.1644734 -6.147402 7.876258e-10 ## clabel.williams 3.1918034 0.3288389 9.706283 2.834878e-22 ## npType.pron 0.6148035 0.2767721 2.221335 2.632827e-02 ## voice.passive 0.7639485 0.2781885 2.746154 6.029846e-03 ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.1383258 0.2076053 -5.483124 4.178800e-08 ## clabel.williams 3.7710505 0.5675843 6.644036 3.052075e-11 ## npType.pron 0.7917211 0.3987366 1.985574 4.708063e-02 ## voice.passive 0.6496316 0.4149409 1.565600 1.174422e-01 ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.039786 0.19946 ## item (Intercept) 0.000000 0.00000 ## Groups Name Variance Std.Dev.<br />
## participant voice.passive 1.6482e+00 1.2838e+00 ## participant.1 npType.pron 5.8230e-01 7.6308e-01 ## participant.2 clabel.williams 5.0132e-15 7.0804e-08 ## participant.3 (Intercept) 1.6855e-01 4.1054e-01 ## item npType.pron 5.3942e-01 7.3445e-01 ## item.1 clabel.williams 1.6193e+00 1.2725e+00 ## item.2 (Intercept) 2.6237e-14 1.6198e-07 ## Solutions {#c7solns} ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: tapped ~ speechrate.slow + syntax.trans + (1 + syntax.trans +<br />
## speechrate.slow || participant) + (1 + syntax.trans + speechrate.slow ||<br />
## item) ## Data: tapped ## ## AIC BIC logLik deviance df.resid ## 330.0 371.2 -156.0 312.0 706 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4530 -0.2026 -0.0697 -0.0302 4.1061 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 2.011e+00 1.418e+00 ## participant.1 syntax.trans 0.000e+00 0.000e+00 ## participant.2 speechrate.slow 1.272e+01 3.566e+00 ## item (Intercept) 3.174e-01 5.634e-01 ## item.1 syntax.trans 4.284e-01 6.545e-01 ## item.2 speechrate.slow 5.115e-10 2.262e-05 ## Number of obs: 715, groups: participant, 23; item, 8 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -4.3843 0.6155 -7.123 1.06e-12 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#speechrate.slow--4.0897-1.0355--3.950-7.83e-05-syntax.trans-1.0909-0.4209-2.592-0.00955-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-spchr.-spechrt.slw-0.419-syntax.trns--0.156--0.068"><span class="toc-section-number">8.205</span> speechrate.slow -4.0897 1.0355 -3.950 7.83e-05 *<strong> ## syntax.trans 1.0909 0.4209 2.592 0.00955 </strong> ## â ## Signif. codes: 0 â<em><strong>â 0.001 â</strong>â 0.01 â</em>â 0.05 â.â 0.1 ââ 1 ## ## Correlation of Fixed Effects: ## (Intr) spchr. ## spechrt.slw 0.419<br />
## syntax.trns -0.156 -0.068</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><i class="fa fa-check"></i><b>9</b> Practical regression topics 2: Ordered factors, nonlinear effects, model predictions, post-hoc tests</a><ul>
<li class="chapter" data-level="9.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#ordered-factors"><i class="fa fa-check"></i><b>9.2</b> Ordered factors</a><ul>
<li class="chapter" data-level="9.2.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#orthogonal-polynomial-contrasts"><i class="fa fa-check"></i><b>9.2.1</b> Orthogonal polynomial contrasts</a></li>
<li class="chapter" data-level="9.2.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-an-ordered-factor-as-a-predictor"><i class="fa fa-check"></i><b>9.2.2</b> Using an ordered factor as a predictor</a></li>
<li class="chapter" data-level="9.2.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#further-points"><i class="fa fa-check"></i><b>9.2.3</b> Further points</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects"><i class="fa fa-check"></i><b>9.3</b> Nonlinear effects</a><ul>
<li class="chapter" data-level="9.3.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#splines-definition-and-benefits"><i class="fa fa-check"></i><b>9.3.1</b> Splines: Definition and benefits</a></li>
<li class="chapter" data-level="9.3.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#restricted-cubic-splines"><i class="fa fa-check"></i><b>9.3.2</b> Restricted cubic splines</a></li>
<li class="chapter" data-level="9.3.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#choosing-spline-complexity"><i class="fa fa-check"></i><b>9.3.3</b> Choosing spline complexity</a></li>
<li class="chapter" data-level="9.3.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#rcs-components"><i class="fa fa-check"></i><b>9.3.4</b> RCS components</a></li>
<li class="chapter" data-level="9.3.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-rcs-in-a-mixed-model"><i class="fa fa-check"></i><b>9.3.5</b> Using RCS in a mixed model</a></li>
<li class="chapter" data-level="9.3.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#random-slopes-for-rcs-terms"><i class="fa fa-check"></i><b>9.3.6</b> Random slopes for RCS terms</a></li>
<li class="chapter" data-level="9.3.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects-summary"><i class="fa fa-check"></i><b>9.3.7</b> Nonlinear effects: Summary</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-from-mixed-models"><i class="fa fa-check"></i><b>9.4</b> Predictions from mixed models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#making-model-predictions"><i class="fa fa-check"></i><b>9.4.1</b> Making Model Predictions</a></li>
<li class="chapter" data-level="9.4.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#simulation-based-predictions"><i class="fa fa-check"></i><b>9.4.2</b> Simulation-based predictions</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#post-hoc-mult-comp"><i class="fa fa-check"></i><b>9.5</b> Post-hoc tests and multiple comparisons</a></li>
<li class="chapter" data-level="9.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8indivpreds"><i class="fa fa-check"></i><b>9.6</b> Appendix: Model predictions for indiviudal participants</a><ul>
<li class="chapter" data-level="9.6.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-incorporating-offsets-for-individual-speakers"><i class="fa fa-check"></i><b>9.6.1</b> Predictions incorporating offsets for individual speakers</a></li>
<li class="chapter" data-level="9.6.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predicted-williams-effect-for-each-speaker"><i class="fa fa-check"></i><b>9.6.2</b> Predicted Williams effect for each speaker</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors"><i class="fa fa-check"></i><b>9.7</b> Appendix: Random slopes for factors</a></li>
<li class="chapter" data-level="9.8" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8solns"><i class="fa fa-check"></i><b>9.8</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="datasets-appendix.html"><a href="datasets-appendix.html"><i class="fa fa-check"></i><b>10</b> Appendix: Datasets and packages</a><ul>
<li class="chapter" data-level="10.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#engdata"><i class="fa fa-check"></i><b>10.1</b> <code>english</code> lexical decision and naming latencies</a></li>
<li class="chapter" data-level="10.2" data-path="datasets-appendix.html"><a href="datasets-appendix.html#dutch-regularity"><i class="fa fa-check"></i><b>10.2</b> Dutch <code id="dregdata">regularity</code></a></li>
<li class="chapter" data-level="10.3" data-path="datasets-appendix.html"><a href="datasets-appendix.html#european-french-phrase-medial-vowel-devoicing"><i class="fa fa-check"></i><b>10.3</b> European French phrase-medial vowel <code id="devdata">devoicing</code></a><ul>
<li class="chapter" data-level="10.3.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background"><i class="fa fa-check"></i><b>10.3.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="datasets-appendix.html"><a href="datasets-appendix.html#north-american-english-tapping"><i class="fa fa-check"></i><b>10.4</b> North American English <code id="tapdata">tapping</code></a><ul>
<li class="chapter" data-level="10.4.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-1"><i class="fa fa-check"></i><b>10.4.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="datasets-appendix.html"><a href="datasets-appendix.html#halfdata"><i class="fa fa-check"></i><b>10.5</b> <code>halfrhyme</code>: English half-rhymes</a></li>
<li class="chapter" data-level="10.6" data-path="datasets-appendix.html"><a href="datasets-appendix.html#givedata"><i class="fa fa-check"></i><b>10.6</b> <code>givenness</code> data: the Williams Effect</a><ul>
<li class="chapter" data-level="10.6.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-2"><i class="fa fa-check"></i><b>10.6.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="datasets-appendix.html"><a href="datasets-appendix.html#alternatives"><i class="fa fa-check"></i><b>10.7</b> <code id="altdata">alternatives</code></a><ul>
<li class="chapter" data-level="10.7.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-3"><i class="fa fa-check"></i><b>10.7.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="datasets-appendix.html"><a href="datasets-appendix.html#votdata"><i class="fa fa-check"></i><b>10.8</b> VOT</a><ul>
<li class="chapter" data-level="10.8.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-4"><i class="fa fa-check"></i><b>10.8.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="datasets-appendix.html"><a href="datasets-appendix.html#transitionsdata"><i class="fa fa-check"></i><b>10.9</b> Transitions</a></li>
<li class="chapter" data-level="10.10" data-path="datasets-appendix.html"><a href="datasets-appendix.html#packages"><i class="fa fa-check"></i><b>10.10</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods for Linguistic Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Practical regression topics 2: Ordered factors, nonlinear effects, model predictions, post-hoc tests</h1>
<p><strong>Preliminary code</strong></p>
<p>This code is needed to make other code below work:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra) <span class="co"># for grid.arrange() to print plots side-by-side</span>
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(languageR)
<span class="kw">library</span>(scales)
<span class="kw">library</span>(rms)
<span class="kw">library</span>(arm)
<span class="kw">library</span>(lsmeans)


## loads votMcGillLing620.csv from OSF project for Sonderegger et al. (2017) data
vot &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/qpab9/download&quot;</span>))

## loads halfrhymeMcGillLing620.csv from OSF project for Harder (2013) data
halfrhyme &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/37uqt/download&quot;</span>))

## loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data
alternatives &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/6qctp/download&quot;</span>))

## remove rows where response is NA (shouldn&#39;t be any...)
alternatives &lt;-<span class="st"> </span><span class="kw">filter</span>(alternatives, !<span class="kw">is.na</span>(prominence))

## add the &#39;shifted&#39; numeric variable
alternatives &lt;-<span class="st"> </span>alternatives %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">shifted =</span> -<span class="dv">1</span>*<span class="kw">as.numeric</span>(prominence)+<span class="dv">2</span>)

## relevel context to be in the intuitively plausible order
alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, <span class="dt">context=</span><span class="kw">as.ordered</span>(<span class="kw">factor</span>(context, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Alternative&quot;</span>, <span class="st">&quot;NoAlternative&quot;</span>, <span class="st">&quot;New&quot;</span>))))

## regularity dataset: 
## order levels for Auxiliary in their natural order
regularity$Auxiliary &lt;-<span class="st"> </span><span class="kw">factor</span>(regularity$Auxiliary, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;hebben&quot;</span>, <span class="st">&quot;zijnheb&quot;</span>, <span class="st">&quot;zijn&quot;</span>))

## loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data
givenness &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/q9e3a/download&quot;</span>))

givenness &lt;-<span class="st"> </span><span class="kw">mutate</span>(givenness,
                    <span class="dt">conditionLabel.williams =</span> arm::<span class="kw">rescale</span>(conditionLabel),
                    <span class="dt">clabel.williams =</span> arm::<span class="kw">rescale</span>(conditionLabel),
                    <span class="dt">npType.pronoun =</span> arm::<span class="kw">rescale</span>(npType),
                    <span class="dt">npType.pron =</span> arm::<span class="kw">rescale</span>(npType),
                    <span class="dt">voice.passive =</span> arm::<span class="kw">rescale</span>(voice),
                    <span class="dt">order.std =</span> arm::<span class="kw">rescale</span>(order),
                    <span class="dt">stressshift.num =</span> (<span class="kw">as.numeric</span>(stressshift) -<span class="st"> </span><span class="dv">1</span>)
)</code></pre></div>
<script src="js/hideOutput.js"></script>
<p><strong>Note</strong>: Answers to some questions/exercises not listed in text are in <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8solns">Solutions</a></p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">9.1</span> Introduction</h2>
<p>These notes cover several practical topics which come up in fitting regression models (mixed-effects or not):</p>
<ul>
<li><p>Ordered factors</p></li>
<li><p>Nonlinear effects</p></li>
<li><p>Making model predictions</p></li>
</ul>
<p>We also briefly discuss:</p>
<ul>
<li><p>Post-hoc tests</p></li>
<li><p>Multiple comparisons</p></li>
</ul>
<!-- TODO FUTURE: flesh out last two topics -->
</div>
<div id="ordered-factors" class="section level2">
<h2><span class="header-section-number">9.2</span> Ordered factors</h2>
<p>So far we have considered two types of variables as predictors in regression models.</p>
<p>First: <strong>numeric</strong> variables, which are continuous and <em>ordered</em>, meaning that there are âlargerâ and âsmallerâ values of the variable. When a numeric variable <span class="math inline">\(X\)</span> is used as a predictor in a regression model, it is assumed that a unit change always has the same effect on the response <span class="math inline">\(Y\)</span> (the âslopeâ): increasing <span class="math inline">\(X\)</span> from 1 to 2 has the same effect on <span class="math inline">\(Y\)</span> as increasing <span class="math inline">\(X\)</span> from 3 to 4.</p>
<p>Second: <strong>factors</strong>, which are discrete and unordered: no level of a factor is âlargerâ than other levels.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> When a factor is used as a predictor in a regression model, it is not assumed that changing from level 1 to level 2 has the same effect on the response as changing from level 2 to level 3.</p>
<p><strong>Ordered factors</strong> lie in between these two types of variables. They are discrete, like factors, but ordered, like continuous variables. It is assumed that level 1 is conceptually âless thanâ level 2, and so on (like a continuous variable), but it is not assumed that level 1 <span class="math inline">\(\to\)</span> 2 has the same effect as level 2 <span class="math inline">\(\to\)</span> 3 (like a factor). Ordered factors are often used for variables where the levels can be thought of as lying on a scale, and take on few values (~3â6).</p>
<div id="c8ex1" class="section level4 unnumbered">
<h4>Example 1</h4>
<p>Consider the <a href="datasets-appendix.html#dregdata">Dutch verb regularity dataset</a>, <code>regularity</code>.</p>
<ul>
<li><p>The <strong>response</strong> variable is <code>Regularity</code>: whether the verb has a regular or irregular past tense (1/0)</p></li>
<li><p>The <strong>predictor</strong> of interest is <code>Auxiliary</code>: which auxiliary a verb takes (<em>hebben</em>, <em>zijnheb</em>, or <em>zijn</em>)</p>
<ul>
<li>These levels have a natural order: <em>zijnheb</em> lies between the other two (because it means âthis verb can take either <em>zijn</em> or <em>hebben</em> as an auxiliary.â)</li>
</ul></li>
</ul>
<p>Thus, we convert <code>Auxiliary</code> to an ordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## make ordered factor for auxiliary
regularity$Auxiliary.ord &lt;-<span class="st"> </span><span class="kw">as.ordered</span>(regularity$Auxiliary)
<span class="kw">head</span>(regularity$Auxiliary.ord)</code></pre></div>
<pre><code>## [1] hebben  zijnheb zijn    hebben  hebben  hebben 
## Levels: hebben &lt; zijnheb &lt; zijn</code></pre>
<p>Note that the R output shows this is an ordered factor by showing the ordering of levels with &lt;. Compare to the R output for an unordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(regularity$Auxiliary)</code></pre></div>
<pre><code>## [1] hebben  zijnheb zijn    hebben  hebben  hebben 
## Levels: hebben zijnheb zijn</code></pre>
</div>
<div id="orthogonal-polynomial-contrasts" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Orthogonal polynomial contrasts</h3>
<p>What âconverting to an ordered factorâ (the <code>as.ordered</code> command) actually means is using a particular contrast coding scheme (See Sec. <a href="#contrast-coding-schemes"><strong>??</strong></a> for details): <em>orthogonal polynomial contrasts</em>. For three levels, the contrasts are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">contrasts</span>(regularity$Auxiliary.ord), <span class="dv">3</span>)</code></pre></div>
<pre><code>##          .L     .Q
## [1,] -0.707  0.408
## [2,]  0.000 -0.816
## [3,]  0.707  0.408</code></pre>
<p>The two contrasts correspond to âlinearâ and âquadraticâ <em>trends</em> (<code>.L</code> and <code>.Q</code> columns), which represent different kinds of relationship between the factor and the response, <strong>if</strong> the levels were treated as equally-spaced (and continuous):</p>
<ul>
<li><p>Linear: how much does relationship with response look like a line?</p></li>
<li><p>Quadratic: how much does relationship with the response look like a parabola?</p></li>
</ul>
<p>The contrasts for <span class="math inline">\(k=3\)</span> can be visualized as:</p>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>For ordered factors with more levels, further contrasts correspond to a cubic trend, and so on. For a four-level ordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">contr.poly</span>(<span class="dv">4</span>)</code></pre></div>
<pre><code>##              .L   .Q         .C
## [1,] -0.6708204  0.5 -0.2236068
## [2,] -0.2236068 -0.5  0.6708204
## [3,]  0.2236068 -0.5 -0.6708204
## [4,]  0.6708204  0.5  0.2236068</code></pre>
<p>the three contrasts capture:</p>
<ul>
<li><p>L: how much does relationship with response look like a line?</p></li>
<li><p>Q: `` `` a parabola?</p></li>
<li><p>C: `` `` a cubic function?</p></li>
</ul>
<p>Visually, the contrasts for four levels (<span class="math inline">\(k=4\)</span>) are: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>where axes have been removed for clarity.</p>
</div>
<div id="using-an-ordered-factor-as-a-predictor" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Using an ordered factor as a predictor</h3>
<p>For <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8ex1">our example</a>, we predict <code>Regularity</code> as a function of the verbâs auxiliary (<code>Auxiliary.ord</code>) using a logistic regression:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regularity.mod<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(Regularity ~<span class="st"> </span>Auxiliary.ord, <span class="dt">data=</span>regularity, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(regularity.mod<span class="fl">.1</span>)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Regularity ~ Auxiliary.ord, family = &quot;binomial&quot;, 
##     data = regularity)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8307   0.6438   0.6438   0.6438   1.3537  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.51944    0.17029   3.050  0.00229 ** 
## Auxiliary.ord.L -1.32507    0.33145  -3.998 6.39e-05 ***
## Auxiliary.ord.Q  0.02954    0.25324   0.117  0.90713    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 750.12  on 699  degrees of freedom
## Residual deviance: 719.92  on 697  degrees of freedom
## AIC: 725.92
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The linear trend has large effect size and is very significant (<span class="math inline">\(p&lt;0.0001\)</span>), while the quadratic trend has low effect size and is not significant (<span class="math inline">\(p=0.91\)</span>). This means the model predicts an essentially linear relationship between <code>Auxiliary.ord</code> and <code>Regularity</code>.</p>
<p>This example illustrates one use for ordered factorsâdimensionality reduction, by reducing the number of contrasts needed to represent a factorâs effect. If we wanted to simplify the model, it would be justified at this point to drop the quadratic trend, and just use the linear contrast to represent the effect of <code>Auxiliary.ord</code>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> We wouldnât gain much by doing so here (just one fewer regression coefficient), but when dealing with ordered factors with 5+ levels, dimensionality reduction can make model fitting and interpretation much easier.</p>
<!-- Note that the ordered -->
<!-- * More specific information than "significant effect of `Auxiliary`" -->
<!--     * Result of model comparison, dropping `Auxiliary.ord`: $p < 0.0001$ -->
<!-- ---  -->
<p>To visualize the predicted relationship between auxiliary and regularity probability (in log-odds and probability space):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## set up a dataframe which varies in Auxiliary.ord:
newdata &lt;-<span class="st"> </span><span class="kw">with</span>(regularity, <span class="kw">data.frame</span>(<span class="dt">Auxiliary.ord =</span> <span class="kw">unique</span>(Auxiliary.ord)))

## predictions at each level of Auxiliary.ord (in log-odds)
newdata$pred &lt;-<span class="st"> </span><span class="kw">predict</span>(regularity.mod<span class="fl">.1</span>, <span class="dt">newdata=</span>newdata)

## predictions in probability 
newdata$pred.p &lt;-<span class="st"> </span><span class="kw">invlogit</span>(newdata$pred)

regularityPlot1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Auxiliary.ord, <span class="dt">y=</span>pred), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Auxiliary (log-odds)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted % regular (logit)&quot;</span>)

regularityPlot2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Auxiliary.ord, <span class="dt">y=</span>pred.p), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Auxiliary (probability)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted % regular&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent)

<span class="kw">grid.arrange</span>(regularityPlot1, regularityPlot2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The predicted trend is âlinearâ in the sense that the three points lie on a line. This replicates the pattern in the empirical data (in log-odds):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">summDf &lt;-<span class="st"> </span>regularity %&gt;%<span class="st"> </span><span class="kw">group_by</span>(Auxiliary) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">logit</span>(<span class="kw">mean</span>(Regularity==<span class="st">&#39;regular&#39;</span>)))

<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Auxiliary,<span class="dt">y=</span>mean), <span class="dt">data=</span>summDf) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;log-odds (Regularity==regular)&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-10-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="further-points" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Further points</h3>
<p>Some other variables that could be represented by ordered factors:</p>
<ul>
<li><p>Number of onset consonants in a syllable (Ex: <em>1</em> &lt; <em>2</em> &lt; <em>3</em>)</p></li>
<li><p>Socio-economic status (SES) (Ex: <em>low</em> &lt; <em>low/mid</em> &lt; <em>high/mid</em> &lt; <em>high</em>)</p></li>
<li><p>Strength of prosodic boundary (<em>word</em> &lt; <em>small phrase</em> &lt; <em>large phrase</em> &lt; <em>utterance</em>)</p></li>
<li><p>L2 level (<em>no knowledge</em> &lt; <em>beginner</em> &lt; <em>intermediate</em> &lt; <em>advanced</em>)</p></li>
</ul>
<p>Note that ordered factors are just factors with a particular (sensible) contrast coding scheme. A model where a conceptually âorderedâ variable is entered as a non-ordered factor is not incorrect, the results just may be harder to interpret.</p>
<p>When using ordered factors in a mixed-effects model: because ordered factors are still factors, the issues with including factors in a mixed model discussed in Section <a href="#c6factorsissue"><strong>??</strong></a> arise. These issues (frequently overparametrized models, uncorrelated random effects) and solutions are very similar for ordered factors, and are discussed in an Appendix (Sec. <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors">9.7</a>).</p>
<div id="example-2-1" class="section level4 unnumbered">
<h4>Example 2</h4>
<!-- (LING 620: this can be skipped.) -->
<p>For <a href="datasets-appendix.html#altdata">the <code>alternatives</code> data</a>, we model the probability of stress shifting (<code>shifted</code>) in a mixed-effects logistic regression, with:</p>
<ul>
<li><p>Fixed effect: <code>context</code></p></li>
<li><p>Random effects: by-item and by-participant intercept and slope</p></li>
</ul>
<p>This predictor is conceptually ordered, with levels <em>Alternative</em> &lt; <em>NoAlternative</em> &lt; <em>New</em> (see <a href="datasets-appendix.html#altdata">the dataset description</a> to understand why). So we can convert it to an ordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, <span class="dt">context=</span><span class="kw">as.ordered</span>(<span class="kw">factor</span>(context, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Alternative&quot;</span>, <span class="st">&quot;NoAlternative&quot;</span>, <span class="st">&quot;New&quot;</span>))))</code></pre></div>
<p>It turns out (see Section <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors">9.7</a>) that this model gives perfect random-effect correlations if the random effect structure <code>(1+context|participant) + (1|context|item)</code> is used, so we instead use uncorrelated random effects. To do so, we first convert <code>context</code> to two numeric contrasts, which correspond to the linear and quadratic trends:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, 
                       <span class="dt">contextL =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">2</span>],
                       <span class="dt">contextQ =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">3</span>])</code></pre></div>
<p>To fit and summarize the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternativesMod2 &lt;-<span class="st"> </span><span class="kw">glmer</span>(shifted ~<span class="st"> </span>context +<span class="st"> </span>
<span class="st">                            </span>(<span class="dv">1</span>+contextL +<span class="st"> </span>contextQ||item) +<span class="st"> </span>
<span class="st">                            </span>(<span class="dv">1</span>+contextL +<span class="st"> </span>contextQ||participant), 
                          <span class="dt">data=</span>alternatives, 
                          <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, 
                          <span class="dt">control=</span><span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>)) 

<span class="kw">summary</span>(alternativesMod2)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: shifted ~ context + (1 + contextL + contextQ || item) + (1 +  
##     contextL + contextQ || participant)
##    Data: alternatives
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##    652.4    692.3   -317.2    634.4      613 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.8990 -0.5248 -0.2875  0.5782  3.5101 
## 
## Random effects:
##  Groups        Name        Variance  Std.Dev. 
##  participant   contextQ    2.272e-15 4.766e-08
##  participant.1 contextL    2.174e-01 4.663e-01
##  participant.2 (Intercept) 6.526e-01 8.078e-01
##  item          contextQ    1.723e-01 4.151e-01
##  item.1        contextL    9.398e-01 9.694e-01
##  item.2        (Intercept) 4.925e-01 7.018e-01
## Number of obs: 622, groups:  participant, 18; item, 12
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.0609     0.3040  -3.490 0.000483 ***
## context.L    -1.9482     0.3748  -5.198 2.01e-07 ***
## context.Q     0.2936     0.2196   1.337 0.181273    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) cntx.L
## context.L 0.103        
## context.Q 0.048  0.108</code></pre>
<blockquote>
<p><strong>Questions</strong>:</p>
<p>What does the model predict about:</p>
<ul>
<li><p>The overall effect of <code>context</code>? (What kind of relationship with log-odds of stress shift?)</p></li>
<li><p>By-participant and by-item variability in the <code>context</code> effect?</p></li>
</ul>
</blockquote>
<p>Comparing the predicted overall effect (for an âaverageâ participant/item) to the empirical means (probability of stress shift for each <code>context</code> value):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## get model predictions at each level of &#39;context&#39;
newdata &lt;-<span class="st"> </span><span class="kw">with</span>(alternatives, <span class="kw">data.frame</span>(<span class="dt">context =</span> <span class="kw">unique</span>(context)))

## re.form = NA : get predictions at &quot;average&quot; speaker and item values
newdata$pred &lt;-<span class="st"> </span><span class="kw">invlogit</span>(<span class="kw">predict</span>(alternativesMod2, <span class="dt">newdata=</span>newdata, <span class="dt">re.form=</span><span class="ot">NA</span>))
summDf2 &lt;-<span class="st"> </span>alternatives %&gt;%<span class="st"> </span><span class="kw">group_by</span>(context) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">pred=</span><span class="kw">mean</span>(shifted))
predEmpDf &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">data.frame</span>(newdata, <span class="dt">type=</span><span class="st">&#39;Predicted&#39;</span>), 
                   <span class="kw">data.frame</span>(summDf2, <span class="dt">type=</span><span class="st">&#39;Empirical&#39;</span>))

<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>context, <span class="dt">y=</span>pred), <span class="dt">data=</span>predEmpDf) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>type),<span class="dt">size=</span><span class="dv">3</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Context&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Percent shifted stress&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="dv">0</span>), <span class="dt">lty=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="dv">1</span>), <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-14-1.png" width="480" style="display: block; margin: auto;" /> The modelâs prediction (significant linear trend but not quadratic trend) makes sense. The relationship is basically linearâand would look more so in log-odds space.</p>
<p>Interestingly, the empirical data shows substantial variability among participants and items, many of which do not show a linear trend:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives %&gt;%<span class="st"> </span><span class="kw">group_by</span>(context, participant) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">mean</span>(shifted)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>context,<span class="dt">y=</span>mean)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Percent shifted (by partic)&quot;</span>) +
<span class="st">  </span><span class="kw">facet_wrap</span>(~participant) +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives %&gt;%<span class="st"> </span><span class="kw">group_by</span>(context, item) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">mean</span>(shifted)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>context,<span class="dt">y=</span>mean)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Percent shifted (by item)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~item) +<span class="st">  </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li><p>What kind of variability is observed, among participants and among items? (In overall probability of stress shifting? In the <code>condition</code> effect?)</p></li>
<li><p>How do the by-participant and by-item random effect estimates of the model reflect these patterns of variability?</p></li>
</ul>
</blockquote>
<!-- --- -->
<!-- ((Q4M: I couldn't find the original code, but going through the slides it appears that I was able to rebuild it)) -->
<!-- ```{r, echo=F} -->
<!-- halfrhyme <- mutate(halfrhyme, -->
<!--                     conditionLabel =  -->
<!--                       factor(conditionLabel, levels = c("bad", "voice", "good"))) -->
<!-- halfrhyme$conditionLabel <- as.ordered(halfrhyme$conditionLabel) -->
<!-- halfrhyme$clabel.c1 <- model.matrix(~conditionLabel, halfrhyme)[,2] -->
<!-- halfrhyme$clabel.c2 <- model.matrix(~conditionLabel, halfrhyme)[,3] -->
<!-- ``` -->
<!-- ```{r} -->
<!-- summary(lmer(rhymeRating ~ conditionLabel +  -->
<!--                (1|participant) +  -->
<!--                (0+clabel.c1|participant) +  -->
<!--                (0+clabel.c2|participant),  -->
<!--              data=halfrhyme)) -->
<!-- ``` -->
<!-- * $\implies$ significant, **positive** lienar and quadratic trends -->
<!--     * Mostly linear (why?) -->
</div>
</div>
</div>
<div id="nonlinear-effects" class="section level2">
<h2><span class="header-section-number">9.3</span> Nonlinear effects</h2>
<p>So far we have always assumed that continuous variables have a relationship with the response that is <em>linear</em>âwell-described by a straight line. In reality this is often not the case.</p>
<p>For example, consider the effect of word frequency (<code>WrittenFrequency</code>) on lexical decision reaction time (<code>RTlexdec</code>) in <a href="datasets-appendix.html#engdata">the <code>english</code> dataset</a>. Plotting this relationship using a nonlinear smoother:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>RTlexdec), <span class="dt">data=</span>english) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>() +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.15</span>, <span class="dt">size=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-17-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>it is clear the relationship is not linear. Certainly RT decreases as a function of frequency, but the relationship is not a straight line. We would like to model this kind of relationship in a regression model.</p>
<p>There are several options for modeling such <em>nonlinear functions</em>, including:</p>
<ul>
<li><p><em>Polynomials</em>, such as a parabola or cubic equation. These are fitted in R by including terms like <code>poly(x,2)</code> in a model (for a quadratic equation).</p></li>
<li><p><em>Natural cubic splines</em>, which you fit in R using <code>ns()</code> (e.g. <code>ns(x,3)</code> for a spline with one âbendâ)</p></li>
</ul>
<p>We will use a related family of functions: <em>restricted cubic splines</em> (RCS), which are fitted using the <code>rcs</code> function in the <code>rms</code> package. Some discussion of RCS is given by <span class="citation">Baayen (<a href="#ref-baayen2008analyzing">2008</a>)</span>, and more technical discussion by <span class="citation">Harrell (<a href="#ref-harrell2001regression">2001</a>)</span>.</p>
<div id="splines-definition-and-benefits" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Splines: Definition and benefits</h3>
<p>While polynomials are probably familiar to you (from high school math: lines, parabolas, etc.) splines are probably not. What are splines, and why should we use them instead of polynomial functionsâwhich are easier to understand?</p>
<p>Intuitively a spline is a function made up of several polynomials glued together (âpiecewise-definedâ), constrained to be âsmoothâ at the places where the polynomial pieces connect (called <em>knots</em>). The glued-together polynomials can be small pieces of parabolas, lines, and so on.</p>
<p>Splines are like polynomials, but better behaved: they avoid interpolation errors and <a href="https://en.wikipedia.org/wiki/Runge%27s_phenomenon">Rungeâs phenomenon</a>. They are better than polynomials especially at the very high and low values of a variable being modeled: polynomials tend to âblow upâ when extrapolated beyond the range of the variable in the data, while splines can be constrained to grow only linearly.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>A polynomial is made up of <em>components</em> for different orders: you add together multiples of <span class="math inline">\(1\)</span>, <span class="math inline">\(x\)</span>, <span class="math inline">\(x^2\)</span>, and so on to approximate a function. Splines also approximate functions, but using a different (and more complex) set of components. There are many ways of defining splines (hence <code>bs</code>, <code>ns</code>, <code>rcs</code>, and other R functions), of which we consider only RCS.</p>
</div>
<div id="restricted-cubic-splines" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Restricted cubic splines</h3>
<p>Intuitively, a restricted cubic spline with <span class="math inline">\(k\)</span> <em>knots</em> describes a curve with <span class="math inline">\(k-2\)</span> âbendsâ. Thus, the simplest possible RCS has three knots, and describes a curve with one bend (analogous to a quadratic polynomial). An RCS term for a variable <code>x</code> is be added to a regression model in R using the notation <code>rcs(x,k)</code>. For example, here we fit three models of reaction time as a function of word frequency, using progressively more complex splines (<span class="math inline">\(k= 3, 5, 7\)</span>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.rcs3 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">3</span>), <span class="dt">data=</span>english)
mod.rcs5 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">5</span>), <span class="dt">data=</span>english)
mod.rcs7 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">7</span>), <span class="dt">data=</span>english)</code></pre></div>
<p>The predictions of these models are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">english$pred.rcs3 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rcs3)
english$pred.rcs5 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rcs5)
english$pred.rcs7 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rcs7)

rcs3PredPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>pred.rcs3), <span class="dt">data=</span>english) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RT (predicted)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Written Frequency</span><span class="ch">\n\n</span><span class="st">Oversmooths&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;k = 3&quot;</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))

rcs5PredPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>pred.rcs5), <span class="dt">data=</span>english) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RT (predicted)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Written Frequency</span><span class="ch">\n\n</span><span class="st">&quot;</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;k = 5&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))

rcs7PredPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>pred.rcs7), <span class="dt">data=</span>english) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RT (predicted)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Written Frequency</span><span class="ch">\n\n</span><span class="st">Overfits&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;k = 7&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))

<span class="kw">grid.arrange</span>(rcs3PredPlot, rcs5PredPlot, rcs7PredPlot, <span class="dt">ncol =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-19-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Comparing to the plot of the empirical data above, we can see visually that <span class="math inline">\(k=3\)</span> is not complex enough (âunderfitsâ) and <span class="math inline">\(k=7\)</span> is too complex (âoverfitsâ).</p>
</div>
<div id="choosing-spline-complexity" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Choosing spline complexity</h3>
<p>This example leads to the question: how to decide on a value of <span class="math inline">\(k\)</span> to model a nonlinear effect, and whether a nonlinear effect is justified at all?</p>
<div id="method-1-visual-inspection" class="section level4">
<h4><span class="header-section-number">9.3.3.1</span> Method 1: Visual inspection</h4>
<p>Make a plot of the predictor versus the response, using a nonlinear smoother, and eyeball the number of bends in the relationship between the two variables.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>For example, for the RT~frequency example, it looks like there are two bends:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>RTlexdec), <span class="dt">data=</span>english) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>() +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.15</span>, <span class="dt">size=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-20-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>so we would choose <span class="math inline">\(k=4\)</span>.</p>
</div>
<div id="method-2-data-driven" class="section level4">
<h4><span class="header-section-number">9.3.3.2</span> Method 2: Data-driven</h4>
<p>Fit models with different values of <span class="math inline">\(k\)</span>, as well as a linear model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.linear &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span>WrittenFrequency, <span class="dt">data=</span>english)
mod.rcs3 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">3</span>), <span class="dt">data=</span>english)
mod.rcs4 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">4</span>), <span class="dt">data=</span>english)
mod.rcs5 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">5</span>), <span class="dt">data=</span>english)
mod.rcs6 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">6</span>), <span class="dt">data=</span>english)</code></pre></div>
<p>then use model comparison to see at what value of <span class="math inline">\(k\)</span> adding complexity no longer gives a better fit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mod.linear, mod.rcs3, mod.rcs4, mod.rcs5, mod.rcs6, mod.rcs7)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ WrittenFrequency
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 3)
## Model 3: RTlexdec ~ rcs(WrittenFrequency, 4)
## Model 4: RTlexdec ~ rcs(WrittenFrequency, 5)
## Model 5: RTlexdec ~ rcs(WrittenFrequency, 6)
## Model 6: RTlexdec ~ rcs(WrittenFrequency, 7)
##   Res.Df    RSS Df Sum of Sq       F    Pr(&gt;F)    
## 1   4566 91.194                                   
## 2   4565 89.602  1   1.59256 81.8914 &lt; 2.2e-16 ***
## 3   4564 89.056  1   0.54555 28.0526 1.236e-07 ***
## 4   4563 88.862  1   0.19449 10.0011  0.001575 ** 
## 5   4562 88.807  1   0.05496  2.8259  0.092822 .  
## 6   4561 88.699  1   0.10793  5.5497  0.018526 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The significant difference between the linear model and the <span class="math inline">\(k=3\)</span> model means that a nonlinear effect is justified. Increasing <span class="math inline">\(k\)</span> from 3 to 4 significantly improves the model, as does increasing from 4 to 5, but increasing from 5 to 6 doesnât (<span class="math inline">\(p=0.09\)</span>). So we would choose a nonlinear relationship with <span class="math inline">\(k=5\)</span>. (Note that this is different from what we chose by visual inspection, <span class="math inline">\(k=4\)</span>, but the relationships for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span> turn out to be very similar.)</p>
<p><strong>Practical note</strong></p>
<p>Choosing <span class="math inline">\(k\)</span> is a <a href="#lm-model-comparison">model selection problem</a>, and like all model selection techniques the resulting model needs to be sanity-checked against the empirical data. In practice, models with very high <span class="math inline">\(k\)</span> often are âbetterâ than a model with lower <span class="math inline">\(k\)</span> by model comparison via <code>anova()</code>, even when the value of <span class="math inline">\(k\)</span> makes no sense given visual inspection. For example, a model with 9 knots significantly improves on the <span class="math inline">\(k=5\)</span> model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.rcs9&lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">9</span>), <span class="dt">data=</span>english)
<span class="kw">anova</span>(mod.rcs5, mod.rcs9)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ rcs(WrittenFrequency, 5)
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 9)
##   Res.Df    RSS Df Sum of Sq    F  Pr(&gt;F)  
## 1   4563 88.862                            
## 2   4559 88.664  4   0.19759 2.54 0.03796 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>but there are obviously not 7 clear bends in the empirical relationship between <code>WrittenFrequency</code> and <code>RTlexdec</code>. In practice, you might use the lowest value of <span class="math inline">\(k\)</span> for which model comparison shows a significant improvement (over <span class="math inline">\(k-1\)</span>) <em>and</em> the predicted relationship is sensical.</p>
<p>Another option to choose a good value of <span class="math inline">\(k\)</span> would be to use another method for model comparison, rather than the F test (what <code>anova</code> does by default for linear regressions). BIC (Sec. <a href="linear-regression.html#non-nested-model-comparison">3.146.1</a>) may be a good choice, as it tends to penalize extra terms more highly than other <a href="#lm-model-comparison">methods weâve considered</a> (e.g.Â AIC, F test, <a href="#c4lrt">LR test for logistic regressions</a>). For the current example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">BIC</span>(mod.linear, mod.rcs3, mod.rcs4, mod.rcs5, mod.rcs6, mod.rcs9)</code></pre></div>
<pre><code>##            df       BIC
## mod.linear  3 -4889.713
## mod.rcs3    4 -4961.764
## mod.rcs4    5 -4981.235
## mod.rcs5    6 -4982.795
## mod.rcs6    7 -4977.194
## mod.rcs9   10 -4959.256</code></pre>
<p>choosing the model with lowest BIC would give <span class="math inline">\(k=5\)</span>, a sensible value.</p>
</div>
</div>
<div id="rcs-components" class="section level3">
<h3><span class="header-section-number">9.3.4</span> RCS components</h3>
<p>Examining the model with <span class="math inline">\(k=5\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod.rcs5)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = RTlexdec ~ rcs(WrittenFrequency, 5), data = english)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.46761 -0.11624 -0.00069  0.10278  0.53806 
## 
## Coefficients:
##                                              Estimate Std. Error t value
## (Intercept)                                  6.742126   0.016089 419.059
## rcs(WrittenFrequency, 5)WrittenFrequency    -0.030765   0.005694  -5.404
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;   -0.159054   0.037966  -4.189
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;   0.761531   0.183525   4.149
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;&#39; -0.810377   0.241481  -3.356
##                                             Pr(&gt;|t|)    
## (Intercept)                                  &lt; 2e-16 ***
## rcs(WrittenFrequency, 5)WrittenFrequency    6.87e-08 ***
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;   2.85e-05 ***
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;  3.39e-05 ***
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;&#39; 0.000798 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1396 on 4563 degrees of freedom
## Multiple R-squared:  0.2098, Adjusted R-squared:  0.2091 
## F-statistic: 302.9 on 4 and 4563 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>there are four rows, with regression coefficients (etc.) describing the nonlinear relationship. For a linear relationship it was clear what the coefficient means: the change in <span class="math inline">\(Y\)</span> for a unit change in <span class="math inline">\(X\)</span>. <strong>What do the coefficients for an RCS mean?</strong></p>
<div id="short-answer" class="section level4">
<h4><span class="header-section-number">9.3.4.1</span> Short answer</h4>
<p>The short answer is: these coefficients are hard to interpret, and itâs fine to mostly ignore them, increase interpreting the nonlinear effect of <span class="math inline">\(X\)</span> as follows:</p>
<ul>
<li><p>Plotting model predictions to see the predicted effect</p></li>
<li><p>To assess whether (the nonlinear effect of) <span class="math inline">\(X\)</span> is significant, report a model comparison with a model without the nonlinear term.</p></li>
</ul>
<p>For the current example: code to visualize the nonlinear relationship is above, and you could report this in a paper as:</p>
<blockquote>
<p>âThere was a nonlinear effect of frequency on reaction time, modeled using a restricted cubic spline with 5 knots (<span class="math inline">\(F_{4567,4} = 303\)</span>, <span class="math inline">\(p&lt;0.0001\)</span>), where the number of knots was chosen by picking the value which gave lowest BIC.â</p>
</blockquote>
<p>If you want to also report that a <em>nonlinear</em> effect in particular was justified, you could add a sentence like</p>
<blockquote>
<p>âA nonlinear relationship is clear from the empirical data (Fig. X), and significantly improves on a linear effect of frequency (<span class="math inline">\(F_{4566,3}=40\)</span>, <span class="math inline">\(p&lt;0.0001\)</span>).â<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
</blockquote>
<p>The model comparisons used in these reports are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.int &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>english)
<span class="kw">anova</span>(mod.linear, mod.rcs5)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ WrittenFrequency
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 5)
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1   4566 91.194                                  
## 2   4563 88.862  3    2.3326 39.926 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mod.int, mod.rcs5)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ 1
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 5)
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1   4567 112.456                                  
## 2   4563  88.862  4    23.594 302.88 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="c8longanswer" class="section level4">
<h4><span class="header-section-number">9.3.4.2</span> Long answer: Components of nonlinear functions</h4>
<!-- (LING 620: This could be skipped if short on time.) -->
<p>The rows of the regression table actually refer to âcomponentsâ of the nonlinear function being modeled by the spline. To get a sense for what that means, letâs consider an example: the <code>WrittenFrequency</code> variable, which is roughly normally distributed with range <span class="math inline">\(\approx 0-12\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(english$WrittenFrequency)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-27-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>A nonlinear function of this variable could be included in a regression using a polynomial term, or an RCS term.</p>
<p>The first few components for a <strong>polynomial</strong> term would be: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-28-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Note that for degree <span class="math inline">\(k&gt;2\)</span> if <code>WrittenFrequency</code> goes below 0 or above 10, the component increases or decreases very quickly (as <span class="math inline">\(x^k\)</span>).</p>
<p>In comparison, the components for restricted cubic splines <strong>for this data</strong> for <span class="math inline">\(k=4\)</span> are: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-29-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>And for <span class="math inline">\(k=5\)</span> the components are: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-30-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The four coefficients of the model above (with a <span class="math inline">\(k=5\)</span> RCS term for <code>WrittenFrequency</code>) refer to these four components. The predicted effect of <code>WrittenFrequency</code> on reaction time is: <span class="math display">\[
-0.03 \cdot \text{component1} -0.016 \cdot \text{component2} + 
0.761 \cdot \text{component3} -0.810 \cdot \text{component4}
\]</span> where -0.03, etc. are the coefficient values.</p>
<p>From the last two figures, we can see that each RCS component only grows <strong>linearly</strong> if extrapolated beyond the endpoints of the data. This is a useful property which gives better generalization on new data, when new values of the independent variable (here, <code>WrittenFrequency</code>) are observed.</p>
</div>
</div>
<div id="using-rcs-in-a-mixed-model" class="section level3">
<h3><span class="header-section-number">9.3.5</span> Using RCS in a mixed model</h3>
<p>As an example, we model the effect of speech rate deviation (<code>speakingRateDev</code>) on log-transformed voice onset time (<code>logVOT</code>) for <a href="datasets-appendix.html#votdata">the VOT dataset</a>.</p>
<p>The empirical effect seems clearly non-linear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev, <span class="dt">y=</span>logVOT), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.15</span>, <span class="dt">size=</span><span class="dv">1</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;log(VOT)&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-31-1.png" width="384" style="display: block; margin: auto;" /> with speech rate having little effect on VOT in sufficiently fast speech.</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li>What <span class="math inline">\(k\)</span> would we choose by visual inspection?</li>
</ul>
</blockquote>
<div id="exercise-5" class="section level4 unnumbered">
<h4>Exercise</h4>
<p>To choose <span class="math inline">\(k\)</span> in a data-driven fashion, try fitting these models using just random intercepts (no slopes) of <code>Speaker</code> and <code>Word</code>, and compare them using model comparison:</p>
<ul>
<li><p><code>VOT ~ speakingRateDev</code> (linear model)</p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 3\)</span></p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 4\)</span></p></li>
</ul>
</div>
</div>
<div id="random-slopes-for-rcs-terms" class="section level3">
<h3><span class="header-section-number">9.3.6</span> Random slopes for RCS terms</h3>
<p>Fitting a âmaximalâ mixed-effects model with random slopes for RCS terms often results in issues that are by now familiar (Sec. <a href="#c6factorsissue"><strong>??</strong></a>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">votMod.corr &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span><span class="kw">rcs</span>(speakingRateDev, <span class="dv">3</span>) +<span class="st"> </span>(<span class="dv">1</span>+<span class="kw">rcs</span>(speakingRateDev, <span class="dv">3</span>) |<span class="st"> </span>Word) +<span class="st"> </span>(<span class="dv">1</span>+<span class="kw">rcs</span>(speakingRateDev,<span class="dv">3</span>)|Speaker), <span class="dt">data=</span>vot)</code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl =
## control$checkConv, : unable to evaluate scaled gradient</code></pre>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl =
## control$checkConv, : Model failed to converge: degenerate Hessian with 1
## negative eigenvalues</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(votMod.corr)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: logVOT ~ rcs(speakingRateDev, 3) + (1 + rcs(speakingRateDev,  
##     3) | Word) + (1 + rcs(speakingRateDev, 3) | Speaker)
##    Data: vot
## 
## REML criterion at convergence: 4595.4
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.2267 -0.6003  0.0509  0.6510  3.0740 
## 
## Random effects:
##  Groups   Name                                    Variance  Std.Dev. Corr 
##  Word     (Intercept)                             0.0000000 0.00000       
##           rcs(speakingRateDev, 3)speakingRateDev  0.0170030 0.13040    NaN
##           rcs(speakingRateDev, 3)speakingRateDev&#39; 0.0235881 0.15358    NaN
##  Speaker  (Intercept)                             0.0253568 0.15924       
##           rcs(speakingRateDev, 3)speakingRateDev  0.0022754 0.04770   0.16
##           rcs(speakingRateDev, 3)speakingRateDev&#39; 0.0001518 0.01232   0.12
##  Residual                                         0.1450546 0.38086       
##       
##       
##       
##  -1.00
##       
##       
##  -0.96
##       
## Number of obs: 4728, groups:  Word, 424; Speaker, 21
## 
## Fixed effects:
##                                         Estimate Std. Error t value
## (Intercept)                              3.99525    0.03700 107.966
## rcs(speakingRateDev, 3)speakingRateDev  -0.15343    0.01908  -8.043
## rcs(speakingRateDev, 3)speakingRateDev&#39;  0.10948    0.01828   5.989
## 
## Correlation of Fixed Effects:
##             (Intr) rc(RD,3)RD
## rcs(RD,3)RD  0.230           
## rc(RD,3)RD&#39; -0.175 -0.837    
## convergence code: 0
## unable to evaluate scaled gradient
## Model failed to converge: degenerate  Hessian with 1 negative eigenvalues</code></pre>
<p>non-convergence, and perfect correlations between random effects. There are a couple probable causes, both of which came up when we have hit these issues before:</p>
<ol style="list-style-type: decimal">
<li><p>The model may be overparametrizedâthe random-effect structure is too complex for the dataset size.</p></li>
<li><p>The predictors are not centered (see Section <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#rcs-components">9.3.4</a>)âwhich results in substantial avoidable collinearity. (See the lower-right entry of <code>Correlation of fixed effects</code>: the correlation between the two RCS components is high (<span class="math inline">\(-0.83\)</span>).)</p></li>
</ol>
<p>There are two corresponding ways to deal with these issues if they come up.</p>
<div id="option-1-fit-a-model-without-random-effect-correlations" class="section level4 unnumbered">
<h4>Option 1: Fit a model without random-effect correlations</h4>
<p>To do this, we need to extract the individual components of the RCS term as numeric variablesâthis is analogous to extracting the contrasts as numeric variables for a factor, to use uncorrelated random effects.</p>
<p>This code extracts the two components for the spline with 3 knots, and adds them to the dataframe as columns:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vot$rateDev.comp1 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>, <span class="dt">inclx=</span><span class="ot">TRUE</span>)[,<span class="dv">1</span>]
vot$rateDev.comp2 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>, <span class="dt">inclx=</span><span class="ot">TRUE</span>)[,<span class="dv">2</span>]</code></pre></div>
<p>The function <code>rcspline.eval</code> gives a matrix of components, <code>nk=3</code> selects <span class="math inline">\(k\)</span>, <code>[,1]</code> or <code>[,2]</code> selects the matrix column number, and <code>inclx=TRUE</code> adds the linear component in addition to the nonlinear components. <!-- (I"m not sure why this isn't the default.) --></p>
<p>We can then fit the model without random-effect correlations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">votMod.nocorr &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span>rateDev.comp1 +<span class="st"> </span>rateDev.comp2 +<span class="st"> </span>
<span class="st">                        </span>(<span class="dv">1</span>+rateDev.comp1 +<span class="st"> </span>rateDev.comp2 ||<span class="st"> </span>Word) +<span class="st"> </span>
<span class="st">                        </span>(<span class="dv">1</span>+rateDev.comp1 +<span class="st"> </span>rateDev.comp2||Speaker), 
                      <span class="dt">data=</span>vot)</code></pre></div>
<p>The model now converges. (This may not be kosher, thoughâthere are conceptual issues with using uncorrelated random effects for non-centered variables <span class="citation">(Barr, Levy, Scheepers, &amp; Tily, <a href="#ref-barr2013random">2013</a>)</span>.</p>
<!-- TODO FUTURE: check if that's right, or just something Roger has said in online posts..? get a better ref -->
<p>The model is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(votMod.nocorr)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: 
## logVOT ~ rateDev.comp1 + rateDev.comp2 + ((1 | Word) + (0 + rateDev.comp1 |  
##     Word) + (0 + rateDev.comp2 | Word)) + ((1 | Speaker) + (0 +  
##     rateDev.comp1 | Speaker) + (0 + rateDev.comp2 | Speaker))
##    Data: vot
## 
## REML criterion at convergence: 4475.1
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.3005 -0.5865  0.0448  0.6312  3.3378 
## 
## Random effects:
##  Groups    Name          Variance  Std.Dev.
##  Word      (Intercept)   2.914e-02 0.170708
##  Word.1    rateDev.comp1 2.327e-04 0.015255
##  Word.2    rateDev.comp2 9.418e-06 0.003069
##  Speaker   (Intercept)   2.540e-02 0.159365
##  Speaker.1 rateDev.comp1 1.358e-03 0.036856
##  Speaker.2 rateDev.comp2 0.000e+00 0.000000
##  Residual                1.394e-01 0.373399
## Number of obs: 4728, groups:  Word, 424; Speaker, 21
## 
## Fixed effects:
##               Estimate Std. Error t value
## (Intercept)    4.07384    0.03913 104.113
## rateDev.comp1 -0.10347    0.01391  -7.436
## rateDev.comp2  0.03810    0.01237   3.080
## 
## Correlation of Fixed Effects:
##             (Intr) rtDv.1
## rateDv.cmp1  0.176       
## rateDv.cmp2 -0.259 -0.646</code></pre>
<p>Note the significant <code>rateDev.comp1</code> and <code>rateDev.comp2</code> terms, which we can think of as the âlinearâ and ânonlinearâ terms.</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li><p>What does the fact that both are significant tell us?</p></li>
<li><p>How do people differ in the speech rate effect? (Examine the random slope terms.)</p></li>
</ul>
</blockquote>
<!-- ### Exercise -->
<!-- * Fit a model with **linear** effect of `speechRateDev` (standardized)  -->
<!--     * Random slopes, no correlations -->
<!-- * Check that `votMod.nocorr` is a significant improvement -->
<!-- * Extra: Fit a model with a nonlinear effect with $k = 5$ (again: random slopes, no correlations) -->
<!--       * Show that it doesn't significantly improve on `mod2` -->
<p><strong>Detour</strong>: Visualizing nonlinear effects</p>
<p>It would be nice to visualize the predicted nonlinear effect from a model, but this turns out to be slightly tricky and is not shown here. <!-- (TODO in a future year: actually show how to do this in an appendix.) --></p>
<p>An easier approximation, which is usually a good idea anyway (as a sanity check that the empirical data shows the qualitative effect predicted by the model), is to plot a smooth over the empirical data using a spline with the same number of knots as the RCS term in the model.</p>
<p>For example, to visualize the effect of an RCS term with 3 knots for a <code>VOT ~ speech rate</code> model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev, <span class="dt">y=</span>logVOT), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&#39;lm&#39;</span>, <span class="dt">formula=</span>y~splines::<span class="kw">ns</span>(x,<span class="dv">3</span>)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;VOT (log)&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-36-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="option-2-use-centered-predictors" class="section level4 unnumbered">
<h4>Option 2: Use centered predictors</h4>
<p>Note that RCS components are not centered, by defaultâas can be seen in the plots of these components for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span> in Sec. <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8longanswer">9.3.4.2</a>, where each component is positive for all values of <code>WrittenFrequency</code>. Less problematically, they are not orthogonalâfor example, components 1 and 2 are clearly correlated (for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span>), as component 2 is a line for <code>WrittenFrequency</code>&gt;6.</p>
<p>We can address both issues by using the <em>principal components</em> of the RCS components: a linear transformation which makes them centered and orthogonal. You can extract the principal components in R using the <code>pc=TRUE</code> flag:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vot$rateDev.pcomp1 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>,<span class="dt">inclx=</span><span class="ot">TRUE</span>, <span class="dt">pc=</span><span class="ot">TRUE</span>)[,<span class="dv">1</span>]
vot$rateDev.pcomp2 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>, <span class="dt">inclx=</span><span class="ot">TRUE</span>, <span class="dt">pc=</span><span class="ot">TRUE</span>)[,<span class="dv">2</span>]</code></pre></div>
<p>These are still restricted cubic spline components (they look like glued-together polynomials, etc.), but they look different from before. For example, the first and second components for <span class="math inline">\(k=3\)</span> for <code>speakingRateDev</code> for the <code>vot</code> data are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rcsPlot1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev,<span class="dt">y=</span>rateDev.pcomp1), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;First component&quot;</span>)

rcsPlot2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev,<span class="dt">y=</span>rateDev.pcomp2), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Second component&quot;</span>)

<span class="kw">grid.arrange</span>(rcsPlot1, rcsPlot2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-38-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>(Compare to the plots for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span> above.) For our purposes, the most important difference is that the PCs are centered.</p>
<p>A model using the PC versions of the RCS components, with full maximal random-effect structure (correlations between random effects included), would be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">votMod.corr<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span>rateDev.pcomp1 +<span class="st"> </span>rateDev.pcomp2 +<span class="st"> </span>
<span class="st">                          </span>(<span class="dv">1</span>+rateDev.pcomp1 +<span class="st"> </span>rateDev.pcomp2|Word) +<span class="st"> </span>
<span class="st">                          </span>(<span class="dv">1</span>+rateDev.pcomp1 +<span class="st"> </span>rateDev.pcomp2|Speaker), 
                        <span class="dt">data=</span>vot)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(votMod.corr<span class="fl">.2</span>)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: logVOT ~ rateDev.pcomp1 + rateDev.pcomp2 + (1 + rateDev.pcomp1 +  
##     rateDev.pcomp2 | Word) + (1 + rateDev.pcomp1 + rateDev.pcomp2 |  
##     Speaker)
##    Data: vot
## 
## REML criterion at convergence: 4467.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.2831 -0.5951  0.0451  0.6310  3.3031 
## 
## Random effects:
##  Groups   Name           Variance  Std.Dev. Corr       
##  Word     (Intercept)    0.0277041 0.16645             
##           rateDev.pcomp1 0.0001375 0.01172   0.84      
##           rateDev.pcomp2 0.0011219 0.03349  -0.87 -0.46
##  Speaker  (Intercept)    0.0253885 0.15934             
##           rateDev.pcomp1 0.0007723 0.02779  -0.24      
##           rateDev.pcomp2 0.0029008 0.05386   0.02 -0.98
##  Residual                0.1394170 0.37339             
## Number of obs: 4728, groups:  Word, 424; Speaker, 21
## 
## Fixed effects:
##                 Estimate Std. Error t value
## (Intercept)     4.103607   0.037700 108.848
## rateDev.pcomp1  0.057963   0.008032   7.217
## rateDev.pcomp2 -0.113209   0.021463  -5.275
## 
## Correlation of Fixed Effects:
##             (Intr) rtDv.1
## ratDv.pcmp1 -0.145       
## ratDv.pcmp2 -0.011 -0.427</code></pre>
<p>Crucially, this model makes the same predictions as <code>votMod.corr</code>âthe only difference is in how the nonlinear function of <code>speechRateDev</code> is coded (analogously to using different contrast coding schemes for a factor).<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> However, the new model converged without issue, while <code>votMod.corr</code> did notâlikely because we are now representing the <code>speechRateDev</code> effect using centered and orthogonal variables.</p>
<p>Note that there is less collinearity in <code>votMod.corr.2</code> than in <code>votMod.corr</code>âthe correlations in <code>Correlation of Fixed Effects</code> are closer to zero.</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li>Why is this?</li>
</ul>
</blockquote>
</div>
</div>
<div id="nonlinear-effects-summary" class="section level3">
<h3><span class="header-section-number">9.3.7</span> Nonlinear effects: Summary</h3>
<p>To summarize:</p>
<ul>
<li><p>Nonlinear effects can be used to capture non-linear relationships between the response and (a) predictor(s). Such relationships are common, so <strong>using nonlinear effects is often appropriate.</strong></p>
<ul>
<li>Modeling nonlinear relationships <strong>somehow</strong> is more important than the actual method used!</li>
</ul></li>
<li><p>In terms of a method: we recommend using splines to code nonlinear effects. (Here we have demonstrated restricted cubic splines, but other flavors are OK.)</p>
<ul>
<li><p>Pro: Splines are well-behaved and should lead to better generalization to new data.</p></li>
<li><p>Con: Spline components are tricky to interpret, and (in R) sometimes tricky to work with.</p></li>
</ul></li>
<li><p>Using polynomials to model nonlinear effects is OK, but dispreferred.</p>
<ul>
<li><p>Pro: Polynomial terms are easy to interpret</p></li>
<li><p>Con: Polynomial functions are not well-behaved (interpolation issues, etc.) and can make bad predictions on new data.</p></li>
<li><p>Regardless, polynomials are commonly used, e.g.Â in <a href="http://www.danmirman.org/gca">Growth Curve Analysis</a> (which is basically mixed-effects models with polynomials used to model a nonlinear relationship).</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="predictions-from-mixed-models" class="section level2">
<h2><span class="header-section-number">9.4</span> Predictions from mixed models</h2>
<p>To visualize the predictions of mixed models, it is useful to make:</p>
<ul>
<li><p><em>partial effect plots</em>: These show the modelâs prediction as one predictor is changed, holding others constant.</p></li>
<li><p>predictions for different levels of grouping factors (e.g.Â different participants): in the overall value (âinterceptâ), partial effect of a given predictor (âslopeâ), or something more complex.</p></li>
</ul>
<p>Decent software (in 2018) exists for making such predictions from mixed models, such as:</p>
<ul>
<li><p>The <a href="https://cran.r-project.org/web/packages/effects/index.html"><code>effects</code></a> package (see <a href="https://cran.r-project.org/web/packages/effects/vignettes/effectsMethods.pdf">vignette</a>)</p></li>
<li><p>The <a href="http://www.strengejacke.de/sjPlot/sjp.lmer/"><code>sjPlot</code></a> package</p></li>
<li><p><code>plotLMER.fnc()</code> in <code>languageR</code></p></li>
</ul>
<p>Nonetheless, it is also useful to know how to make such predictions yourself, as pre-existing packages make various assumptions, and donât always give exactly what you want.</p>
<div id="making-model-predictions" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Making Model Predictions</h3>
<!-- (LING 620: This could be skipped if short on time, given the existence of the packages above.) -->
<p>Visualizing predictions from a model in R always involves three steps:</p>
<ol style="list-style-type: decimal">
<li><p>Make a new dataframe of values you want to predict at</p></li>
<li><p>Get predictions of model for these values</p></li>
<li><p>Make plots of the predictions</p></li>
</ol>
<div id="example-13" class="section level4 unnumbered">
<h4>Example</h4>
<p>Letâs use a basic model of the <code>acoustics</code> correlate of stress shifting, for <a href="datasets-appendix.html#givedata">the <code>givenness</code> data</a>:<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(acoustics ~<span class="st"> </span>conditionLabel*npType +<span class="st"> </span>voice +
<span class="st">                 </span>(<span class="dv">1</span> +<span class="st"> </span>clabel.williams*npType.pron ||<span class="st"> </span>item) +
<span class="st">                 </span>(<span class="dv">1</span> +<span class="st"> </span>clabel.williams*npType.pron +<span class="st"> </span>voice.passive|<span class="st"> </span>participant),
             <span class="dt">data=</span>givenness)</code></pre></div>
</div>
<div id="predictions-only-no-confidence-intervals" class="section level4 unnumbered">
<h4>Predictions only (no confidence intervals)</h4>
<p><strong>Step 1</strong>: Make dataframe of new values we want to predict the response for:</p>
<p>The <code>expand.grid()</code> function can be used to make all possible combinations of multiple predictors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata &lt;-<span class="st"> </span><span class="kw">with</span>(givenness,
                <span class="kw">expand.grid</span>(<span class="dt">conditionLabel=</span><span class="kw">unique</span>(conditionLabel),
                            <span class="dt">npType=</span><span class="kw">unique</span>(npType), 
                            <span class="dt">voice=</span><span class="kw">unique</span>(voice)))

newdata</code></pre></div>
<pre><code>##   conditionLabel  npType   voice
## 1       Williams    full passive
## 2       Contrast    full passive
## 3       Williams pronoun passive
## 4       Contrast pronoun passive
## 5       Williams    full  active
## 6       Contrast    full  active
## 7       Williams pronoun  active
## 8       Contrast pronoun  active</code></pre>
<p><strong>Step 2</strong>: Make model predictions</p>
<p>If you want predictions based on <strong>fixed effects only</strong> (no random effects), use the <code>predict()</code> function with the flag <code>re.form=NA</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata$prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, <span class="dt">newdata=</span>newdata, <span class="dt">re.form=</span><span class="ot">NA</span>)</code></pre></div>
<p><strong>Step 3</strong>: Visualize</p>
<p>The modelâs predictions for <code>acoustics</code> as a function of the three predictors (condition label, NP type, voice) are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conditionLabel, <span class="dt">y=</span>prediction), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType,<span class="dt">group=</span>npType)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~voice) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted value&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-44-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>These predictions are for an average participant, and âaverage itemâ: meaning, the average over <code>voice</code>=active and <code>voice</code>=passive items.</p>
<p>To make a âpartial effect plotâ of just the effect of <code>conditionLabel</code>, say, we can simply average over the other variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata %&gt;%<span class="st"> </span><span class="kw">group_by</span>(conditionLabel) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">pred=</span><span class="kw">mean</span>(prediction), <span class="dt">dummy=</span><span class="dv">1</span>) %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conditionLabel, <span class="dt">y=</span>pred)) +<span class="st"> </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group=</span>dummy)) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted value&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
</div>
<div id="predictions-with-confidence-intervals" class="section level4 unnumbered">
<h4>Predictions with confidence intervals</h4>
<p>Generally we want to show model predictions with a measure of uncertainty, such as confidence intervals (CIs)</p>
<p>Obtaining CIs turns out to be less straightforward than obtaining just model predictions, because there is more than one way to define âuncertaintyâ. For example: do we want to take into account uncertainty from just (uncertainty about the) fixed effects? What about random effects? And how? (You can google âconfidence intervals prediction lme4â to get a sense of the issue.)</p>
<p>You can get confidence intervals relatively simply using just the uncertainty in the fixed effects, as illustrated in Ben Bolkerâs <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions">FAQ</a>. Applied to our data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## &quot;design matrix&quot; for fitted model
mm &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="kw">terms</span>(mod1), <span class="kw">data.frame</span>(<span class="dt">acoustics=</span><span class="dv">1</span>, newdata))

## SE of prediction, just from uncertainty in fixed effects and residual variance:
newdata$SE &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(mm %*%<span class="st"> </span><span class="kw">tcrossprod</span>(<span class="kw">vcov</span>(mod1), mm)))</code></pre></div>
<p>Note that the computed standard error (<code>SE</code>) does not take into account variation among participants, etc. It can be thought of as âthe error for an average subject and itemâ.</p>
<p>Multiplying these standard errors by 1.96 can be used to construct 95% confidence intervals (again, calculated from the fixed-effect errors only), which can be visualized:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conditionLabel, <span class="dt">y=</span>prediction, <span class="dt">ymin=</span>prediction<span class="fl">-1.96</span>*SE, <span class="dt">ymax=</span>prediction<span class="fl">+1.96</span>*SE), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType), <span class="dt">width=</span><span class="fl">0.3</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~voice) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted value&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-47-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="extracting-predicted-random-effects" class="section level4 unnumbered">
<h4>Extracting predicted random effects</h4>
<p>Extracting partial effects, and âoverallâ values (intercepts) for each participant (etc.) is also of interest. Some examples are given in previous chapters, and further examples are shown in an Appendix (Sec. <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8indivpreds">9.6</a>).</p>
<!-- TODO FUTURE: link to previous chapter examples -->
</div>
</div>
<div id="simulation-based-predictions" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Simulation-based predictions</h3>
<p>The examples seen so far calculate model predictions and confidence intervals using the terms of the fitted modelsâfixed-effect coefficient values and SEs, and so on. This requires writing some code (and some knowledge), but the predictions/CIs are computed quickly.</p>
<p>The more general solution, which requires little code or knowledgeâbut can be very slowâis computing model predictions and confidence intervals using simulation. Parametric or semi-parametric bootstrapping, as implemented in the <code>bootMer</code> package or the <code>simulate</code> function (from the <code>arm</code> package), can be used to estimate the probability distribution over values of <strong>any</strong> quantity predicted by the modelâincluding a particular combination of predictor values, as in a partial-effect plot. This distribution can be used to obtain a âpredictionâ and â95% confidence intervalâ by computing e.g.Â the median and the 2.5%/97.5% quantiles. The downside is that simulation can be very computationally intensiveâyou essentially have to re-fit the model many (1000+) times to get reasonable estimates.</p>
<p>Useful examples are given in:</p>
<ul>
<li><p>A <a href="https://cran.r-project.org/web/packages/merTools/vignettes/Using_predictInterval.html">vignette</a> by J. Knowles and C. Frederick</p></li>
<li><p>An <a href="https://www.r-bloggers.com/confidence-intervals-for-prediction-in-glmms/">R-bloggers</a> page by grumble10.</p></li>
</ul>
<p>An example of a simple simulation-based method is shown for LMMs in Section <a href="#lmm-simulation-confint"><strong>??</strong></a>.</p>
</div>
</div>
<div id="post-hoc-mult-comp" class="section level2">
<h2><span class="header-section-number">9.5</span> Post-hoc tests and multiple comparisons</h2>
<p>The <em>multiple comparisons</em> problem refers to the issue that the more hypotheses you test, the less meaningful the <span class="math inline">\(p\)</span>-values are. (If we test 20 hypotheses with <span class="math inline">\(\alpha\)</span> level <span class="math inline">\(0.05\)</span>, we will find 1 significant effect by chance, on average.)</p>
<p>A solution commonly used is to correct the <span class="math inline">\(p\)</span>-values for âmultiple comparisonsâ before comparing to <span class="math inline">\(\alpha\)</span> (e.g.Â 0.05). Many such correction methods exist, including:</p>
<ul>
<li>The <em>Bonferroni</em> method: multiply <span class="math inline">\(p\)</span> by the number of tests conducted
<ul>
<li>This method has low power, and should never be usedâsee <code>?p.adjust.methods</code> in R.</li>
</ul></li>
<li>The <em>Holm</em> method
<ul>
<li>Less conservative than Bonferroni</li>
</ul></li>
<li><p><em>Tukey HSD</em> (âHonestly Significant Differenceâ)</p></li>
<li><p><em>FDR</em> (âFalse Discovery Rateâ), a.k.a. the Benjamini &amp; Hochberg (BH) method</p></li>
</ul>
<p>Not correcting for multiple comparisons when doing many statistical tests can easily lead to spurious resultsâthis is often called âdata dredgingâ or âp-hackingâ.</p>
<p>Which multiple comparison method should be used? There is a trade-off between methods with higher power and lower Type I error. Reasonable and widely-used methods are Holm and Tukey HSD.</p>
<p>One place where the multiple comparisons problem comes up is for factors with multiple (&gt;2) levels. When a model includes a categorical variable <span class="math inline">\(X\)</span> with <span class="math inline">\(k\)</span> levels, we know how to:</p>
<ol style="list-style-type: decimal">
<li><p>Ask <span class="math inline">\(k-1\)</span> questions about how it affects the response: <strong>contrast coding</strong> (discussed in Sec. <a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding">6.6</a>)</p></li>
<li><p>Ask âdoes <span class="math inline">\(X\)</span> affect the response?â: <strong>likelihood ratio test</strong> (discussed in Sec. <a href="#c5mlf"><strong>??</strong></a>)</p></li>
</ol>
<p>It is customary to not correct for multiple comparisons for (1)âand indeed, for any set of predictors in multiple regression models in general.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<p>But often, we would like to ask more than <span class="math inline">\(k-1\)</span> questions, such as:</p>
<ul>
<li><p>âis level 1 diff from level 2?â âLevel 2 from level 3?â âLevel 1 from level 3?â</p></li>
<li><p>âis there any Williams effect when <code>npType</code> = pronoun?â (for the <code>givenness</code> data)</p></li>
</ul>
<p>Such questions can be answered via hypothesis tests using <em>post-hoc tests</em>.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> These are also called âdifference in means testsâ, or other terms. It is common in ANOVA analyses to use âpost-hoc testsâ to refer to âtesting which levels of a factor <span class="math inline">\(X\)</span> are actually different from each other, after an ANOVA showed that <span class="math inline">\(X\)</span> has a significant effect.â</p>
<p>When we ask more than <span class="math inline">\(k-1\)</span> questions, the questions are not independent, so we <strong>need</strong> to correct for multiple comparisons.</p>
<div id="example-14" class="section level4 unnumbered">
<h4>Example</h4>
<p>As an example, consider the <code>alternatives</code> dataset, where we will fit a mixed-effects logistic regression, with:</p>
<ul>
<li><p>Response: <code>prominence</code></p></li>
<li><p>Predictor: <code>context</code> (<em>NoAlternative</em>, <em>Alternative</em>, <em>None</em>)</p></li>
<li><p>Random effects: maximal, without random-effect correlations</p></li>
</ul>
<p>The empirical pattern is:</p>
<pre><code>##         context prominence.ID         se
## 1   Alternative     0.4146341 0.03449301
## 2 NoAlternative     0.7380952 0.03041268
## 3           New     0.8502415 0.02486184</code></pre>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-48-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>First, we make <code>context1</code>, <code>context2</code> numerical predictors, corresponding to the two Helmert contrasts:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">contrasts</span>(alternatives$context) &lt;-<span class="st"> </span><span class="kw">contr.helmert</span>(<span class="dv">3</span>)
alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, 
                       <span class="dt">context1 =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">2</span>],
                       <span class="dt">context2 =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">3</span>])</code></pre></div>
<p>The model is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.nocorr &lt;-<span class="st"> </span><span class="kw">glmer</span>(prominence ~<span class="st"> </span>context +<span class="st"> </span>
<span class="st">                      </span>(<span class="dv">1</span>+context1 +<span class="st"> </span>context2||participant) +<span class="st"> </span>
<span class="st">                      </span>(<span class="dv">1</span>+context1 +<span class="st"> </span>context2||item), 
                    <span class="dt">data=</span>alternatives, 
                    <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, 
                    <span class="dt">control=</span><span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>))
<span class="kw">summary</span>(mod.nocorr)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## prominence ~ context + (1 + context1 + context2 || participant) +  
##     (1 + context1 + context2 || item)
##    Data: alternatives
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##    646.8    686.7   -314.4    628.8      613 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.5763 -0.5676  0.2484  0.5564  2.9286 
## 
## Random effects:
##  Groups        Name        Variance Std.Dev.
##  participant   (Intercept) 0.67379  0.8208  
##  participant.1 context1    0.06545  0.2558  
##  participant.2 context2    0.00000  0.0000  
##  item          (Intercept) 0.56035  0.7486  
##  item.1        context1    0.00000  0.0000  
##  item.2        context2    0.29399  0.5422  
## Number of obs: 622, groups:  participant, 18; item, 12
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   1.1533     0.3199   3.605 0.000312 ***
## context1      0.8716     0.1375   6.338 2.32e-10 ***
## context2      0.7014     0.1909   3.673 0.000240 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) cntxt1
## context1 0.054        
## context2 0.129  0.018</code></pre>
<p>The two significant fixed-effect coefficients can be interpreted as:</p>
<ul>
<li><p><em>NoAlternative</em> &gt; <em>Alternative</em> (in terms of probability of prominence shift)</p></li>
<li><p><em>New</em> &gt; <em>NoAlternative</em>/<em>Alternative</em></p></li>
</ul>
<p>But what about <em>NoAlternative</em> versus <em>New</em>, or <em>Alternative</em> versus <em>New</em>?</p>
<p>The <code>lsmeans</code> package (now superceded by the <code>emmeans</code> package, with expanded functionality) is invaluable for carrying out post-hoc tests <span class="citation">(Lenth, <a href="#ref-lsmeans">2016</a>, <a href="#ref-emmeans">2018</a>)</span>. In this case, we examine every difference between two levels:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.lsmeans &lt;-<span class="st"> </span>lsmeans::<span class="kw">lsmeans</span>(mod.nocorr, ~context)
<span class="kw">pairs</span>(mod.lsmeans)</code></pre></div>
<pre><code>##  contrast                     estimate        SE df z.ratio p.value
##  Alternative - NoAlternative -1.743220 0.2750211 NA  -6.338  &lt;.0001
##  Alternative - New           -2.975683 0.5915409 NA  -5.030  &lt;.0001
##  NoAlternative - New         -1.232463 0.5866488 NA  -2.101  0.0896
## 
## Results are given on the log odds ratio (not the response) scale. 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>This reports an estimated difference between each pair of levels (here, in log-odds), with an associated <span class="math inline">\(p\)</span>-value, corrected for multiple comparisons using the Tukey HSD method.</p>
<p>We can conclude that: <em>Alternative</em> <span class="math inline">\(&lt;\)</span> <em>NoAlternative</em> <span class="math inline">\(\leq\)</span> <em>New</em> (at <span class="math inline">\(\alpha=0.05\)</span>).</p>
<p>Post-hoc tests can also be used for:</p>
<ul>
<li><p>Checking whether particular subsets of levels differ from others</p></li>
<li><p>Checking whether <span class="math inline">\(X\)</span> has an effect, for each level of <span class="math inline">\(Y\)</span> (e.g., âis the Williams effect significant for <strong>each</strong> level of <code>npType</code>?â, for the <code>givenness</code> data)</p></li>
</ul>
<p>For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp &lt;-<span class="st"> </span>lsmeans::<span class="kw">lsmeans</span>(mod1, ~conditionLabel |<span class="st"> </span>npType)
<span class="kw">pairs</span>(temp)</code></pre></div>
<pre><code>## npType = full:
##  contrast              estimate         SE    df t.ratio p.value
##  Contrast - Williams -0.1694650 0.08214115 53.57  -2.063  0.0440
## 
## npType = pronoun:
##  contrast              estimate         SE    df t.ratio p.value
##  Contrast - Williams -0.4691477 0.09227544 22.89  -5.084  &lt;.0001
## 
## Results are averaged over the levels of: voice</code></pre>
<p>You can read more in the very useful <a href="http://cran.r-project.org/web/packages/lsmeans/vignettes/using-lsmeans.pdf">vignette</a> for <code>lsmeans</code> (or <a href="https://cran.r-project.org/web/packages/emmeans/vignettes/">for <code>emmeans</code></a>).</p>
<p><strong>Exercise</strong></p>
<ul>
<li><p>For <a href="datasets-appendix.html#dregdata">the <code>regularity</code> data</a>, fit a logistic regression of <code>regularity</code> as a function of <code>Auxiliary</code></p></li>
<li><p>Use <code>lsmeans</code> to test: is there a difference between</p>
<ul>
<li><p><em>zijn</em>/<em>hebben</em></p></li>
<li><p><em>zijnheb</em>/<em>hebben</em></p></li>
<li><p><em>zijn</em>/<em>zijnheb</em></p></li>
</ul></li>
</ul>
<p>?</p>
<!-- TODO FUTURE: "other readings" section -->
</div>
</div>
<div id="c8indivpreds" class="section level2">
<h2><span class="header-section-number">9.6</span> Appendix: Model predictions for indiviudal participants</h2>
<p>A couple additional examples of predictions from <code>mod1</code>:</p>
<div id="predictions-incorporating-offsets-for-individual-speakers" class="section level3">
<h3><span class="header-section-number">9.6.1</span> Predictions incorporating offsets for individual speakers</h3>
<p>Get predictions for every speaker, for every combination of fixed-effect values: <!-- ((Q4M: Below in `predict` the slides make reference to `mod3.full`. This model doesn't appear in the code and so I have temporarily placed `mod1` as standby since this model is the only one discussed))   --> <!-- ((I can't get this code to work without fairly substantial edits, and as a result this following figures aren't identical)) --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata &lt;-<span class="st"> </span><span class="kw">with</span>(givenness,
                <span class="kw">expand.grid</span>(<span class="dt">participant=</span><span class="kw">unique</span>(participant),
                            <span class="dt">item=</span><span class="kw">unique</span>(item),
                            <span class="dt">conditionLabel=</span><span class="kw">unique</span>(conditionLabel),
                            <span class="dt">npType=</span><span class="kw">unique</span>(npType), 
                            <span class="dt">voice=</span><span class="kw">unique</span>(voice),
                            <span class="dt">voice.passive=</span><span class="kw">unique</span>(voice.passive),
                            <span class="dt">clabel.williams=</span><span class="kw">unique</span>(clabel.williams),
                            <span class="dt">npType.pron=</span><span class="kw">unique</span>(npType.pron)))

newdata$prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, <span class="dt">newdata=</span>newdata, <span class="dt">re.form=</span>~(<span class="dv">1</span>|participant))</code></pre></div>
<p>These predictions can be used to obtain each speakerâs intercept (fixed effect + by-speaker intercept), and visualize their distribution across speakers:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">byParticInt &lt;-<span class="st"> </span>newdata %&gt;%<span class="st"> </span><span class="kw">group_by</span>(participant) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">intercept =</span> <span class="kw">mean</span>(prediction))

<span class="kw">ggplot</span>(byParticInt, <span class="kw">aes</span>(intercept)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker&#39;s intercept&quot;</span>) </code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-54-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>We can conclude that speakers differ substantially in their baseline rate of stress shifting (<code>acoustics</code>) value, but they are always more likely to <em>not</em> shift (negative value).</p>
</div>
<div id="predicted-williams-effect-for-each-speaker" class="section level3">
<h3><span class="header-section-number">9.6.2</span> Predicted Williams effect for each speaker</h3>
<p>One way to do this:</p>
<ul>
<li>Get overall Williams effect (across participant and items)</li>
</ul>
<!-- ((Q4M: Again, slides reference `mod3.full`, which I have replaced with `mod1` as a hotfit)) -->
<!-- ((Q4M: Also, slides reference `givenness2`, which isn't loaded (but is the name of the csv loaded into `givenness` -- so I used this data frame))) -->
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata2 &lt;-<span class="st"> </span><span class="kw">with</span>(givenness,
                 <span class="kw">expand.grid</span>(<span class="dt">conditionLabel=</span><span class="kw">unique</span>(conditionLabel),
                             <span class="dt">npType=</span><span class="kw">unique</span>(npType), 
                             <span class="dt">voice=</span><span class="st">&#39;active&#39;</span>))
newdata2$prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, newdata2, <span class="dt">re.form=</span><span class="ot">NA</span>)

overall &lt;-<span class="st"> </span><span class="kw">mean</span>((newdata2[<span class="dv">1</span>,<span class="st">&#39;prediction&#39;</span>]-newdata2[<span class="dv">2</span>,<span class="st">&#39;prediction&#39;</span>]),
                (newdata2[<span class="dv">3</span>,<span class="st">&#39;prediction&#39;</span>]-newdata2[<span class="dv">4</span>,<span class="st">&#39;prediction&#39;</span>]))</code></pre></div>
<ul>
<li>Then, add each participantâs offset (random slope): <!-- ((Q4M: Figure not identical due to above mentioned issues)) --></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">slopes &lt;-<span class="st"> </span><span class="kw">ranef</span>(mod1)$participant[[<span class="st">&#39;clabel.williams&#39;</span>]]
byParticSlope &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">participant=</span><span class="kw">rownames</span>(<span class="kw">ranef</span>(mod1)$participant),
                             <span class="dt">williamsEffect=</span>overall +<span class="st"> </span>slopes)</code></pre></div>
<p>Visualize distribution of participant effects:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(byParticSlope, <span class="kw">aes</span>(williamsEffect)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker&#39;s Williams effect&quot;</span>) </code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-57-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="c8slopesForFactors" class="section level2">
<h2><span class="header-section-number">9.7</span> Appendix: Random slopes for factors</h2>
<p>Ordered factors have the same issues when fitting random slopes with uncorrelated random-effect structures that we have seen for factors with multiple levels.</p>
<p>As an example, using the <code>alternatives</code> data, we fit a model with a fixed effect of <code>context</code>, coded as an ordered factor (<em>Alternative</em> &lt; <em>NoAlternative</em> &lt; <em>New</em>)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## relevel context to be in the intuitively plausible order
alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, <span class="dt">context=</span><span class="kw">as.ordered</span>(<span class="kw">factor</span>(context, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Alternative&quot;</span>, <span class="st">&quot;NoAlternative&quot;</span>, <span class="st">&quot;New&quot;</span>))))</code></pre></div>
<p>and with by-participant random effects only.</p>
<p><strong>Exercise</strong>: fit this model</p>
<p>Solution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(alternativesMod1)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## shifted ~ context + (1 + context | item) + (1 + context | participant)
##    Data: alternatives
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##    654.6    721.1   -312.3    624.6      607 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5891 -0.5648 -0.2148  0.5550  3.5691 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev. Corr       
##  participant (Intercept) 0.65857  0.8115              
##              context.L   0.23473  0.4845   -0.11      
##              context.Q   0.05022  0.2241   -0.27 -0.93
##  item        (Intercept) 0.67813  0.8235              
##              context.L   1.98312  1.4082   0.62       
##              context.Q   0.58874  0.7673   0.61  1.00 
## Number of obs: 622, groups:  participant, 18; item, 12
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.25159    0.36521  -3.427  0.00061 ***
## context.L   -2.33728    0.58091  -4.024 5.73e-05 ***
## context.Q    0.06461    0.36381   0.178  0.85905    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) cntx.L
## context.L 0.567        
## context.Q 0.461  0.760</code></pre>
<p>The high random-effect correlations here suggest we should try a model with uncorrelated random effects.</p>
<p>As weâve seen before, fitting a model with standard notation for uncorrelated random effects (<code>||</code>) doesnât work:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(shifted ~<span class="st"> </span>context +<span class="st"> </span>
<span class="st">       </span>(<span class="dv">1</span>+context||participant) +
<span class="st">       </span>(<span class="dv">1</span>+context||participant), 
     <span class="dt">data=</span>alternatives)</code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio
##  - Rescale variables?</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: 
## shifted ~ context + ((1 | participant) + (0 + context | participant)) +  
##     ((1 | participant) + (0 + context | participant))
##    Data: alternatives
## REML criterion at convergence: 704.8152
## Random effects:
##  Groups        Name                 Std.Dev. Corr     
##  participant   (Intercept)          0.00000           
##  participant.1 contextAlternative   0.17163           
##                contextNoAlternative 0.10918  0.83     
##                contextNew           0.04853  0.83 1.00
##  participant.2 (Intercept)          0.00000           
##  participant.3 contextAlternative   0.10457           
##                contextNoAlternative 0.08913  0.67     
##                contextNew           0.03927  0.68 1.00
##  Residual                           0.41044           
## Number of obs: 622, groups:  participant, 18
## Fixed Effects:
## (Intercept)    context.L    context.Q  
##     0.33134     -0.30660      0.08701  
## convergence code 0; 1 optimizer warnings; 0 lme4 warnings</code></pre>
<p><strong>Exercise</strong>: carry out the same procedure to implement uncorrelated random effects as we saw for multi-level factors in Section <a href="mixed-effects-logistic-regression.html#c7appendix2">8.175.1</a></p>
<ul>
<li><p>Manually make numeric variables for each contrast, called <code>context1</code>, <code>context2</code></p></li>
<li><p>Fit a model with uncorrelated random effects using these numeric variables</p></li>
<li><p>Check using a model comparison whether the models with and without correlations significantly differ</p></li>
</ul>
</div>
<div id="c8solns" class="section level2">
<h2><span class="header-section-number">9.8</span> Solutions</h2>
<p><strong>Q</strong>: What does the model predict about:</p>
<ul>
<li><p>The overall effect of <code>context</code>? (What kind of relationship with log-odds of stress shift?)</p></li>
<li><p>By-participant and by-item variability in the <code>context</code> effect?</p></li>
</ul>
<p><strong>A</strong>: There is a significant linear effect of the ordered predictor linear, but the quadratic component does not reach significance. There is substantial by-item and by-participant variability with respect to both linear and quadratic effect.</p>
<hr />
<p><strong>Q</strong>: What <span class="math inline">\(k\)</span> would we choose by visual inspection?</p>
<p><strong>A</strong>: k=3 (we choose k so there are k - 2 âbendsâ, and it looks like there is one bend in the curve)</p>
<hr />
<p><strong>Exercise</strong>: To choose <span class="math inline">\(k\)</span> in a data-driven fashion, try fitting these models using just random intercepts (no slopes) of <code>Speaker</code> and <code>Word</code>, and compare them using model comparison:</p>
<ul>
<li><p><code>VOT ~ speakingRateDev</code> (linear model)</p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 3\)</span></p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 4\)</span></p></li>
</ul>
<p><strong>A</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelVOT=<span class="kw">lmer</span>(logVOT ~<span class="st"> </span>speakingRateDev +
<span class="st">       </span>(<span class="dv">1</span>|Speaker) +<span class="st"> </span>(<span class="dv">1</span>|Word), 
     <span class="dt">data=</span>vot)
modelVOT.rcs3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span><span class="kw">rcs</span>(speakingRateDev,<span class="dv">3</span>) +<span class="st"> </span>(<span class="dv">1</span>|Speaker) +<span class="st"> </span>(<span class="dv">1</span>|Word), <span class="dt">data=</span>vot)
modelVOT.rcs4 &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span><span class="kw">rcs</span>(speakingRateDev,<span class="dv">4</span>) +<span class="st"> </span>(<span class="dv">1</span>|Speaker) +<span class="st"> </span>(<span class="dv">1</span>|Word), <span class="dt">data=</span>vot)

<span class="kw">anova</span>(modelVOT,modelVOT.rcs3, modelVOT.rcs4)</code></pre></div>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: vot
## Models:
## modelVOT: logVOT ~ speakingRateDev + (1 | Speaker) + (1 | Word)
## modelVOT.rcs3: logVOT ~ rcs(speakingRateDev, 3) + (1 | Speaker) + (1 | Word)
## modelVOT.rcs4: logVOT ~ rcs(speakingRateDev, 4) + (1 | Speaker) + (1 | Word)
##               Df    AIC    BIC  logLik deviance   Chisq Chi Df Pr(&gt;Chisq)
## modelVOT       5 4493.5 4525.8 -2241.8   4483.5                          
## modelVOT.rcs3  6 4482.6 4521.4 -2235.3   4470.6 12.9231      1  0.0003246
## modelVOT.rcs4  7 4483.8 4529.0 -2234.9   4469.8  0.8121      1  0.3675095
##                  
## modelVOT         
## modelVOT.rcs3 ***
## modelVOT.rcs4    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The results are line with the visual inspection: Having splines with k = 4 does not improve the model over just having splines with k = 3.</p>
<hr />
<p><strong>Q</strong>:</p>
<ul>
<li><p>What does the fact that both are significant tell us?</p></li>
<li><p>How do people differ in the speech rate effect? (Examine the random slope terms.)</p></li>
</ul>
<p><strong>A</strong>: The fact that both are significant tells us that just fitting a linear predictor would not be justifiedâthe non-linear component contributes significantly to the model. Participants show variability in the linear effect.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-baayen2008analyzing">
<p>Baayen, R. (2008). <em>Analyzing linguistic data</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-harrell2001regression">
<p>Harrell, F. (2001). <em>Regression modeling strategies: With applications to linear models, logistic regression, and survival analysis</em>. New York: Springer Verlag.</p>
</div>
<div id="ref-barr2013random">
<p>Barr, D. J., Levy, R., Scheepers, C., &amp; Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. <em>Journal of Memory and Language</em>, <em>68</em>(3), 255â278.</p>
</div>
<div id="ref-lsmeans">
<p>Lenth, R. (2016). Least-squares means: The R package lsmeans. <em>Journal of Statistical Software</em>, <em>69</em>(1), 1â33. <a href="https://doi.org/10.18637/jss.v069.i01" class="uri">https://doi.org/10.18637/jss.v069.i01</a></p>
</div>
<div id="ref-emmeans">
<p>Lenth, R. (2018). <em>Emmeans: Estimated marginal means, aka least-squares means</em>. Retrieved from <a href="https://CRAN.R-project.org/package=emmeans" class="uri">https://CRAN.R-project.org/package=emmeans</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>This may be confusing, since levels of a factor are often discussed as if they do have an order: âlevel 1â, âlevel 2â, and so on. This ordering is used to define contrasts (e.g.Â which factor level is the âbase levelâ), and is assumed by R when making plots involving the factor, etc. However, this ordering is <em>arbitrary</em>âthere is no sense in which level 1 is inherently âlessâ than level 2.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref1">â©</a></p></li>
<li id="fn2"><p>To do this weâd have to use numeric variables for the contrast, as <a href="#lmem-mwrec">shown for mixed models</a>.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref2">â©</a></p></li>
<li id="fn3"><p>For example, think about trying to fit a cubic equation to the reaction time ~ frequency relationship above. The cubic you would need to draw will grow as frequency<span class="math inline">\(^3\)</span> for frequencies below 0, or above 10.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref3">â©</a></p></li>
<li id="fn4"><p>Ideally you should try to see the number of bends using the <strong>empirical data</strong>, since any nonlinear smoother you use is already making assumptions about how much to smooth the dataâanalogous to choosing a value of <span class="math inline">\(k\)</span>. However, this isnât always possible.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref4">â©</a></p></li>
<li id="fn5"><p>This probably isnât necessary as long as there is an empirical plot where a nonlinear relationship is clear.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref5">â©</a></p></li>
<li id="fn6"><p>At least, we think this is the case.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref6">â©</a></p></li>
<li id="fn7"><p>We use uncorrelated by-item random effects in this model because the correlations do not significantly improve model likelihood (by an LR test), the by-item random effects have smaller magnitudes, and the model with correlations does not converge.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref7">â©</a></p></li>
<li id="fn8"><p>It is beyond our knowledge whether there is actually a good reason for this, but googling (e.g. <a href="https://stats.stackexchange.com/questions/3200/is-adjusting-p-values-in-a-multiple-regression-for-multiple-comparisons-a-good-i?noredirect=1&amp;lq=1">here</a>, <a href="https://stats.stackexchange.com/questions/59670/multiple-regression-and-multiple-comparisons">here</a>) suggests that âwhy donât we correct for multiple comparisons in multiple regression models?â is a common question.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref8">â©</a></p></li>
<li id="fn9"><p>Why âpost-hocâ? The terminology comes from ANOVAs applied in a traditional experimental setup, where âpost-hocâ tests are different from âplanned comparisonsâ.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref9">â©</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mixed-effects-logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="datasets-appendix.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
