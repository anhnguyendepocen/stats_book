<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Quantitative Methods for Linguistic Data</title>
  <meta name="description" content="Quantitative Methods for Linguistic Data">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Quantitative Methods for Linguistic Data" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Quantitative Methods for Linguistic Data" />
  
  
  

<meta name="author" content="Morgan Sonderegger, Michael Wagner, Francisco Torreira">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linear-regression.html">
<link rel="next" href="logistic-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods for Linguistic Data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html"><i class="fa fa-check"></i><b>1</b> Inferential statistics: Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-population"><i class="fa fa-check"></i><b>1.1</b> Population vs.Â sample</a><ul>
<li class="chapter" data-level="1.1.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-to-population-high-level"><i class="fa fa-check"></i><b>1.1.1</b> Sample <span class="math inline">\(\to\)</span> population: High level</a></li>
<li class="chapter" data-level="1.1.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sdsm"><i class="fa fa-check"></i><b>1.1.2</b> Sampling distribution of the sample mean</a></li>
<li class="chapter" data-level="1.1.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sampling-from-a-non-normal-distribution"><i class="fa fa-check"></i><b>1.1.3</b> Sampling from a non-normal distribution</a></li>
<li class="chapter" data-level="" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#confidence-intervals"><i class="fa fa-check"></i><b>1.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-distribution"><i class="fa fa-check"></i><b>1.3</b> <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="1.3.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-based-confidence-intervals"><i class="fa fa-check"></i><b>1.3.1</b> <span class="math inline">\(t\)</span>-based confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#other-reading"><i class="fa fa-check"></i><b>1.4</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>2</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-high-level"><i class="fa fa-check"></i><b>2.1</b> Hypothesis testing: High-level</a></li>
<li class="chapter" data-level="2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#z-scores"><i class="fa fa-check"></i><b>2.2</b> <span class="math inline">\(z\)</span>-scores</a></li>
<li class="chapter" data-level="2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-tests"><i class="fa fa-check"></i><b>2.3</b> <span class="math inline">\(t\)</span>-tests</a><ul>
<li class="chapter" data-level="2.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#single-sample-t-test-setup"><i class="fa fa-check"></i><b>2.3.1</b> Single-sample <span class="math inline">\(t\)</span>-test: Setup</a></li>
<li class="chapter" data-level="2.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-in-general"><i class="fa fa-check"></i><b>2.3.2</b> Hypothesis testing in general</a></li>
<li class="chapter" data-level="2.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.3.3</b> Two-sample <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-example"><i class="fa fa-check"></i><b>2.3.4</b> Unequal variances: Welch <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-test-assumptions"><i class="fa fa-check"></i><b>2.3.5</b> Assumptions behind <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>2.3.6</b> Paired <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#reporting-a-hypothesis-test"><i class="fa fa-check"></i><b>2.3.7</b> Reporting a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#checking-normality"><i class="fa fa-check"></i><b>2.4</b> Checking normality</a><ul>
<li class="chapter" data-level="2.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#visual-methods"><i class="fa fa-check"></i><b>2.4.1</b> Visual methods</a></li>
<li class="chapter" data-level="2.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#q-q-plots"><i class="fa fa-check"></i><b>2.4.2</b> Q-Q plots</a></li>
<li class="chapter" data-level="2.4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#shapiro-wilk-example"><i class="fa fa-check"></i><b>2.4.3</b> Hypothesis test</a></li>
<li class="chapter" data-level="2.4.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-parametric-tests"><i class="fa fa-check"></i><b>2.4.4</b> Other parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>2.5</b> Non-parametric tests</a><ul>
<li class="chapter" data-level="2.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxson-tests"><i class="fa fa-check"></i><b>2.5.1</b> Wilcoxson tests</a></li>
<li class="chapter" data-level="2.5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-wilcoxson-test"><i class="fa fa-check"></i><b>2.5.2</b> Two-sample Wilcoxson test</a></li>
<li class="chapter" data-level="2.5.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#parametric-versus-non-parametric-tests"><i class="fa fa-check"></i><b>2.5.3</b> Parametric versus non-parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-reading-1"><i class="fa fa-check"></i><b>2.6</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#regression-general-introduction"><i class="fa fa-check"></i><b>3.1</b> Regression: General introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#linear-models"><i class="fa fa-check"></i><b>3.1.1</b> Linear models</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#terminology"><i class="fa fa-check"></i><b>3.1.2</b> Terminology</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#steps-and-assumptions-of-regression-analysis"><i class="fa fa-check"></i><b>3.1.3</b> Steps and assumptions of regression analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.2</b> Simple linear regression</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#slr-continuous-predictor"><i class="fa fa-check"></i><b>3.2.1</b> SLR: Continuous predictor</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#slr-parameter-estimation"><i class="fa fa-check"></i><b>3.2.2</b> SLR: Parameter estimation</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>3.2.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#quality-of-fit"><i class="fa fa-check"></i><b>3.2.4</b> Quality of fit</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#categorical-predictor"><i class="fa fa-check"></i><b>3.2.5</b> Categorical predictor</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#slr-with-a-binary-categorical-predictor-vs.two-sample-t-test"><i class="fa fa-check"></i><b>3.2.6</b> SLR with a binary categorical predictor vs.Â two-sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.3</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="3.3.1" data-path="linear-regression.html"><a href="linear-regression.html#goodness-of-fit-metrics"><i class="fa fa-check"></i><b>3.3.1</b> Goodness of fit metrics</a></li>
<li class="chapter" data-level="3.3.2" data-path="linear-regression.html"><a href="linear-regression.html#interactions-and-factors"><i class="fa fa-check"></i><b>3.3.2</b> Interactions and factors</a></li>
<li class="chapter" data-level="3.3.3" data-path="linear-regression.html"><a href="linear-regression.html#plotting-interactions"><i class="fa fa-check"></i><b>3.3.3</b> Plotting interactions</a></li>
<li class="chapter" data-level="3.3.4" data-path="linear-regression.html"><a href="linear-regression.html#categorical-factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>3.3.4</b> Categorical factors with more than two levels</a></li>
<li class="chapter" data-level="3.3.5" data-path="linear-regression.html"><a href="linear-regression.html#releveling-factors"><i class="fa fa-check"></i><b>3.3.5</b> Releveling factors</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="linear-regression.html"><a href="linear-regression.html#linear-regression-assumptions"><i class="fa fa-check"></i><b>3.4</b> Linear regression assumptions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="linear-regression.html"><a href="linear-regression.html#visual-methods-1"><i class="fa fa-check"></i><b>3.4.1</b> Visual methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-regression.html"><a href="linear-regression.html#assumption-1-linearity"><i class="fa fa-check"></i><b>3.4.2</b> Assumption 1: Linearity</a></li>
<li class="chapter" data-level="3.4.3" data-path="linear-regression.html"><a href="linear-regression.html#c2ioe"><i class="fa fa-check"></i><b>3.4.3</b> Assumption 2: Independence of errors</a></li>
<li class="chapter" data-level="3.4.4" data-path="linear-regression.html"><a href="linear-regression.html#assumption-3-normality-of-errors"><i class="fa fa-check"></i><b>3.4.4</b> Assumption 3: Normality of errors</a></li>
<li class="chapter" data-level="3.4.5" data-path="linear-regression.html"><a href="linear-regression.html#assumtion-4-constancy-of-variance"><i class="fa fa-check"></i><b>3.4.5</b> Assumtion 4: Constancy of variance</a></li>
<li class="chapter" data-level="3.4.6" data-path="linear-regression.html"><a href="linear-regression.html#interim-summary"><i class="fa fa-check"></i><b>3.4.6</b> Interim summary</a></li>
<li class="chapter" data-level="3.4.7" data-path="linear-regression.html"><a href="linear-regression.html#transforming-to-normality"><i class="fa fa-check"></i><b>3.4.7</b> Transforming to normality</a></li>
<li class="chapter" data-level="3.4.8" data-path="linear-regression.html"><a href="linear-regression.html#assumption-5-linear-independence-of-predictors"><i class="fa fa-check"></i><b>3.4.8</b> Assumption 5: Linear independence of predictors</a></li>
<li class="chapter" data-level="3.4.9" data-path="linear-regression.html"><a href="linear-regression.html#collinearity"><i class="fa fa-check"></i><b>3.4.9</b> Collinearity</a></li>
<li class="chapter" data-level="3.4.10" data-path="linear-regression.html"><a href="linear-regression.html#assumption-6-observations"><i class="fa fa-check"></i><b>3.4.10</b> Assumption 6: Observations</a></li>
<li class="chapter" data-level="3.4.11" data-path="linear-regression.html"><a href="linear-regression.html#lin-reg-measuring-influence"><i class="fa fa-check"></i><b>3.4.11</b> Measuring influence</a></li>
<li class="chapter" data-level="3.4.12" data-path="linear-regression.html"><a href="linear-regression.html#outliers"><i class="fa fa-check"></i><b>3.4.12</b> Outliers</a></li>
<li class="chapter" data-level="3.4.13" data-path="linear-regression.html"><a href="linear-regression.html#regression-assumptions-reassurance"><i class="fa fa-check"></i><b>3.4.13</b> Regression assumptions: Reassurance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="linear-regression.html"><a href="linear-regression.html#lm-model-comparison"><i class="fa fa-check"></i><b>3.5</b> Model comparison</a><ul>
<li class="chapter" data-level="3.5.1" data-path="linear-regression.html"><a href="linear-regression.html#nested-model-comparison"><i class="fa fa-check"></i><b>3.5.1</b> Nested model comparison</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-regression.html"><a href="linear-regression.html#non-nested-model-comparison"><i class="fa fa-check"></i><b>3.5.2</b> Non-nested model comparison</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-regression.html"><a href="linear-regression.html#c2varselect"><i class="fa fa-check"></i><b>3.5.3</b> Variable selection</a></li>
<li class="chapter" data-level="3.5.4" data-path="linear-regression.html"><a href="linear-regression.html#interpretability-issues"><i class="fa fa-check"></i><b>3.5.4</b> Interpretability issues</a></li>
<li class="chapter" data-level="3.5.5" data-path="linear-regression.html"><a href="linear-regression.html#interim-recipe-building-a-multiple-linear-regression-model"><i class="fa fa-check"></i><b>3.5.5</b> Interim recipe: Building a multiple linear regression model</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-regression.html"><a href="linear-regression.html#c2solns"><i class="fa fa-check"></i><b>3.6</b> Solutions</a><ul>
<li class="chapter" data-level="3.6.1" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression-solutions"><i class="fa fa-check"></i><b>3.6.1</b> Multiple linear regression: Solutions</a></li>
<li class="chapter" data-level="3.6.2" data-path="linear-regression.html"><a href="linear-regression.html#linear-regression-assumptions-solutions"><i class="fa fa-check"></i><b>3.6.2</b> Linear regression assumptions: Solutions</a></li>
<li class="chapter" data-level="3.6.3" data-path="linear-regression.html"><a href="linear-regression.html#model-comparison-solutions"><i class="fa fa-check"></i><b>3.6.3</b> Model comparison: Solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cda.html"><a href="cda.html"><i class="fa fa-check"></i><b>4</b> Categorical data analysis: Preliminaries</a><ul>
<li class="chapter" data-level="4.1" data-path="cda.html"><a href="cda.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="cda.html"><a href="cda.html#x2-contingency-tables"><i class="fa fa-check"></i><b>4.1.1</b> 2x2 contingency tables</a></li>
<li class="chapter" data-level="4.1.2" data-path="cda.html"><a href="cda.html#the-chi-squared-test"><i class="fa fa-check"></i><b>4.1.2</b> The chi-squared test</a></li>
<li class="chapter" data-level="4.1.3" data-path="cda.html"><a href="cda.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.1.3</b> Fisherâs exact test</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="cda.html"><a href="cda.html#towards-logistic-regression"><i class="fa fa-check"></i><b>4.2</b> Towards logistic regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="cda.html"><a href="cda.html#odds"><i class="fa fa-check"></i><b>4.2.1</b> Odds</a></li>
<li class="chapter" data-level="4.2.2" data-path="cda.html"><a href="cda.html#log-odds"><i class="fa fa-check"></i><b>4.2.2</b> Log-odds</a></li>
<li class="chapter" data-level="4.2.3" data-path="cda.html"><a href="cda.html#odds-ratios"><i class="fa fa-check"></i><b>4.2.3</b> Odds ratios</a></li>
<li class="chapter" data-level="4.2.4" data-path="cda.html"><a href="cda.html#log-odds-sample-and-population"><i class="fa fa-check"></i><b>4.2.4</b> Log odds: sample and population</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="cda.html"><a href="cda.html#cda-other-readings"><i class="fa fa-check"></i><b>4.3</b> Other readings</a></li>
<li class="chapter" data-level="4.4" data-path="cda.html"><a href="cda.html#c3solns"><i class="fa fa-check"></i><b>4.4</b> Solutions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="cda.html"><a href="cda.html#solutions-to-exercise-1"><i class="fa fa-check"></i><b>4.4.1</b> Solutions to Exercise 1:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>5.1</b> Simple logistic regression</a><ul>
<li class="chapter" data-level="5.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-hyp-test"><i class="fa fa-check"></i><b>5.1.1</b> Hypothesis testing</a></li>
<li class="chapter" data-level="5.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-the-coefficients-logit-odds-and-probability"><i class="fa fa-check"></i><b>5.1.2</b> Interpreting the coefficients: Logit, odds, and probability</a></li>
<li class="chapter" data-level="5.1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-as-a-glm"><i class="fa fa-check"></i><b>5.1.3</b> Logistic regression as a GLM</a></li>
<li class="chapter" data-level="5.1.4" data-path="logistic-regression.html"><a href="logistic-regression.html#c4differences"><i class="fa fa-check"></i><b>5.1.4</b> Differences from linear regression: Fitting and interpretation</a></li>
<li class="chapter" data-level="5.1.5" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-a-logistic-regression-model"><i class="fa fa-check"></i><b>5.1.5</b> Fitting a logistic regression model</a></li>
<li class="chapter" data-level="5.1.6" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation"><i class="fa fa-check"></i><b>5.1.6</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#evaluating-logistic-regression-models"><i class="fa fa-check"></i><b>5.2</b> Evaluating logistic regression models</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#c4lrt"><i class="fa fa-check"></i><b>5.2.1</b> Likelihood ratio test</a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-accuracy"><i class="fa fa-check"></i><b>5.2.2</b> Classification accuracy</a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-pseudo-r2"><i class="fa fa-check"></i><b>5.2.3</b> Pseudo-<span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>5.3</b> Multiple logistic regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-test-general-case"><i class="fa fa-check"></i><b>5.3.1</b> Likelihood ratio test: General case</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-worked-example"><i class="fa fa-check"></i><b>5.3.2</b> Worked example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#model-criticism-logistic-regression"><i class="fa fa-check"></i><b>5.4</b> Model criticism for logistic regression</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-plots"><i class="fa fa-check"></i><b>5.4.1</b> Residual plots</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-cooks-distance"><i class="fa fa-check"></i><b>5.4.2</b> Cookâs distance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#other-readings"><i class="fa fa-check"></i><b>5.5</b> Other readings</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#c4solns"><i class="fa fa-check"></i><b>5.6</b> Solutions</a></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#c4appendix2"><i class="fa fa-check"></i><b>5.7</b> Appendix: Other Generalized Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><i class="fa fa-check"></i><b>6</b> Practical Regression Topics 1: Multi-level factors, contrast coding, interactions</a><ul>
<li class="chapter" data-level="6.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multi-level-factors-introduction"><i class="fa fa-check"></i><b>6.1</b> Multi-level factors: Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding"><i class="fa fa-check"></i><b>6.2</b> Contrast coding</a><ul>
<li class="chapter" data-level="6.2.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#first-examples"><i class="fa fa-check"></i><b>6.2.1</b> First examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#basic-interpretation-of-contrasts"><i class="fa fa-check"></i><b>6.2.2</b> Basic interpretation of contrasts</a></li>
<li class="chapter" data-level="6.2.3" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding-schemes"><i class="fa fa-check"></i><b>6.2.3</b> Contrast coding schemes</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#c5mlf"><i class="fa fa-check"></i><b>6.3</b> Assessing a multi-level factorâs contribution</a></li>
<li class="chapter" data-level="6.4" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#practice-with-interactions"><i class="fa fa-check"></i><b>6.4</b> Practice with interactions</a></li>
<li class="chapter" data-level="6.5" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#c5solns"><i class="fa fa-check"></i><b>6.5</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lmem.html"><a href="lmem.html"><i class="fa fa-check"></i><b>7</b> Linear mixed models</a><ul>
<li class="chapter" data-level="7.1" data-path="lmem.html"><a href="lmem.html#mixed-effects-models-motivation"><i class="fa fa-check"></i><b>7.1</b> Mixed-effects models: Motivation</a><ul>
<li class="chapter" data-level="7.1.1" data-path="lmem.html"><a href="lmem.html#simpsons-paradox"><i class="fa fa-check"></i><b>7.1.1</b> Simpsonâs paradox</a></li>
<li class="chapter" data-level="7.1.2" data-path="lmem.html"><a href="lmem.html#repeated-measure-anovas"><i class="fa fa-check"></i><b>7.1.2</b> Repeated-measure ANOVAs</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-1-one-grouping-factor-random-intercepts"><i class="fa fa-check"></i><b>7.2</b> Linear mixed models 1: One grouping factor, random intercepts</a><ul>
<li class="chapter" data-level="7.2.1" data-path="lmem.html"><a href="lmem.html#c6model1A"><i class="fa fa-check"></i><b>7.2.1</b> Model 1A: Simple linear regression</a></li>
<li class="chapter" data-level="7.2.2" data-path="lmem.html"><a href="lmem.html#c6model1b"><i class="fa fa-check"></i><b>7.2.2</b> Model 1B: Random intercept only</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="lmem.html"><a href="lmem.html#c6lmm2"><i class="fa fa-check"></i><b>7.3</b> Linear mixed models 2: One grouping factor, random intercepts and slopes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="lmem.html"><a href="lmem.html#c6model1c"><i class="fa fa-check"></i><b>7.3.1</b> Model 1C</a></li>
<li class="chapter" data-level="7.3.2" data-path="lmem.html"><a href="lmem.html#fitting-model-1c"><i class="fa fa-check"></i><b>7.3.2</b> Fitting Model 1C</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-3-two-grouping-factors"><i class="fa fa-check"></i><b>7.4</b> Linear mixed models 3: Two grouping factors</a><ul>
<li class="chapter" data-level="7.4.1" data-path="lmem.html"><a href="lmem.html#c6model2A"><i class="fa fa-check"></i><b>7.4.1</b> Model 2A: By-participant and by-item random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="lmem.html"><a href="lmem.html#evaluating-lmms"><i class="fa fa-check"></i><b>7.5</b> Evaluating LMMs</a><ul>
<li class="chapter" data-level="7.5.1" data-path="lmem.html"><a href="lmem.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>7.5.1</b> Hypothesis testing</a></li>
<li class="chapter" data-level="7.5.2" data-path="lmem.html"><a href="lmem.html#significance-of-a-random-effect-term"><i class="fa fa-check"></i><b>7.5.2</b> Significance of a random effect term</a></li>
<li class="chapter" data-level="7.5.3" data-path="lmem.html"><a href="lmem.html#c6fixedp"><i class="fa fa-check"></i><b>7.5.3</b> Significance of fixed effects</a></li>
<li class="chapter" data-level="7.5.4" data-path="lmem.html"><a href="lmem.html#evaluating-goodness-of-fit"><i class="fa fa-check"></i><b>7.5.4</b> Evaluating goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-4-multiple-predictors"><i class="fa fa-check"></i><b>7.6</b> Linear mixed models 4: Multiple predictors</a><ul>
<li class="chapter" data-level="7.6.1" data-path="lmem.html"><a href="lmem.html#types-of-predictors"><i class="fa fa-check"></i><b>7.6.1</b> Types of predictors</a></li>
<li class="chapter" data-level="7.6.2" data-path="lmem.html"><a href="lmem.html#c6model3A"><i class="fa fa-check"></i><b>7.6.2</b> Model 3A: Random intercepts only</a></li>
<li class="chapter" data-level="7.6.3" data-path="lmem.html"><a href="lmem.html#c6model3B"><i class="fa fa-check"></i><b>7.6.3</b> Model 3B: Random intercepts and all possible random slopes</a></li>
<li class="chapter" data-level="7.6.4" data-path="lmem.html"><a href="lmem.html#assessing-variability"><i class="fa fa-check"></i><b>7.6.4</b> Assessing variability</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="lmem.html"><a href="lmem.html#more-on-random-slopes"><i class="fa fa-check"></i><b>7.7</b> More on random slopes</a><ul>
<li class="chapter" data-level="7.7.1" data-path="lmem.html"><a href="lmem.html#what-does-adding-a-random-slope-term-do"><i class="fa fa-check"></i><b>7.7.1</b> What does adding a random slope term do?</a></li>
<li class="chapter" data-level="7.7.2" data-path="lmem.html"><a href="lmem.html#adding-a-random-slope"><i class="fa fa-check"></i><b>7.7.2</b> Discussion: Adding a random slope</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="lmem.html"><a href="lmem.html#random-effect-correlations"><i class="fa fa-check"></i><b>7.8</b> Random effect correlations</a><ul>
<li class="chapter" data-level="7.8.1" data-path="lmem.html"><a href="lmem.html#model-1e-correlated-random-slope-intercept"><i class="fa fa-check"></i><b>7.8.1</b> Model 1E: <strong>Correlated</strong> random slope &amp; intercept</a></li>
<li class="chapter" data-level="7.8.2" data-path="lmem.html"><a href="lmem.html#c6discuss"><i class="fa fa-check"></i><b>7.8.2</b> Dicussion: Adding a correlation</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="lmem.html"><a href="lmem.html#model-criticism-for-linear-mixed-models"><i class="fa fa-check"></i><b>7.9</b> Model criticism for linear mixed models</a><ul>
<li class="chapter" data-level="7.9.1" data-path="lmem.html"><a href="lmem.html#model-3b-residual-plots"><i class="fa fa-check"></i><b>7.9.1</b> Model 3B: Residual plots</a></li>
<li class="chapter" data-level="7.9.2" data-path="lmem.html"><a href="lmem.html#model-3b-random-effect-distribution"><i class="fa fa-check"></i><b>7.9.2</b> Model 3B: Random effect distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="lmem.html"><a href="lmem.html#c6factorsissue"><i class="fa fa-check"></i><b>7.10</b> Random slopes for factors</a><ul>
<li class="chapter" data-level="7.10.1" data-path="lmem.html"><a href="lmem.html#model-with-random-effect-correlations"><i class="fa fa-check"></i><b>7.10.1</b> Model with random-effect correlations</a></li>
<li class="chapter" data-level="7.10.2" data-path="lmem.html"><a href="lmem.html#lmem-mwrec"><i class="fa fa-check"></i><b>7.10.2</b> Models without random-effect correlations</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="lmem.html"><a href="lmem.html#other-readings-1"><i class="fa fa-check"></i><b>7.11</b> Other readings</a></li>
<li class="chapter" data-level="7.12" data-path="lmem.html"><a href="lmem.html#c6extraexamples"><i class="fa fa-check"></i><b>7.12</b> Appendix: Extra examples</a><ul>
<li class="chapter" data-level="7.12.1" data-path="lmem.html"><a href="lmem.html#lmm-simulation-confint"><i class="fa fa-check"></i><b>7.12.1</b> Predicting confidence intervals by simulation</a></li>
<li class="chapter" data-level="7.12.2" data-path="lmem.html"><a href="lmem.html#random-intercept-and-slope-model-for-givenness-data"><i class="fa fa-check"></i><b>7.12.2</b> Random intercept and slope model for <code>givenness</code> data</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="lmem.html"><a href="lmem.html#c6extendedexercise"><i class="fa fa-check"></i><b>7.13</b> Appendix: Extended exercise</a></li>
<li class="chapter" data-level="7.14" data-path="lmem.html"><a href="lmem.html#c6solns"><i class="fa fa-check"></i><b>7.14</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#preliminaries"><i class="fa fa-check"></i><b>8.1</b> Preliminaries</a><ul>
<li class="chapter" data-level="8.1.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#motivation"><i class="fa fa-check"></i><b>8.1.1</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#basics"><i class="fa fa-check"></i><b>8.2</b> Basics</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7m1"><i class="fa fa-check"></i><b>8.2.1</b> Model 1: <code>givenness</code> data, crossed random effects (intercepts + slopes)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#hypothesis-testing-3"><i class="fa fa-check"></i><b>8.3</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="8.3.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects"><i class="fa fa-check"></i><b>8.3.1</b> Fixed effects</a></li>
<li class="chapter" data-level="8.3.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects"><i class="fa fa-check"></i><b>8.3.2</b> Random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>8.4</b> Fixed and random effects</a></li>
<li class="chapter" data-level="8.5" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#melr-practice"><i class="fa fa-check"></i><b>8.5</b> MELR Practice</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7ex1"><i class="fa fa-check"></i><b>8.5.1</b> Exercise 1: tapping</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-criticism-for-mixed-effects-logistic-regression"><i class="fa fa-check"></i><b>8.6</b> Model criticism for mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.6.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effect-distributions"><i class="fa fa-check"></i><b>8.6.1</b> Random-effect distributions</a></li>
<li class="chapter" data-level="8.6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-plots"><i class="fa fa-check"></i><b>8.6.2</b> Residual plots</a></li>
<li class="chapter" data-level="8.6.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#influence"><i class="fa fa-check"></i><b>8.6.3</b> Influence</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measures"><i class="fa fa-check"></i><b>8.7</b> Evaluation measures</a><ul>
<li class="chapter" data-level="8.7.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measure-1-likelihood-ratio-test"><i class="fa fa-check"></i><b>8.7.1</b> Evaluation measure 1: Likelihood ratio test</a></li>
<li class="chapter" data-level="8.7.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measure-2-classification-accuracy"><i class="fa fa-check"></i><b>8.7.2</b> Evaluation measure 2: Classification accuracy</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#miscellaneous-mixed-effects-regression-topics"><i class="fa fa-check"></i><b>8.8</b> Miscellaneous mixed-effects regression topics</a><ul>
<li class="chapter" data-level="8.8.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7m2"><i class="fa fa-check"></i><b>8.8.1</b> Random-effect correlation issues</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#other-readings-2"><i class="fa fa-check"></i><b>8.9</b> Other readings</a></li>
<li class="chapter" data-level="8.10" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#appendices"><i class="fa fa-check"></i><b>8.10</b> Appendices</a><ul>
<li class="chapter" data-level="8.10.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#melr-random-slopes-for-factors"><i class="fa fa-check"></i><b>8.10.1</b> Appendix: Random slopes for factors</a></li>
<li class="chapter" data-level="8.10.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7appendix2"><i class="fa fa-check"></i><b>8.10.2</b> Appendix: Multi-level factors and uncorrelated random effects</a></li>
<li class="chapter" data-level="8.10.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#appendix-what-can-happen-if-a-random-slope-isnt-included"><i class="fa fa-check"></i><b>8.10.3</b> Appendix: What can happen if a random slope isnât included?</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7solns"><i class="fa fa-check"></i><b>8.11</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><i class="fa fa-check"></i><b>9</b> Practical regression topics 2: Ordered factors, nonlinear effects, model predictions, post-hoc tests</a><ul>
<li class="chapter" data-level="9.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#ordered-factors"><i class="fa fa-check"></i><b>9.2</b> Ordered factors</a><ul>
<li class="chapter" data-level="9.2.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#orthogonal-polynomial-contrasts"><i class="fa fa-check"></i><b>9.2.1</b> Orthogonal polynomial contrasts</a></li>
<li class="chapter" data-level="9.2.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-an-ordered-factor-as-a-predictor"><i class="fa fa-check"></i><b>9.2.2</b> Using an ordered factor as a predictor</a></li>
<li class="chapter" data-level="9.2.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#further-points"><i class="fa fa-check"></i><b>9.2.3</b> Further points</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects"><i class="fa fa-check"></i><b>9.3</b> Nonlinear effects</a><ul>
<li class="chapter" data-level="9.3.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#splines-definition-and-benefits"><i class="fa fa-check"></i><b>9.3.1</b> Splines: Definition and benefits</a></li>
<li class="chapter" data-level="9.3.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#restricted-cubic-splines"><i class="fa fa-check"></i><b>9.3.2</b> Restricted cubic splines</a></li>
<li class="chapter" data-level="9.3.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#choosing-spline-complexity"><i class="fa fa-check"></i><b>9.3.3</b> Choosing spline complexity</a></li>
<li class="chapter" data-level="9.3.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#rcs-components"><i class="fa fa-check"></i><b>9.3.4</b> RCS components</a></li>
<li class="chapter" data-level="9.3.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-rcs-in-a-mixed-model"><i class="fa fa-check"></i><b>9.3.5</b> Using RCS in a mixed model</a></li>
<li class="chapter" data-level="9.3.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#random-slopes-for-rcs-terms"><i class="fa fa-check"></i><b>9.3.6</b> Random slopes for RCS terms</a></li>
<li class="chapter" data-level="9.3.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects-summary"><i class="fa fa-check"></i><b>9.3.7</b> Nonlinear effects: Summary</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-from-mixed-models"><i class="fa fa-check"></i><b>9.4</b> Predictions from mixed models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#making-model-predictions"><i class="fa fa-check"></i><b>9.4.1</b> Making Model Predictions</a></li>
<li class="chapter" data-level="9.4.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#simulation-based-predictions"><i class="fa fa-check"></i><b>9.4.2</b> Simulation-based predictions</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#post-hoc-mult-comp"><i class="fa fa-check"></i><b>9.5</b> Post-hoc tests and multiple comparisons</a></li>
<li class="chapter" data-level="9.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8indivpreds"><i class="fa fa-check"></i><b>9.6</b> Appendix: Model predictions for indiviudal participants</a><ul>
<li class="chapter" data-level="9.6.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-incorporating-offsets-for-individual-speakers"><i class="fa fa-check"></i><b>9.6.1</b> Predictions incorporating offsets for individual speakers</a></li>
<li class="chapter" data-level="9.6.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predicted-williams-effect-for-each-speaker"><i class="fa fa-check"></i><b>9.6.2</b> Predicted Williams effect for each speaker</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors"><i class="fa fa-check"></i><b>9.7</b> Appendix: Random slopes for factors</a></li>
<li class="chapter" data-level="9.8" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8solns"><i class="fa fa-check"></i><b>9.8</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="datasets-appendix.html"><a href="datasets-appendix.html"><i class="fa fa-check"></i><b>10</b> Appendix: Datasets and packages</a><ul>
<li class="chapter" data-level="10.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#engdata"><i class="fa fa-check"></i><b>10.1</b> <code>english</code> lexical decision and naming latencies</a></li>
<li class="chapter" data-level="10.2" data-path="datasets-appendix.html"><a href="datasets-appendix.html#dutch-regularity"><i class="fa fa-check"></i><b>10.2</b> Dutch <code id="dregdata">regularity</code></a></li>
<li class="chapter" data-level="10.3" data-path="datasets-appendix.html"><a href="datasets-appendix.html#european-french-phrase-medial-vowel-devoicing"><i class="fa fa-check"></i><b>10.3</b> European French phrase-medial vowel <code id="devdata">devoicing</code></a><ul>
<li class="chapter" data-level="10.3.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background"><i class="fa fa-check"></i><b>10.3.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="datasets-appendix.html"><a href="datasets-appendix.html#north-american-english-tapping"><i class="fa fa-check"></i><b>10.4</b> North American English <code id="tapdata">tapping</code></a><ul>
<li class="chapter" data-level="10.4.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-1"><i class="fa fa-check"></i><b>10.4.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="datasets-appendix.html"><a href="datasets-appendix.html#halfdata"><i class="fa fa-check"></i><b>10.5</b> <code>halfrhyme</code>: English half-rhymes</a></li>
<li class="chapter" data-level="10.6" data-path="datasets-appendix.html"><a href="datasets-appendix.html#givedata"><i class="fa fa-check"></i><b>10.6</b> <code>givenness</code> data: the Williams Effect</a><ul>
<li class="chapter" data-level="10.6.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-2"><i class="fa fa-check"></i><b>10.6.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="datasets-appendix.html"><a href="datasets-appendix.html#alternatives"><i class="fa fa-check"></i><b>10.7</b> <code id="altdata">alternatives</code></a><ul>
<li class="chapter" data-level="10.7.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-3"><i class="fa fa-check"></i><b>10.7.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="datasets-appendix.html"><a href="datasets-appendix.html#votdata"><i class="fa fa-check"></i><b>10.8</b> VOT</a><ul>
<li class="chapter" data-level="10.8.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-4"><i class="fa fa-check"></i><b>10.8.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="datasets-appendix.html"><a href="datasets-appendix.html#transitionsdata"><i class="fa fa-check"></i><b>10.9</b> Transitions</a></li>
<li class="chapter" data-level="10.10" data-path="datasets-appendix.html"><a href="datasets-appendix.html#packages"><i class="fa fa-check"></i><b>10.10</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods for Linguistic Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cda" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Categorical data analysis: Preliminaries</h1>
<p><strong>Preliminary code</strong></p>
<p>This code is needed to make other code below work:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra) <span class="co"># for grid.arrange() to print plots side-by-side</span>
<span class="kw">library</span>(languageR)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(arm)
<span class="kw">library</span>(boot)

## loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) 
## &quot;Information structure and production planning&quot;
alternatives &lt;-<span class="st"> </span><span class="kw">read.delim</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/6qctp/download&quot;</span>), <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><strong>Note</strong>: Answers to some questions/exercises not listed in text are in <a href="cda.html#c3solns">Solutions</a></p>
<script src="js/hideOutput.js"></script>
<!-- TODO FUTURE: actually complete solutions -->
<div id="introduction" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>So far in this book, we have mostly considered data analysis where the outcome is a continuous variable, like reaction time or vowel duration. In linear regression, the outcome (<span class="math inline">\(Y\)</span>) is modeled as a function of one or more categorical and continuous predictors (<span class="math inline">\(X_i\)</span>).</p>
<p>We now turn to <em>categorical data analysis</em>, where the outcome being modeled is a categorical variable. We assume that you have had some exposure to some basic categorical data analysis topics:</p>
<ul>
<li><p><em>Contingency tables</em> (e.g. <code>xtabs</code> in R)</p>
<ul>
<li>Including the notion of <strong>observed</strong> and <strong>expected</strong> values based on a contingency table, and âobserved/expected ratiosâ (O/E ratios).</li>
</ul></li>
<li><p><em>Tests of independence</em> of categorical variables</p>
<ul>
<li><p><span class="math inline">\(\chi^2\)</span> tests</p></li>
<li><p>Fisherâs exact test</p></li>
</ul></li>
</ul>
<p>which we refresh briefly below. If you havenât seen these topics before, some places to read more are given <a href="cda.html#cda-other-readings">below</a>.</p>
<div id="x2-contingency-tables" class="section level3">
<h3><span class="header-section-number">4.1.1</span> 2x2 contingency tables</h3>
<!-- TODO future: re-add this if we ever have an EDA chapter -->
<!-- As discussed in (TODO: update to Exploratory Data Analysis chapter once this exists),  -->
<p>Contingency tables show the number of observations for each combination of values of categorical variables. A 2x2 contingency table in particular shows the number of observations for each combination of two categorical variables, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</p>
<div id="example-14" class="section level4 unnumbered">
<h4>Example</h4>
<p>For this subset of <a href="datasets-appendix.html#altdata">the <code>alternatives</code> data</a>:</p>
<ul>
<li><p><code>prominence</code> = <code>Adjective</code> or <code>Noun</code></p></li>
<li><p><code>context</code>= <code>Alternative</code> or <code>NoAlternative</code></p></li>
</ul>
<p>A contingency table showing the number of observations for each combination of <code>prominence</code> and <code>context</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives.sub &lt;-<span class="st"> </span><span class="kw">filter</span>(alternatives, context%in%<span class="kw">c</span>(<span class="st">&#39;Alternative&#39;</span>, <span class="st">&#39;NoAlternative&#39;</span>) &amp;<span class="st"> </span>
<span class="st">                               </span>prominence %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;Adjective&#39;</span>, <span class="st">&#39;Noun&#39;</span>))</code></pre></div>
<pre><code>## Warning: package &#39;bindrcpp&#39; was built under R version 3.4.4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xtabs</span>(~prominence +<span class="st"> </span>context, <span class="dt">data=</span>alternatives.sub)</code></pre></div>
<pre><code>##            context
## prominence  Alternative NoAlternative
##   Adjective         120            55
##   Noun               85           155</code></pre>
</div>
<div id="observed-and-expected-values" class="section level4 unnumbered">
<h4>Observed and expected values</h4>
<p>In the contingency table above, it looks like prominence isnât independent of context: <code>Adjective</code> prominence is much more likely relative to <code>Noun</code> prominence in <code>Alternative</code> context. We would like to formally test this hypothesis of non-independence. We can do so using this null hypothesis:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <code>prominence</code> and <code>context</code> occur independently in this data.</li>
</ul>
<p>Under <span class="math inline">\(H_0\)</span>, we can work out:</p>
<ol style="list-style-type: decimal">
<li><p>The estimated P(<code>context</code> = <code>alternative</code>)</p></li>
<li><p>The estimated P(<code>prominence</code> = <code>adjective</code>)</p></li>
<li><p>The expected count in each cell, given the total number of observations <span class="math inline">\(n\)</span>.</p></li>
</ol>
<p>For example, for the contingency table above, we can calculate the probabilities #1 and #2:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tab &lt;-<span class="st"> </span><span class="kw">xtabs</span>(~prominence +<span class="st"> </span>context, <span class="dt">data=</span>alternatives.sub)
## total number of observations
n &lt;-<span class="st"> </span><span class="kw">sum</span>(tab)

## P(context = alternative)
pAlt &lt;-<span class="st"> </span><span class="kw">sum</span>(tab[,<span class="st">&#39;Alternative&#39;</span>])/n

## p(prominence = adjective)
pAdj &lt;-<span class="st"> </span><span class="kw">sum</span>(tab[<span class="st">&#39;Adjective&#39;</span>,])/n

## print these probabilities
pAlt</code></pre></div>
<pre><code>## [1] 0.4939759</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pAdj</code></pre></div>
<pre><code>## [1] 0.4216867</code></pre>
The estimated count in the <code>context</code>=<code>Alternative</code> &amp; <code>prominence</code>=<code>Adjective</code> cell is then:
<span class="math display">\[\begin{align}
n \cdot P(`context` = `Alternative`) \cdot P(`prominence` = `Adjective`) &amp; = 
415 \cdot 0.4939759 \cdot 0.4216867 \\
&amp; = 86.4457831
\end{align}\]</span>
</div>
<div id="exercise-1-1" class="section level4 unnumbered">
<h4>Exercise 1</h4>
<p>Calculate the estimated counts for the other three cells.</p>
</div>
</div>
<div id="the-chi-squared-test" class="section level3">
<h3><span class="header-section-number">4.1.2</span> The chi-squared test</h3>
<p>For a 2x2 contingency table, we have:</p>
<ul>
<li><p>The <em>observed</em> counts in each cell, denoted <span class="math inline">\(O_i\)</span></p></li>
<li><p>The <em>expected</em> counts in each cell, denoted <span class="math inline">\(E_i\)</span>, calculated assuming independence (<span class="math inline">\(H_0\)</span>).</p></li>
</ul>
We can then define <em>Pearsonâs test statistic</em>:
<span class="math display" id="eq:pearson">\[\begin{equation*}
  X^2 = \sum^n_{i = 1} \frac{(O_i - E_i)^2}{E_i}
    \tag{4.1}
\end{equation*}\]</span>
<p>which measures how much the observed and expected values differ, across the whole contingency table. <span class="math inline">\(X^2\)</span> is 0 when the observed and expected values are exactly the same, and increases the more the observed and expected values differ.</p>
<p>Pearsonâs test statistic <strong>approximately</strong> follows a <span class="math inline">\(\chi^2\)</span> distribution (pronounced âchi-squaredâ) with one degree of freedom, denoted <span class="math inline">\(\chi^2(1)\)</span>, under conditions described below. Thus, we can test the null hypothesis that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent by comparing the value of <span class="math inline">\(X^2\)</span> to the <span class="math inline">\(\chi^2(1)\)</span> distribution.</p>
<p>The same methodology applies for testing independence of two categorical variables with any number of levels. For <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> with <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> levels, <span class="math inline">\(X^2\)</span> can be calculated using Eq. <a href="cda.html#eq:pearson">(4.1)</a>, and the null hypothesis tested using a <span class="math inline">\(\chi^2((p-1)(q-1))\)</span> distribution.</p>
<div id="examples" class="section level4 unnumbered">
<h4>Examples</h4>
<ol style="list-style-type: decimal">
<li>Are <code>prominence</code> and <code>context</code> independent for the contingency table above?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(tab)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  tab
## X-squared = 43.189, df = 1, p-value = 4.969e-11</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Are <code>Regularity</code> and <code>Auxiliary</code> independent in the Dutch <a href="datasets-appendix.html#dregdata"><code>regularity</code> data</a>?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xtabs</span>(~Auxiliary +<span class="st"> </span>Regularity, regularity)</code></pre></div>
<pre><code>##          Regularity
## Auxiliary irregular regular
##   hebben        108     469
##   zijn           12       8
##   zijnheb        39      64</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(<span class="kw">xtabs</span>(~Auxiliary +<span class="st"> </span>Regularity, regularity))</code></pre></div>
<pre><code>## Warning in chisq.test(xtabs(~Auxiliary + Regularity, regularity)): Chi-
## squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  xtabs(~Auxiliary + Regularity, regularity)
## X-squared = 34.555, df = 2, p-value = 3.136e-08</code></pre>
<hr />
<p>Note that in the <code>regularity</code> example, there is a warning message, related to the âapproximatelyâ condition above. The â<span class="math inline">\(\chi^2\)</span> approximationâ (that the test statistic <span class="math inline">\(X^2\)</span> follows a <span class="math inline">\(\chi^2\)</span> distribution) is only valid when the expected count in each cell is âbig enoughââotherwise, <span class="math inline">\(p\)</span> values are anti-conservative. Common rules of thumb for âbig enoughâ are 5 or 10 observations per cell.</p>
<p>It is common to have fewer than 10 observations in some cell in a contingency table, making <span class="math inline">\(\chi^2\)</span> tests frequently inappropriate. Widespread use of the <span class="math inline">\(\chi^2\)</span> test is to some extent a holdover from when it was computationally difficult to compute âexactâ tests (= no approximation to distribution of test statistic), which require simulation, and there is little reason to use the <span class="math inline">\(\chi^2\)</span> approximation today. For example, you can run a âchi-squared testâ but without assuming the <span class="math inline">\(\chi^2\)</span> approximation by using the <code>simulate.p.value</code> flag to <code>chi.sq</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(<span class="kw">xtabs</span>(~Auxiliary +<span class="st"> </span>Regularity, regularity), <span class="dt">simulate.p.value=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with simulated p-value (based on 2000
##  replicates)
## 
## data:  xtabs(~Auxiliary + Regularity, regularity)
## X-squared = 34.555, df = NA, p-value = 0.0004998</code></pre>
<p>which gets rid of the error.</p>
<p>It is still worth knowing about the <span class="math inline">\(\chi^2\)</span> test and its limitations because it is still frequently used, and in older literature is very widely used. For example, if you are reading a paper where the crucial result relies on a <span class="math inline">\(\chi^2\)</span> test with <span class="math inline">\(p=0.02\)</span> for a contingency table with 5 observations in one cell, you should be suspicious. If the contingency table has 20+ observations per cell, you shouldnât be.</p>
</div>
</div>
<div id="fishers-exact-test" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Fisherâs exact test</h3>
<p>A good alternative to the <span class="math inline">\(\chi^2\)</span> test is <em>Fisherâs exact test</em>, which as an âexact testâ does not place any assumptions on counts per cell. Fisherâs test asks a slightly different question from a <span class="math inline">\(\chi^2\)</span> test:</p>
<ul>
<li>Given the <em>marginal counts</em> (row and column totals) in the contingency table, if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> were independent, how likely would an arrangement of the data at least this extreme be?</li>
</ul>
<p>For example, for testing independence of <code>Auxiliary</code> and <code>Regularity</code> for the <a href="datasets-appendix.html#dregdata">Dutch <code>regularity</code> data</a>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xtabs</span>(~Auxiliary +<span class="st"> </span>Regularity, regularity)</code></pre></div>
<pre><code>##          Regularity
## Auxiliary irregular regular
##   hebben        108     469
##   zijn           12       8
##   zijnheb        39      64</code></pre>
<p>Fisherâs test asks: for 159 irregular verbs, assuming independence, how likely would we be to have <span class="math inline">\(\geq\)</span> 108 <em>hebben</em>, <span class="math inline">\(\leq\)</span> 12 <em>zijn</em>, <span class="math inline">\(\leq\)</span> 39 <em>zijnheb</em>, and so on.</p>
<p>To perform Fisherâs exact test in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fisher.test</span>(<span class="kw">xtabs</span>(~Auxiliary +<span class="st"> </span>Regularity, regularity))</code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  xtabs(~Auxiliary + Regularity, regularity)
## p-value = 1.52e-07
## alternative hypothesis: two.sided</code></pre>
<p>As expected, whether a verb is irregular and which <code>Auxiliary</code> it takes are not independent.</p>
</div>
</div>
<div id="towards-logistic-regression" class="section level2">
<h2><span class="header-section-number">4.2</span> Towards logistic regression</h2>
<p>Intuitively, in logistic regression (<a href="logistic-regression.html#logistic-regression">next chapter</a>) we will predict the probability that some event happens (e.g.Â tapping) as a function of predictors, given a bunch of data where each observation corresponds to observing whether the event happened or not, once (<span class="math inline">\(Y=\)</span> 0 or 1). It would be tempting to just apply the tool weâve learned so farâlinear regressionâto this task. However, itâs not obvious <strong>what to predict</strong> in such a model:</p>
<ul>
<li><p>We canât do a linear regression using <span class="math inline">\(Y\)</span> as the response, because <span class="math inline">\(Y\)</span> only takes on the values 0 and 1. We want to model a <strong>probability</strong>.</p></li>
<li><p>However, we canât do a linear regression using a probability as a response, because (among other reasons) probabilities are bounded by 0 and 1 and linear regression assumes that the response variable can be any number. (We donât want the model to be able to predict âprobability = 2â.)</p></li>
</ul>
<p>In order to predict probabilities using a regression model, we need:</p>
<p><strong>Goal 1</strong>: A way to think of probabilities on a continuous, unbounded scale.</p>
<p><strong>Goal 2</strong>: A way to estimate these probabilities, such that the sample statistic is normally distributed.</p>
<p>Goal 2 is necessary so that we can apply all the statistical inference machinery we have used so far to do things like conduct hypothesis tests.<br />
<!-- Roughly speaking: we will want our measure of probability to be approximately linear as a function of $p$, for it to make sense for us to apply similar machinery to that used for linear regression. --> <!-- not sure that's true.. --></p>
<p>The answer turns out to be to use âlog-oddsâ, for which we must first discuss âoddsâ.</p>
<div id="odds" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Odds</h3>
<p><em>Odds</em> are a way of thinking about probability, as in âhow likely is this event to happen versus not happen?â</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<p>Intuitively, what does it mean to say the odds are 3:1 (âthree-to-oneâ) that it will be sunny tomorrow?</p>
</blockquote>
<p>The relationship between probabilities (<span class="math inline">\(p \in [0,1]\)</span>) and odds are: <span class="math display">\[
\text{Odds}(p) = \frac{p}{1 - p}
\]</span></p>
<p>For the example above: if the probability that it is sunny tomorrow is 0.75, then the odds of it being sunny tomorrow are 3 (<span class="math inline">\(0.75/(1-0.75) = 3\)</span>). The odds of it <em>not</em> being sunny tomorrow are 1/3 (<span class="math inline">\(0.25/(1-0.25)\)</span>), pronounced âone-to-threeâ, or âthree-to-one against sun tomorrow.â</p>
Figure <a href="cda.html#fig:odds1">4.1</a> shows odds as a function of probability.
<div class="figure" style="text-align: center"><span id="fig:odds1"></span>
<img src="04-CDA_files/figure-html/odds1-1.png" alt="Odds as a function of probability." width="288" />
<p class="caption">
Figure 4.1: Odds as a function of probability.
</p>
</div>
<p>Odds may be more intuitive than probabilities, but they do not meet Goal 1 (unbounded scale) because odds are always positive.</p>
</div>
<div id="log-odds" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Log-odds</h3>
The <em>log-odds</em>, corresponding to a probability <span class="math inline">\(p\)</span> are:<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a> <span class="math display">\[
  \text{log-odds}(p) = \log \frac{p}{1-p}
\]</span> The following figure shows log-odds as a function of probability.
<div class="figure" style="text-align: center"><span id="fig:logodds"></span>
<img src="04-CDA_files/figure-html/logodds-1.png" alt="Log-odds as a function of probability" width="288" />
<p class="caption">
Figure 4.2: Log-odds as a function of probability
</p>
</div>
<p>Log-odds meet our goals: they range from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>, and are nearly linear as a function of <span class="math inline">\(p\)</span>, so long as <span class="math inline">\(p\)</span> isnât too close to 0 or 1. It also turns out that log-odds satisfy our Goal 2 (normally-distributed sampling statistic), as discussed below.</p>
<p>Log-odds do have an important drawback: they are unintuitive, compared to odds or probability. With some practice you can learn to think in log-odds.</p>
<div id="exercise-2-log-odds-practice" class="section level4 unnumbered">
<h4>Exercise 2: log-odds practice</h4>
<p>What are the log-odds corresponding to these probabilities?</p>
<ul>
<li><p><span class="math inline">\(p = 0.5\)</span></p></li>
<li><p><span class="math inline">\(p = 0.73\)</span></p></li>
<li><p><span class="math inline">\(p = 0.88\)</span></p></li>
<li><p><span class="math inline">\(p = 0.953\)</span></p></li>
</ul>
<div class="fold o">
<pre><code>## [1] 0</code></pre>
<pre><code>## [1] 0.9946226</code></pre>
<pre><code>## [1] 1.99243</code></pre>
<pre><code>## [1] 3.009467</code></pre>
</div>
<p>This example illustrates:</p>
<ul>
<li><p>Probability space is contracted in log-odds, as we approach 0 or 1: a change of 1 in log-odds corresponds to a smaller and smaller change in <span class="math inline">\(p\)</span>.</p></li>
<li><p>Log-odds of -3 to 3 encompasses 90% of probability space (<span class="math inline">\(\approx p \in (0.05, 0.95)\)</span>).</p></li>
</ul>
<p>Note that 4 is huge in log-odds (<span class="math inline">\(p \approx 0.983\)</span>).</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<p>What is <span class="math inline">\(p\)</span> corresponding to log-odds of -4?</p>
</blockquote>
<div class="fold o">
<pre><code>## [1] 0.01798621</code></pre>
</div>
</div>
</div>
<div id="odds-ratios" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Odds ratios</h3>
<p>Letâs start with an example from <a href="#ctapdata">the <code>tapping</code> data</a>, looking at how the likelihood of tapping depends on <code>syntax</code>:</p>
<ul>
<li><p><span class="math inline">\(Y =\)</span> <code>tapped</code> (1 = yes, 0 = no)</p></li>
<li><p><span class="math inline">\(X =\)</span> <code>syntax</code> (1 = transitive, 0 = intransitive)</p></li>
</ul>
<p>Suppose that the proportions of cases in each cell for our data are:</p>
<span class="math display">\[\begin{array}{c|cc}
&amp; Y = 1 &amp; Y = 0 \\
\hline
X = 1 &amp; 0.462 &amp; 0.037 \\
X = 0 &amp; 0.43 &amp; 0.07
\end{array}\]</span>
<p>We would like a measure of how much more likely tapping is when <span class="math inline">\(X=1\)</span> than when <span class="math inline">\(X=0\)</span>. One way to do this is to calculate the odds of tapping in each case, then take their ratio:</p>
<ul>
<li><p>when <span class="math inline">\(X = 1\)</span>: <span class="math inline">\(\frac{0.462}{0.037} = 12.49\)</span></p></li>
<li><p>when <span class="math inline">\(X = 0\)</span>: <span class="math inline">\(\frac{0.43}{0.07} = 6.14\)</span></p></li>
<li><p>Ratio: <span class="math inline">\(\frac{12.49}{6.14}=\)</span> <strong>2.03</strong></p></li>
</ul>
<p>Thus, the odds of tapping are roughly doubled for transitive verbs, relative to intransitive verbs.</p>
<p>To define this <em>odds ratio</em> more generally, suppose that two binary random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> co-occur with these (population) probabilities:</p>
<span class="math display">\[\begin{array}{c|cc}
&amp; Y = 1 &amp; Y = 0 \\
\hline
X = 1 &amp; p_{11} &amp; p_{10} \\
X = 0 &amp; p_{01} &amp; p_{00}
\end{array}\]</span>
<p>The odds that <span class="math inline">\(Y=1\)</span> are then:</p>
<ul>
<li><p>When <span class="math inline">\(X = 1\)</span>: <span class="math inline">\(\frac{p_{11}}{p_{10}}\)</span></p></li>
<li><p>When <span class="math inline">\(X = 0\)</span>: <span class="math inline">\(\frac{p_{01}}{p_{00}}\)</span></p></li>
</ul>
<p>and the <em>odds ratio</em>, as a population statistic, is defined as: <span class="math display">\[
  OR = \frac{p_{11}/p_{10}}{p_{01}/p_{00}}
\]</span></p>
<p>The odds ratio describes how much the occurrence of one (binary) event depends on another (binary) event, and is often used as an intuitive measure:</p>
<ul>
<li><p>âYour odds of developing lung cancer are halved if you quit smoking.â</p></li>
<li><p>âMarieâs odds of winning the election tripled from January to March.â</p></li>
</ul>
<p>Note that odds ratios are interpreted multiplicatively: it makes sense to say â<span class="math inline">\(X\)</span> raises the odds of <span class="math inline">\(Y\)</span> by a factor of 2â, but not â<span class="math inline">\(X\)</span> raises the odds of <span class="math inline">\(Y\)</span> by 2â.</p>
<p>Odds ratios are in part a way of thinking about changes in probability. For the tapping example: <span class="math display">\[
P(\,\text{tapped}~|~\text{transitive}\,) = 0.926, \quad
  P(\,\text{tapped}~|~\text{intransitive}\,) = 0.86
\]</span><br />
Thus, the change in probability from intransitive to transitive sentences is 0.066. However, odds ratios are <em>not</em> equivalent to changes in probability, because with odds ratios, what a change from <span class="math inline">\(p\)</span> to <span class="math inline">\(p + \Delta p\)</span> corresponds to depends on the probability (<span class="math inline">\(p\)</span>) you start at. For example, Figure <a href="cda.html#fig:oddsratio">4.3</a> shows the odds ratio corresponding to a change in probability of 0.1, as a function of the starting probability.</p>
<div class="figure" style="text-align: center"><span id="fig:oddsratio"></span>
<img src="04-CDA_files/figure-html/oddsratio-1.png" alt="Odds ratio when a probability ($p$) is increased by 0.1, as a function of $p$" width="336" />
<p class="caption">
Figure 4.3: Odds ratio when a probability (<span class="math inline">\(p\)</span>) is increased by 0.1, as a function of <span class="math inline">\(p\)</span>
</p>
</div>
<p>For a change in probability from 0.5 to 0.6, the odds increase by about 1.5x, while for a change in probability from 0.85 to 0.95 the odds increase by 3.35x.</p>
<p>To summarize:</p>
<ul>
<li><p>Odds have a one-to-one relationship with probabilities</p></li>
<li><p><strong>Changes</strong> in odds donât straightforwardly correspond to <strong>changes</strong> in probabilities.</p></li>
</ul>
<p>The non-equivalence between changes in odds and changes in probability is important to remember when interpreting logistic regressions, which are in log-odds space.</p>
</div>
<div id="log-odds-sample-and-population" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Log odds: sample and population</h3>
<p>The odds ratio is a useful <em>summary statistic</em> of the degree of dependence between two binary variables, analogous to correlations (<span class="math inline">\(r\)</span>, <span class="math inline">\(\rho\)</span>) for summarizing dependence between two continuous variables. <!-- TODO FUTURE: if a chapter including correlations ever added in, add cross-ref --> Because we never actually observe the population value of the odds ratioâwhich is based on probabilities of each combination of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>âwe need a <em>sample statistic</em> to estimate it from observed counts for each <span class="math inline">\(X\)</span>/<span class="math inline">\(Y\)</span> combination.</p>
<p>Suppose we observe the following counts:</p>
<span class="math display">\[\begin{array}{c|cc}
&amp; Y = 1 &amp; Y = 0 \\
\hline
X = 1 &amp; n_{11} &amp; n_{10} \\
X = 0 &amp; n_{01} &amp; n_{00}
\end{array}\]</span>
To calculate the empirical odds ratio, we estimate each probability from the observed counts. For example:
<span class="math display">\[\begin{align}
P(Y=1|X=1) \approx \frac{n_{11}}{n_{11}+n_{10}},  \quad P(Y=0|X=1) \approx\frac{n_{10}}{n_{11}+n_{10}} \\
\implies Odds(Y=1|X=1) = \frac{n_{11}}{n_{10}}
\end{align}\]</span>
<p>Similarly estimating <span class="math inline">\(Odds(Y=1|X=1)\)</span>, then taking the logarithm of <span class="math inline">\(Odds(Y=1|X=1)/Odds(Y=1|X=0)\)</span>, gives the sample change in log odds: <span class="math display">\[
  \hat{L} = \log \left[ \frac{n_{11}/n_{10}}{n_{01}/n_{00}} \right]
\]</span></p>
<p>It turns out that <strong><span class="math inline">\(\hat{L}\)</span> is normally distributed with mean <span class="math inline">\(\log(OR)\)</span></strong>, where <span class="math inline">\(OR\)</span> is the population value of the odds ratio. Thus, if we want to do inferential statistics on the effect of binary <span class="math inline">\(X\)</span> on binary <span class="math inline">\(Y\)</span>, it makes sense to work with <strong>log-odds</strong>, rather than probabilities.</p>
<div id="calculation-and-interpretation" class="section level4">
<h4><span class="header-section-number">4.2.4.1</span> Calculation and interpretation</h4>
<ul>
<li><p>The function from probability to log-odds is called <em>logit</em> (<span class="math inline">\(\text{logit}(p)\)</span>)</p></li>
<li><p>The function from log-odds to probability is called <em>inverse logit</em> (<span class="math inline">\(\text{logit}^{-1}(x)\)</span>), a.k.a. the âlogistic functionâ (<span class="math inline">\(1/(1+e^{-x})\)</span>).</p></li>
</ul>
<p>Both can be calculated using R functions, such as <code>logit</code> and <code>invlogit</code> in the <code>arm</code> package.</p>
<p>Note that <strong>adding</strong> in the log-odds scale corresponds to <strong>multiplying</strong> in the odds scale, by a power of <span class="math inline">\(e\)</span>.</p>
For example, changing log-odds by 1 corresponds to multiplying the odds ratio by <span class="math inline">\(e\)</span>:
<span class="math display">\[\begin{eqnarray*}
\log(OR_1) = 0.69 &amp; \implies &amp; OR_1 = e^{0.69} = 2 \\
\log(OR_2) = 1.69 &amp; \implies &amp; OR_2 = e^{1.69} = 5.42 = 2{\cdot}e
\end{eqnarray*}\]</span>
</div>
<div id="exercise-3-1" class="section level4 unnumbered">
<h4>Exercise 3</h4>
<p>Suppose that in the <code>tapping</code> data, one participantâs tapping rate (i.e.Â probability of tapping) is 0.90 in fast speech and 0.70 in slow speech.</p>
<ul>
<li>What are the participantâs <strong>odds</strong> of tapping in fast and slow speech (two numbers)?</li>
</ul>
<div class="fold o">
<pre><code>## [1] 9</code></pre>
<pre><code>## [1] 2.333333</code></pre>
</div>
<ul>
<li>What is the <strong>odds ratio</strong> of tapping (in fast vs.Â slow speech) (one number)?</li>
</ul>
<div class="fold o">
<pre><code>## [1] 3.857143</code></pre>
</div>
<ul>
<li>What is the equivalent <strong>change in log-odds</strong>?</li>
</ul>
<div class="fold o">
<pre><code>## [1] 1.349927</code></pre>
</div>
</div>
</div>
</div>
<div id="cda-other-readings" class="section level2">
<h2><span class="header-section-number">4.3</span> Other readings</h2>
<p>Most introductory statistics books cover contingency tables, chi-squared tests, and Fisher exact tests, including:</p>
<ul>
<li><p>General audience: <span class="citation">Dalgaard (<a href="#ref-dalgaard2008introductory">2008</a>)</span> Ch. 8, <span class="citation">Agresti (<a href="#ref-agresti2007">2007</a>)</span> Ch. 1-2</p></li>
<li><p>For psychologists and language scientists: <span class="citation">Navarro (<a href="#ref-NavarroOnline">2015</a>)</span> Ch. 12, <span class="citation">Johnson (<a href="#ref-johnson2008quantitative">2008</a>)</span> Ch. 3.1, 5.1-5.3</p></li>
</ul>
<p>The Agresti book is a particularly good and accessible resource for categorical data analysis generally. (<span class="citation">Agresti (<a href="#ref-agresti2003categorical">2003</a>)</span> is Agrestiâs more technical/comprehensive book, which is the reference on CDA.)</p>
<p>Some discussion of odds and odds ratios is given by <span class="citation">Agresti (<a href="#ref-agresti2007">2007</a>)</span> Ch. 2, <span class="citation">Gelman &amp; Hill (<a href="#ref-gelman2007data">2007</a>)</span> 5.2, <span class="citation">Crawley (<a href="#ref-crawley2015statistics">2015</a>)</span> Ch. 14.</p>
</div>
<div id="c3solns" class="section level2">
<h2><span class="header-section-number">4.4</span> Solutions</h2>
<div id="solutions-to-exercise-1" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Solutions to Exercise 1:</h3>
<p>Estimated Counts for:</p>
<ul>
<li><p><code>Prominence</code> = <code>Noun</code>, <code>Context</code> = <code>Alternative</code> cell = 118.5542</p></li>
<li><p><code>Prominence</code> = <code>Adjective</code>, <code>Context</code> = <code>NoAlternative</code> cell = 88.55422</p></li>
<li><p><code>Prominence</code> = <code>Adjective</code>, <code>Context</code> = <code>NoAlternative</code> cell = 121.4458</p></li>
</ul>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-dalgaard2008introductory">
<p>Dalgaard, P. (2008). <em>Introductory statistics with R</em> (2nd ed.). New York, NY: Springer.</p>
</div>
<div id="ref-agresti2007">
<p>Agresti, A. (2007). <em>An introduction to categorical data analysis</em>. Wiley.</p>
</div>
<div id="ref-NavarroOnline">
<p>Navarro, D. (2015). <em>Learning Statistics with R</em>. School of Psychology, University of Adelaide, Adelaide, Australia.</p>
</div>
<div id="ref-johnson2008quantitative">
<p>Johnson, K. (2008). <em>Quantitative methods in linguistics</em>. Malden, MA: Wiley-Blackwell.</p>
</div>
<div id="ref-agresti2003categorical">
<p>Agresti, A. (2003). <em>Categorical data analysis</em>. Wiley.</p>
</div>
<div id="ref-gelman2007data">
<p>Gelman, A., &amp; Hill, J. (2007). <em>Data analysis using regression and multilevel/hierarchical models</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-crawley2015statistics">
<p>Crawley, M. J. (2015). <em>Statistics: an introduction using R</em> (Second edition). Wiley.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="20">
<li id="fn20"><p>Note that <span class="math inline">\(\log\)</span> here is base <span class="math inline">\(e\)</span>, where <span class="math inline">\(e=2.718..\)</span> is the base of the <em>natural logarithm</em>.<a href="cda.html#fnref20">â©</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
